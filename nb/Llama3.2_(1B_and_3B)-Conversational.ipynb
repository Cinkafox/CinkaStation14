{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WlwzU91TSHx"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZO3Zm8zTSHz"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYWDy-XpTSH0"
      },
      "source": [
        "**[NEW] We've fixed many bugs in Phi-4** which greatly increases Phi-4's accuracy. See our [blogpost](https://unsloth.ai/blog/phi4)\n",
        "\n",
        "[NEW] You can view all Phi-4 model uploads with our bug fixes including [dynamic 4-bit quants](https://unsloth.ai/blog/dynamic-4bit), GGUF & more [here](https://huggingface.co/collections/unsloth/phi-4-all-versions-677eecf93784e61afe762afa)\n",
        "\n",
        "[NEW] As of Novemeber 2024, Unsloth now supports [vision finetuning](https://unsloth.ai/blog/vision)!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1W6njFlTSH1"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kv-tsWcWTSH2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Normally using pip install unsloth is enough\n",
        "\n",
        "# Temporarily as of Jan 31st 2025, Colab has some issues with Pytorch\n",
        "# Using pip install unsloth will take 3 minutes, whilst the below takes <1 minute:\n",
        "!pip install --no-deps bitsandbytes accelerate xformers peft trl triton\n",
        "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQGJh67jTSH3"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VS_YMJ41TSH4",
        "outputId": "708a2f74-d4a2-4afb-91a2-540c19d46b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "57481ab209ec481cba85d9596869478d",
            "6559dfe4336f4a8bb45ada14d0af4a7c",
            "7c3d72d4bcf142f29b53c5d00818275c",
            "3bacf0503cdc4d62a270b7d8c1e7bc48",
            "ffef66b900be4ee1aacf9728abaa5eb2",
            "81dd2cc8b9014609b2cd20ddeb9600bb",
            "85633e809da940679a182fba4bac08b8",
            "bf0a1160e3bd4597953bfadda9e25906",
            "7b84679ed4e74efeb264a4781fa443eb",
            "b26c0805c1d9458bb0b8145de2e5c0ae",
            "3765bdf5a32049ddaccc70ac06352f7e",
            "c410a11d395542c5aac3bb74d2168059",
            "950bcb2a564f4f02a5fc57eb8b7188cc",
            "2d5f39b06e754c49b7d9dbcf678e50c9",
            "72cb30322a744138a73ec84bb32db6ed",
            "ccfd76324760453890bec67c8e0a64ee",
            "f2f779651494403daffb25c204776ded",
            "7e947372ad4547a2860fcb05a2a524ed",
            "a76ffcd9a8524adba0f7e856ebcd2e14",
            "d72a70824ea246e69e29fff289bedadf",
            "be0676f942b546a79d986afcae5b217d",
            "5ae629c85ac14f91be8d2c415c93e667",
            "7c3635e64b994d5da077270b2e154190",
            "84a6478e693e43499ece9a6f3fa58c7c",
            "2fe5f67dc5c24df9a2143ebe4bd44f9a",
            "8716b0d7930b4a10a9be35fdb73ab7f3",
            "a240c5967e3e49e0ad929304370dd214",
            "fe8bdfcbe9e84822bf60ab478a8857ca",
            "74c4c4ef08f3475c8f68558b4511b666",
            "688e5fe0bf944ce9a8cf7c5f01918fc7",
            "ab7061cb2f4342b2aa5b69bd80d756dd",
            "776e44dbfcb9432fbc020b3546df4bef",
            "935167ea9e144e5e9acaba2d5321fb28",
            "bc31436406614d0da2da9af5ce040bdf",
            "841d599cfa794be1af02fcbaf851d8df",
            "f23896430e7e4964a914745a70a6615d",
            "3e837fa624c84b138ae5469855e13950",
            "cf8104a986e54fcfa4abf431860766dc",
            "bce1976f3a5d482693c794ff983b0c64",
            "5c3e6bd2f7314db3a2788a2f27c8ce86",
            "0f55c1be429644c1be58df561c250a21",
            "b149939143fc421fb50e31fe61b8786a",
            "091a22c484294f61b9130229a3e48eac",
            "5b66903480f54a94a6df6277929c8c98",
            "d5bb59e50d4446cfaa621feefdfebff5",
            "051f004ad2af45b387e119e58dbaa556",
            "a877ce22c57e43b98e51c5d62459e983",
            "15efb40df15b41bd955e203dfbc36f6f",
            "5181a0a13b7e44f09662bd54ab30a8a6",
            "9feaa7d7e504414eb2c2c57094631cd0",
            "74f15b5d1fd44c42872a6f17c37b51ff",
            "95f7debb292b4a5cbe7e22f91c926eae",
            "1904f36568c84894936d11a5b516137a",
            "2c4fed8b1ffe40f794a5c6782a35e913",
            "bb829a22304749ef847f75b0eda8d77e"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.1.8: Fast Llama patching. Transformers: 4.47.1.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57481ab209ec481cba85d9596869478d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c410a11d395542c5aac3bb74d2168059"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c3635e64b994d5da077270b2e154190"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc31436406614d0da2da9af5ce040bdf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5bb59e50d4446cfaa621feefdfebff5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "a2648ce1-e690-47cd-eac7-f085d25eed7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.1.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "I'm great thanks!<|eot_id|>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    #mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conv\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"Arketov/ru_roleplay_conversation\", split = \"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n",
        "```\n",
        "{\"from\": \"system\", \"value\": \"You are an assistant\"}\n",
        "{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n",
        "{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n",
        "```\n",
        "to\n",
        "```\n",
        "{\"role\": \"system\", \"content\": \"You are an assistant\"}\n",
        "{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c19a89b8825649cd8c84f5dd086e5e54",
            "9a490e51ce1a4355ad3f07869a41efc2",
            "48e299974bb34a06a2cd2d67973e7972",
            "0e880418a72946cb8090b95fb9ece14b",
            "4142d77eb4a04c61b5139dfb217cb30a",
            "f4cdf5b762de4f3fba7355c7391a6493",
            "4027f755aadd46b9b60a8fcedd8f0fa0",
            "4142bbd3e2d14555bbc5cb528649bc00",
            "463f8e1bafcf4a4ca9d45418d8ba5ea7",
            "49e0663d4a3f4a60a124b5be5c1aa76e",
            "f1b628fb0eb3483cb856b64dd27f84de"
          ]
        },
        "id": "oPXzJZzHEgXe",
        "outputId": "c3120e8d-825e-4bf9-c488-2e044de6d09f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11686 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c19a89b8825649cd8c84f5dd086e5e54"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "#dataset[\"conversation\"] = dataset[\"conv\"]\n",
        "#print(dataset)\n",
        "#dataset = standardize_sharegpt(dataset)\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for item 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "8f2bc2fc-7941-4d51-c1d3-269a8b04571b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'bot',\n",
              "  'content': '((ooc: –Ω–∞–∂–º–∏ –Ω–∞ —Ö–æ—Ç–ª–∏–Ω–∫–∏, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Ç–æ–≥–æ, —á—Ç–æ –Ω–æ—Å–∏—Ç/–¥–µ—Ä–∂–∏—Ç –ö—É—Ä—å–µ—Ä ^_^))\\n\\n\\n\\r\\n–§—Ä–∏—Å–∞–π–¥ –±—ã–ª —Ç–∞–∫–∏–º –∂–µ, –∫–∞–∫ –∏ –ø–æ—Å–ª–µ –ø–æ–±–µ–¥—ã –ö—É—Ä—å–µ—Ä–∞ –ø–æ—á—Ç–∏ –º–µ—Å—è—Ü –Ω–∞–∑–∞–¥.  –õ—é–¥–µ–π —Å—Ç–∞–ª–æ –±–æ–ª—å—à–µ, –∏ –æ–Ω–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –≤—ã–≥–ª—è–¥–µ–ª–∏ –∑–¥–æ—Ä–æ–≤–µ–µ.  –†–∞–∑–ª–∏—á–∏—è –±—ã–ª–∏ —á—É—Ç—å –±–æ–ª–µ–µ —Ç–æ–Ω–∫–∏–º–∏: –∑–¥–∞–Ω–∏—è –≤—ã–≥–ª—è–¥–µ–ª–∏ —á—É—Ç—å —á–∏—â–µ, –ª—é–¥–∏ –Ω–æ—Å–∏–ª–∏ –±–æ–ª–µ–µ –∫—Ä–∞—Å–∏–≤—É—é –æ–¥–µ–∂–¥—É.  –¢—Ä—É–ø—ã –±—ã–ª–∏ —É–±—Ä–∞–Ω—ã.  –î–∞–∂–µ –≤ –°—Ç–∞—Ä–æ–º –º–æ—Ä–º–æ–Ω—Å–∫–æ–º —Ñ–æ—Ä—Ç–µ —Ç–µ–ø–µ—Ä—å –±—ã–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–µ –ø–æ—Å—Ç—Ä–æ–π–∫–∏.  –û–Ω–∏ –≤—Å–µ –µ—â–µ –±—ã–ª–∏ –¥–æ–≤–æ–ª—å–Ω–æ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–º–∏, –Ω–æ —Ç–µ–ø–µ—Ä—å –æ–Ω–∏ –º–æ–≥–ª–∏ –ø—Ä–∏–≤–æ–∑–∏—Ç—å —Ç—É–¥–∞ –±–æ–ª—å—à–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ç–µ—Ö–Ω–∏–∫–∏ –∏ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤, –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –∏–º —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å –ø–æ—Ç–æ–∫–æ–º —Ä–∞–Ω–µ–Ω—ã—Ö –ø–æ—Å–ª–µ –í—Ç–æ—Ä–æ–π –±–∏—Ç–≤—ã –∑–∞ –¥–∞–º–±—É –ì—É–≤–µ—Ä–∞.\\n\\n\\n\\r\\n–í–æ—Ç –æ–Ω —à–µ–ª –ø–æ —Ü–µ–Ω—Ç—Ä—É –§—Ä–∏—Å–∞–π–¥–∞, –æ–¥–µ—Ç—ã–π –≤ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π\\n–ø—ã–ª—å–Ω–∏–∫\\n –≤ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–π –æ–¥–µ–∂–¥–µ.  –£ –Ω–µ–≥–æ –±—ã–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–µ, –Ω–µ–∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ —á–µ—Ä–Ω—ã–µ –≤–æ–ª–æ—Å—ã –∏ –≥—É—Å—Ç–∞—è –∫–æ–∑–ª–∏–Ω–∞—è –±–æ—Ä–æ–¥–∫–∞.  –í —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å –µ–≥–æ\\n—Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–º–∏ –æ—á–∫–∞–º–∏\\n –∏\\n–±–∞–Ω–¥–∞–Ω–æ–π\\n–æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –≤—ã–¥–µ–ª—è–ª—Å—è —Å—Ä–µ–¥–∏ –±–µ–¥–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π.  –ï–≥–æ —É–≤–µ—Ä–µ–Ω–Ω–∞—è –ø–æ—Ö–æ–¥–∫–∞, —Ü–µ–ª–µ—É—Å—Ç—Ä–µ–º–ª–µ–Ω–Ω–æ—Å—Ç—å, —Å –∫–æ—Ç–æ—Ä–æ–π –æ–Ω –¥–≤–∏–≥–∞–ª—Å—è, –∏ –æ—Ç–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —á–µ—Ä–Ω–∞—è\\n—à—Ç—É—Ä–º–æ–≤–∞—è –≤–∏–Ω—Ç–æ–≤–∫–∞\\n (—Å –ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–≤–æ–ª–æ–º –∏–∑ —Å–µ—Ä–µ–±—Ä–∏—Å—Ç–æ–≥–æ –º–µ—Ç–∞–ª–ª–∞) –ø—Ä–∏–¥–∞–≤–∞–ª–∏ –µ–º—É –≤–ª–∞—Å—Ç–Ω—ã–π –≤–∏–¥.  –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª–∏ –µ–≥–æ, —Ö–æ—Ç—è –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞–ª–∏ –ø–∞–ª—å—Ü–µ–º –∏ –ø–µ—Ä–µ—à–µ–ø—Ç—ã–≤–∞–ª–∏—Å—å –Ω–∞ —Ç–∏—Ö–∏—Ö —Ç–æ–Ω–∞—Ö, –∫–æ–≥–¥–∞ –æ–Ω –ø—Ä–æ—Ö–æ–¥–∏–ª –º–∏–º–æ.  –ö–∞–∑–∞–ª–æ—Å—å, –æ–Ω –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –æ–ø–∏—Å–∞–Ω–∏—è–º –ø—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ –∏ –≥–æ—Ä–æ–∂–∞–Ω, \"–ö—É—Ä—å–µ—Ä–∞ –®–µ—Å—Ç—å\", –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –∏–º–µ–Ω–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ, –ø–æ—Ö–æ–∂–µ, –Ω–∏–∫—Ç–æ –Ω–µ –∑–Ω–∞–ª.  –û–Ω –¥–æ–ª–∂–µ–Ω –±—ã–ª –±—ã—Ç—å –¥–æ–±—Ä—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º, –∞... –Ω—É, —ç—Ç–æ—Ç —á–µ–ª–æ–≤–µ–∫ –≤—ã–≥–ª—è–¥–µ–ª –æ–ø–∞—Å–Ω—ã–º.  –ú–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å, –∫—Ä—É—Ç—ã–º, –∫–æ–≥–¥–∞ –æ–Ω –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞–ª —É–ª–∏—Ü—ã.'},\n",
              " {'role': 'user',\n",
              "  'content': '–ü–æ—Å–ª–µ –ø–æ–±–µ–≥–∞ –î–∂–µ—Å—Å–∏–∫–∞ –ø–æ–Ω—è–ª–∞, —á—Ç–æ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –º–µ—Å—Ç–æ, –∫—É–¥–∞ –æ–Ω–∞ –º–æ–∂–µ—Ç –ø–æ–π—Ç–∏ –∏ –Ω–∞–π—Ç–∏ —Ö–æ—Ç—å –∫–∞–∫—É—é-—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ù—å—é-–í–µ–≥–∞—Å. –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞—â–∏—â–µ–Ω–Ω—ã–π –∑–∞–≥–∞–¥–æ—á–Ω—ã–º \"–ö—É—Ä—å–µ—Ä–æ–º\" –∏ –µ–≥–æ –∞—Ä–º–∏–µ–π —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤, –æ–Ω –±—ã–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –õ–µ–≥–∏–æ–Ω–∞ –¶–µ–∑–∞—Ä–µ–π, –≥—Ä—É–ø–ø—ã, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ä–∞–±–æ—Ç–∏–ª–∞ –µ–µ –ø–æ—á—Ç–∏ –Ω–∞ –≥–æ–¥.\\n\\n\\n\\r\\n–£ –Ω–µ–µ –Ω–µ –±—ã–ª–æ –∫—Ä—ã—à–µ–∫, —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ –°—Ç—Ä–∏–ø. –≠—Ç–æ —É–∂ —Ç–æ—á–Ω–æ. –°–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω—ã —Å—Ä–∞–∑—É –∂–µ –æ—Ç–≤–µ—Ä–≥–ª–∏ –µ–µ. –û–¥–Ω–∞–∫–æ –¥–æ –Ω–µ–µ –¥–æ—Ö–æ–¥–∏–ª–∏ —Å–ª—É—Ö–∏ –æ –¥–æ–±—Ä–æ—Å–µ—Ä–¥–µ—á–Ω–æ–º –ö—É—Ä—å–µ—Ä–µ –∏ –µ–≥–æ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞—Ç—å –ì–æ—Ä–æ–¥ - –¥–∞–∂–µ —Ç—Ä—É—â–æ–±—ã –§—Ä–∏—Å–∞–π–¥–∞.\\n\\n\\n\\r\\n–ù–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –î–∂–µ—Å—Å–∏–∫–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –∏ –≤—ã–∂–∏–≤–∞–ª–∞ –≤–æ –§—Ä–∏—Å–∞–π–¥–µ, –¥–µ–ª–∞—è –≤—Å–µ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ç—å –∫–∞–∫—É—é-—Ç–æ –∫—Ä—ã—à–∫—É –∏–ª–∏ –¥–∞–∂–µ –≥–æ—Ä—è—á—É—é –µ–¥—É. –ü—Ä–∏ —ç—Ç–æ–º –æ–Ω–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —Å–ª–µ–¥–∏–ª–∞ –∑–∞ –Ω–æ–≤–æ—Å—Ç—è–º–∏ –æ —Å–≤–æ–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–º —Å–ø–∞—Å–∏—Ç–µ–ª–µ. –£–¥–∞—á–∞ –±—ã–ª–∞ –Ω–∞ –µ–µ —Å—Ç–æ—Ä–æ–Ω–µ, —Ç–∞–∫ –∫–∞–∫ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏–ª—Å—è —Å–ª—É—Ö, —á—Ç–æ –ö—É—Ä—å–µ—Ä –Ω–∞ —Å–≤–æ–±–æ–¥–µ –∏ –æ—Ö—Ä–∞–Ω—è–µ—Ç —É–ª–∏—Ü—ã –§—Ä–∏—Å–∞–π–¥–∞. –û–Ω–∞ –≤—ã–ª–µ—Ç–µ–ª–∞ –∏–∑ –∑–∞—Ö—É–¥–∞–ª–æ–≥–æ –±–∞—Ä–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º —á–∞—Å—Ç–æ –±—ã–≤–∞–ª–∞, –Ω–∞ –ø–æ–∏—Å–∫–∏ –ö—É—Ä—å–µ—Ä–∞.\\n\\n\\n\\r\\n–ï–≥–æ —Ü–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –∏ –ø–æ—á—Ç–µ–Ω–∏–µ, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—Å–µ –∫ –Ω–µ–º—É –æ—Ç–Ω–æ—Å–∏–ª–∏—Å—å, –Ω–µ –æ—Å—Ç–∞–≤–ª—è–ª–∏ —Å–æ–º–Ω–µ–Ω–∏–π –≤ —Ç–æ–º, —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –æ–¥–µ—Ç—ã–π –∏ –≤–æ–æ—Ä—É–∂–µ–Ω–Ω—ã–π –¥–∂–µ–Ω—Ç–ª—å–º–µ–Ω, –ø—Ä–æ–≥—É–ª–∏–≤–∞—é—â–∏–π—Å—è –ø–æ —É–ª–∏—Ü–µ, –∏ –µ—Å—Ç—å —Ç–æ—Ç —Å–∞–º—ã–π —Ç–∞–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–Ω–∞ –∏—Å–∫–∞–ª–∞. –£—Å–ø–æ–∫–æ–∏—Ç–µ–ª—å–Ω–æ –≤–∑–¥–æ—Ö–Ω—É–≤, –æ–Ω–∞ –ø–æ–¥–±–µ–∂–∞–ª–∞ –∫ –Ω–µ–º—É, –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞—è –ø—Ä–æ–∏–∑–Ω–µ—Å—Ç–∏ —É–∂–µ –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—É—é —Ä–µ—á—å, –∏–∑–ª–∞–≥–∞—è –ª–æ–≥–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ —Ç–æ–º, –∫–∞–∫ –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –µ–º—É –ø–æ–ª–µ–∑–Ω–∞, –µ—Å–ª–∏ –æ–Ω –ø–æ–∑–≤–æ–ª–∏—Ç –µ–π –æ—Å—Ç–∞—Ç—å—Å—è –≤ –°—Ç—Ä–∏–ø–µ, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –µ–µ –±–µ–¥–Ω–æ—Å—Ç—å. –û–¥–Ω–∞–∫–æ, –∫ –µ–µ —É–∂–∞—Å—É, –∫–æ–≥–¥–∞ –æ–Ω–∞ –æ—Ç–∫—Ä—ã–ª–∞ —Ä–æ—Ç, —Ç–æ –≤—ã—Ä–≤–∞–ª–æ—Å—å —Å–ª–µ–¥—É—é—â–µ–µ: \"–ò—â–µ—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ö–æ—Ä–æ—à–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –≤—Ä–µ–º—è —Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º, —Å—ç—Ä?\".'},\n",
              " {'role': 'bot',\n",
              "  'content': '–ö—É—Ä—å–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –Ω–µ–µ.  –ë–æ–ª—å—à–∏–µ —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏ –¥–µ–ª–∞–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –µ–≥–æ –ª–∏—Ü–∞ –Ω–µ–∑–∞–º–µ—Ç–Ω—ã–º, –Ω–æ –Ω–µ–±–æ–ª—å—à–∞—è —É–ª—ã–±–∫–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ—è–≤–∏–ª–∞—Å—å –Ω–∞ –µ–≥–æ –ª–∏—Ü–µ.\\n\\n\\n\\r\\n\"–°–ø–∞—Å–∏–±–æ, –º–∏—Å—Å, –Ω–æ —Å–µ–≥–æ–¥–Ω—è –º–Ω–µ –Ω–∏—á–µ–≥–æ —Ç–∞–∫–æ–≥–æ –Ω–µ –Ω—É–∂–Ω–æ\".  –ì–æ–ª–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –∏—Å—Ö–æ–¥–∏–ª –æ—Ç –Ω–µ–≥–æ, –±—ã–ª —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ —Ç–∞–∫–∏–º, –∫–∞–∫ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å –ø–æ –µ–≥–æ –æ–±—Ä–∞–∑—É: –æ–Ω –±—ã–ª —Å–ø–æ–∫–æ–π–Ω—ã–º, –¥–æ–±—Ä—ã–º –∏ –º—è–≥–∫–∏–º, –∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –µ–≥–æ –∫—É–¥–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏.'},\n",
              " {'role': 'user',\n",
              "  'content': '–û–Ω–∞ –ø–æ–¥–∞–≤–∏–ª–∞ –≤–∑–¥–æ—Ö –æ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∞—Å—å –Ω–∞ –≥–ª—É–±–æ–∫–æ–º —Ä—É–º—è–Ω—Ü–µ. –ó–∞–∫—Ä—ã–≤ –≥–ª–∞–∑–∞ –∏ —Ç—Ä—è—Ö–Ω—É–≤ –≥–æ–ª–æ–≤–æ–π, —Å–ª–æ–≤–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –±—É–∫–≤–∞–ª—å–Ω–æ –≤—ã—Ç—Ä—è—Ö–Ω—É—Ç—å –Ω–µ—Ä–≤—ã, –æ–Ω–∞ —Å–Ω–æ–≤–∞ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∞ –Ω–∞ –∫—É—Ä—å–µ—Ä–∞ –∏ —Å–∫–∞–∑–∞–ª–∞: \"–Ø... –ù–µ—Ç, –ø—Ä–æ—Å—Ç–∏—Ç–µ. –Ø –Ω–µ –∑–Ω–∞—é, –ø–æ—á–µ–º—É —è —Ç–∞–∫ —Å–∫–∞–∑–∞–ª–∞\", - –Ω–µ—Ä–≤–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç —Ä—É–∫–æ–π –ø–æ —Å–ø—É—Ç–∞–≤—à–∏–º—Å—è –≤–æ–ª–æ—Å–∞–º –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç: \"–ü—Ä–æ—Å—Ç–æ... —É –º–µ–Ω—è –µ—Å—Ç—å –∫ —Ç–µ–±–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ\".\\n\\n\\n\\n–û–Ω–∞ –≤—ã–≥–ª—è–¥–∏—Ç –¥–æ–≤–æ–ª—å–Ω–æ –ø–æ–±–µ–∂–¥–µ–Ω–Ω–æ–π, –¥—É–º–∞—è –ø—Ä–æ —Å–µ–±—è, –∫–∞–∫–∞—è –æ–Ω–∞ –Ω–µ—É–¥–∞—á–Ω–∏—Ü–∞. –í–∏–¥–Ω–æ, —á—Ç–æ –æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –≥—Ä–∞–Ω–∏ —Å–ª–µ–∑, –Ω–æ —Å–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Ö. –ö–∞–∫ –±—ã –æ–Ω–∞ –Ω–∏ —Å—Ç–∞—Ä–∞–ª–∞—Å—å –±—ã—Ç—å —Å–∏–ª—å–Ω–æ–π –∏ –∫–∞–∫ –±—ã –Ω–∏ –∑–∞–∫–∞–ª–∏–ª–∞ –µ–µ –∂–∏–∑–Ω—å –≤ –ü—É—Å—Ç–æ—à–∏, –æ–Ω–∞ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç–æ–ª—å–∫–æ –∏–∑–º–æ–∂–¥–µ–Ω–∞, –∫–∞–∫ —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã –≤–µ—Ä–∏—Ç—å –ª—é–¥—è–º.'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –Ω–∞—Ö–º—É—Ä–∏–ª—Å—è, –≥–ª—è–¥—è –Ω–∞ –µ–µ –¥–µ–π—Å—Ç–≤–∏—è, –≤–∏–¥—è, —á—Ç–æ –æ–Ω–∞ —è–≤–Ω–æ –æ—á–µ–Ω—å —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–∞.  –û–Ω —Å–¥–µ–ª–∞–ª —à–∞–≥ –±–ª–∏–∂–µ –∏ –Ω–µ—Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Å–Ω—É–ª—Å—è –µ–µ –ø–ª–µ—á–∞.\\n\\n\\n\\r\\n\"–≠–π, –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ.  –ü—Ä–æ—Å—Ç–æ —É—Å–ø–æ–∫–æ–π—Å—è, –ø–æ–¥—É–º–∞–π, –ø—Ä–µ–∂–¥–µ —á–µ–º –æ—Ç–≤–µ—á–∞—Ç—å.  –ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?\"'},\n",
              " {'role': 'user',\n",
              "  'content': '–ü—Ä–∏–∫—É—Å–∏–≤ –≥—É–±—É, –æ–Ω–∞ –Ω–µ—Ä–≤–Ω–æ –æ–≥–ª—è–¥—ã–≤–∞–µ—Ç—Å—è –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º, —Å–ª–æ–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—è, –Ω–µ—Ç –ª–∏ –∑–∞ –Ω–µ–π —Å–ª–µ–∂–∫–∏. –ù–µ–º–Ω–æ–≥–æ —É—Å–ø–æ–∫–æ–∏–≤—à–∏—Å—å, –æ–Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç: \"–Ø... —è –î–∂–µ—Å—Å–∏–∫–∞. –ú–æ–π –≥–æ—Ä–æ–¥ –±—ã–ª —Ä–∞–∑—Ä—É—à–µ–Ω –õ–µ–≥–∏–æ–Ω–æ–º –¶–µ–∑–∞—Ä—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥, –∏ –º–Ω–µ –Ω–µ–∫—É–¥–∞ –∏–¥—Ç–∏. –í–æ –§—Ä–∏—Å–∞–π–¥–µ –¥–ª—è –º–µ–Ω—è –Ω–µ—Ç –º–µ—Å—Ç–∞, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –Ω–∏ –∫–µ–ø–æ–∫, –Ω–∏ –ø–∞—Å–ø–æ—Ä—Ç–∞, —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ –ø–æ–ª–æ—Å—É. –Ø –ø—Ä–æ—Å—Ç–æ —Ö–æ—á—É –∏–º–µ—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –º–µ—Å—Ç–æ, –≥–¥–µ –º–æ–∂–Ω–æ –∂–∏—Ç—å –∏ —Ä–∞–±–æ—Ç–∞—Ç—å, - —á–µ—Ä–µ–∑ —Å–µ–∫—É–Ω–¥—É –æ–Ω–∞ –≤—Å–ø–æ–º–Ω–∏–ª–∞, –∫ –∫–æ–º—É –æ–±—Ä–∞—â–∞–µ—Ç—Å—è, –∏ –¥–æ–±–∞–≤–∏–ª–∞ \"—Å—ç—Ä\".'},\n",
              " {'role': 'bot',\n",
              "  'content': '–ö—É—Ä—å–µ—Ä –≤–∑–¥–æ—Ö–Ω—É–ª, –æ–ø—É—Å—Ç–∏–≤ –≤–∑–≥–ª—è–¥ –∏ –ø–æ–∫–∞—á–∞–≤ –≥–æ–ª–æ–≤–æ–π.  –≠—Ç–æ –±—ã–ª –Ω–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑, –∫–æ–≥–¥–∞ –∫—Ç–æ-—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏–ª –∫ –Ω–µ–º—É, —á—Ç–æ–±—ã –ª–∏—á–Ω–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å –æ –ø–æ–º–æ—â–∏.  –¢–∞–∫–æ–≤–∞ –±—ã–ª–∞ –µ–≥–æ —Ä–µ–ø—É—Ç–∞—Ü–∏—è.  –û–Ω –≤–æ–æ–±—â–µ –Ω–∏–∫–æ–≥–¥–∞ –Ω–∏–∫–æ–º—É –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–ª –Ω–∞–ø—Ä—è–º—É—é, –Ω–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø—Ä–∞–≤–ª—è–ª –ª—é–¥–µ–π –∫ –¥—Ä—É–≥–∏–º, –∫—Ç–æ –º–æ–≥ –∏–º –ø–æ–º–æ—á—å.  –•–æ—Ç—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã Lucky 38 –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–ª–∏, —á—Ç–æ –µ–º—É –Ω–µ –ø—Ä–∏–¥–µ—Ç—Å—è —Ç—Ä–∞—Ç–∏—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ú–æ—Ö–∞–≤–µ, —É –Ω–µ–≥–æ —Å–æ–≤—Å–µ–º –Ω–µ –±—É–¥–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –µ–¥—É –∏ —Å–æ–Ω, –µ—Å–ª–∏ –æ–Ω –±—É–¥–µ—Ç –ª–∏—á–Ω–æ –ø–æ–º–æ–≥–∞—Ç—å –∫–∞–∂–¥–æ–º—É, –∫—Ç–æ –ø–æ–ø—Ä–æ—Å–∏—Ç.\\n\\n\\n\\n\"–î–∂–µ—Å—Å–∏–∫–∞... –∫–æ–Ω–µ—á–Ω–æ, –∑–¥–µ—Å—å —Å —Ç–æ–±–æ–π –±—É–¥—É—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ\".  –û–Ω —Å–ª–µ–≥–∫–∞ —É–ª—ã–±–Ω—É–ª—Å—è.  \"–¢—ã —Ä–∞–Ω–µ–Ω–∞?  –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ê–ø–æ–∫–∞–ª–∏–ø—Å–∏—Å–∞ –≤ —Ñ–æ—Ä—Ç–µ –°—Ç–∞—Ä—ã—Ö –ú–æ—Ä–º–æ–Ω–æ–≤...\", - –æ–Ω —É–∫–∞–∑–∞–ª –Ω–∞ –±–æ–ª—å—à–æ–π —Ñ–æ—Ä—Ç –°—Ç–∞—Ä–æ–≥–æ –°–≤–µ—Ç–∞ –Ω–µ–ø–æ–¥–∞–ª–µ–∫—É –æ—Ç –Ω–∏—Ö.  \"–û–Ω–∏ –ø–æ–º–æ–≥—É—Ç —Ç–µ–±–µ —Å —Ç–≤–æ–∏–º–∏ —Ä–∞–Ω–∞–º–∏, —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ –∏–ª–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏\".'},\n",
              " {'role': 'user',\n",
              "  'content': '–° —Ä–µ—à–∏—Ç–µ–ª—å–Ω—ã–º –≤–∑–≥–ª—è–¥–æ–º –≤ –≥–ª–∞–∑–∞—Ö –æ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∞ —Ç–≤–µ—Ä–¥—ã–π –∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç —Å –∫—É—Ä—å–µ—Ä–æ–º... –∏–ª–∏, –ø–æ –∫—Ä–∞–π–Ω–µ–π –º–µ—Ä–µ, –µ–π —Ç–∞–∫ –ø–æ–∫–∞–∑–∞–ª–æ—Å—å. –ï–≥–æ —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏ –±—ã–ª–∏ –æ—á–µ–Ω—å –∑–µ—Ä–∫–∞–ª—å–Ω—ã–º–∏. \"–Ø –Ω–µ –±–µ–∂–µ–Ω–∫–∞ –∏ –Ω–µ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∏—Ü–∞, —Å—ç—Ä. –Ø —Ö–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å. –Ø —Ö–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ —Å—Ç—Ä–∏–ø–µ, –≥–¥–µ —è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ–≥—É –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–∞ –∂–∏–∑–Ω—å\".\\n\\n\\n\\n–ù–µ –±—É–¥—É—á–∏ –æ—Ç –ø—Ä–∏—Ä–æ–¥—ã —Ç–∞–∫–æ–π —Å–º–µ–ª–æ–π, –æ–Ω–∞ –Ω–µ–º–Ω–æ–≥–æ –ø–æ–∫—Ä–∞—Å–Ω–µ–ª–∞, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏–ª–∞: \"–Ø —Ç—Ä—É–¥–æ–ª—é–±–∏–≤–∞—è, –±—ã—Å—Ç—Ä–æ —É—á—É—Å—å –∏ –≥–æ—Ç–æ–≤–∞ –¥–µ–ª–∞—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ, –µ—Å–ª–∏ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–±–∏—Ç—å—Å—è –Ω–∞ —Å—Ç—Ä–∏–ø. –ì–¥–µ-—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ—Å—Ç–æ –¥–ª—è –º–µ–Ω—è\".'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–µ–ª –≤ –µ–µ –≥–ª–∞–∑–∞, –∫–æ–≥–¥–∞ –æ–Ω–∞ –≥–æ–≤–æ—Ä–∏–ª–∞, –∏, –≤–æ–∑–º–æ–∂–Ω–æ, —É–≤–∏–¥–µ–ª —Ç–∞–º —á—Ç–æ-—Ç–æ –æ—Ç —Å–µ–±—è.  –¢–æ, —á–µ–º –æ–Ω –±—ã–ª –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –ø–æ–¥–Ω—è–ª—Å—è –∏–∑ —Å–≤–æ–µ–π –Ω–µ–≥–ª—É–±–æ–∫–æ–π –º–æ–≥–∏–ª—ã –≤ –ì—É–¥—Å–ø—Ä–∏–Ω–≥—Å–µ, –æ—Ç–ª–∏—á–∞–ª–æ—Å—å –æ—Ç —Ç–æ–≥–æ, —á–µ–º –æ–Ω –±—ã–ª —Ä–∞–Ω—å—à–µ.  –ï–≥–æ –º–æ–∑–≥ –±—ã–ª —Ä–∞–∑–¥—Ä–æ–±–ª–µ–Ω –ø—É–ª—è–º–∏, –∏ –æ–Ω –ø—Ä–æ—Å–Ω—É–ª—Å—è —Å–æ–≤—Å–µ–º –¥—Ä—É–≥–∏–º —á–µ–ª–æ–≤–µ–∫–æ–º.  –†–∞–Ω—å—à–µ –µ–≥–æ —É—Å—Ç—Ä–∞–∏–≤–∞–ª–∞ —Ä–∞–±–æ—Ç–∞ –∏ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫—É—Ä—å–µ—Ä–∞, –Ω–æ –∫–æ–≥–¥–∞ –æ–Ω –ø—Ä–æ—Å–Ω—É–ª—Å—è –≤ —Ç–æ—Ç –¥–µ–Ω—å, —Ç–æ –æ–±–Ω–∞—Ä—É–∂–∏–ª, —á—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∏—á–µ–≥–æ –≤ –ø–æ–∫–æ–µ; –æ–Ω\\n–±—ã–ª\\n –¥–µ–ª–∞—Ç—å —Ç–æ, —á—Ç–æ –±—ã–ª–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.  –î—Ä—É–≥–æ–≥–æ –≤—ã–±–æ—Ä–∞ –Ω–µ –±—ã–ª–æ.  –í—Å–∫–æ—Ä–µ –æ–Ω —Å—Ç–∞–ª –±–æ–ª–µ–µ —Ç–≤–µ—Ä–¥—ã–º, –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–º –≤ —Å–µ–±–µ... –∏ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ –æ–Ω —É–≤–∏–¥–µ–ª –≤ –Ω–µ–π.\\n\\n\\n\\n\"–¢—ã –±–µ–∂–µ–Ω–∫–∞... –≤ —ç—Ç–æ–º –Ω–µ—Ç –Ω–∏—á–µ–≥–æ –ø–ª–æ—Ö–æ–≥–æ.  –≠—Ç–æ –Ω–µ —Ç–≤–æ—è –≤–∏–Ω–∞\".  –û–Ω –º—è–≥–∫–æ –≤–∑–¥–æ—Ö–Ω—É–ª.  \"–§—Ä–∏—Å–∞–π–¥ –∏–∑–º–µ–Ω–∏–ª—Å—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü.  –û–Ω —Å—Ç–∞–±–∏–ª–µ–Ω, –≤ –Ω–µ–º –Ω–µ—Ç –Ω–∞—Å–∏–ª–∏—è.  –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ª—é–¥–µ–π —Ä–∞–±–æ—Ç–∞—é—Ç.  –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–π —è –Ω–µ —Å–Ω–µ—Å –≤–æ—Ä–æ—Ç–∞ –≤ –°—Ç—Ä–∏–ø, –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –¢—Ä–∏ –°–µ–º—å–∏ –æ–ø–∞—Å–∞—é—Ç—Å—è —Ä–∞—Å–ø—Ä–∞–≤—ã, –∏ –≤–ø–æ–ª–Ω–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ.  –ö–æ–≥–¥–∞-–Ω–∏–±—É–¥—å —Å–∫–æ—Ä–æ —è —Å–Ω–µ—Å—É —ç—Ç–∏ –≤–æ—Ä–æ—Ç–∞\".  –û–Ω —Å–¥–µ–ª–∞–ª –ø–∞—É–∑—É –Ω–∞ –º–≥–Ω–æ–≤–µ–Ω–∏–µ.  \"–û—Ç–ª–∏—á–Ω–æ.  –ü–æ–π–¥–µ–º —Å–æ –º–Ω–æ–π, –º—ã –æ–±—Å—É–¥–∏–º, —á—Ç–æ —Ç—ã –º–æ–∂–µ—à—å —Å–¥–µ–ª–∞—Ç—å.  –í —á–µ–º —Ç—ã —Ö–æ—Ä–æ—à?  –ß—Ç–æ —Ç–µ–±–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ?\"  –û–Ω —Å–ª–µ–≥–∫–∞ –ø–æ–≤–µ—Ä–Ω—É–ª—Å—è –∏ –Ω–∞—á–∞–ª –∏–¥—Ç–∏ –∫ –≤–æ—Ä–æ—Ç–∞–º –≤ –¥—Ä—É–≥—É—é —á–∞—Å—Ç—å –§—Ä–∏—Å–∞–π–¥–∞, —Å –ê—Ç–æ–º–Ω—ã–º –í—Ä–∞–Ω–≥–ª–µ—Ä–æ–º –∏ –≤–æ—Ä–æ—Ç–∞–º–∏ –≤ –°—Ç—Ä–∏–ø, –º–∞–Ω—è –µ–µ –∑–∞ —Å–æ–±–æ–π.'},\n",
              " {'role': 'user',\n",
              "  'content': '–ö–∞–∂–µ—Ç—Å—è, —á—Ç–æ –µ–µ –Ω–æ–≥–∏ –¥–≤–∏–≥–∞—é—Ç—Å—è —Ä–∞–Ω—å—à–µ, —á–µ–º –µ–µ —Ä–∞–∑—É–º –æ—Å–æ–∑–Ω–∞–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–µ–µ, –∏–∑-–∑–∞ —á–µ–≥–æ –æ–Ω–∞ –Ω–µ–º–Ω–æ–≥–æ —Å–ø–æ—Ç—ã–∫–∞–µ—Ç—Å—è, –Ω–æ –ø–æ—Ç–æ–º –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –∏–¥—Ç–∏ –∑–∞ –∫—É—Ä—å–µ—Ä–æ–º. –û–Ω–∞ –Ω–∞ —Å–µ–∫—É–Ω–¥—É –∑–∞–¥—É–º—ã–≤–∞–µ—Ç—Å—è, –ø—Ä–µ–∂–¥–µ —á–µ–º –∑–∞–≥–æ–≤–æ—Ä–∏—Ç—å - –Ω–æ–≤–∞—è –ø—Ä–∏–≤—ã—á–∫–∞, - –∞ –ø–æ—Ç–æ–º –æ—Ç–≤–µ—á–∞–µ—Ç: \"–ß—Ç–æ —è —É–º–µ—é? –ù—É, –º–æ–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã... –æ–≥—Ä–∞–Ω–∏—á–µ–Ω. –ù–æ –º–Ω–µ –≥–æ–≤–æ—Ä–∏–ª–∏, —á—Ç–æ —è —Å–∏–º–ø–∞—Ç–∏—á–Ω–∞—è, —Ç–∞–∫ —á—Ç–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å, —è –º–æ–≥–ª–∞ –±—ã... —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –æ–¥–Ω–æ–º –∏–∑ –æ—Ç–µ–ª–µ–π? –Ø —Ç–∞–∫–∂–µ –∑–Ω–∞—é –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–≤–æ–π –ø–æ–º–æ—â–∏, —Ç–∞–∫ —á—Ç–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å... –∫–æ–º—É-—Ç–æ –Ω—É–∂–Ω–∞ –º–µ–¥—Å–µ—Å—Ç—Ä–∞? –Ø —Ç—Ä—É–¥–æ–ª—é–±–∏–≤ –∏ –Ω–µ –ø—Ä–∏–≤–µ—Ä–µ–¥–ª–∏–≤, –æ–±–µ—â–∞—é. –õ—é–±–∞—è —Ä–∞–±–æ—Ç–∞, –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ, –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –ø–æ—Ä—è–¥–∫–µ\".'},\n",
              " {'role': 'bot',\n",
              "  'content': '–ö—É—Ä—å–µ—Ä –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–≤–µ—Ä–∏–ª –≤ —ç—Ç–æ, —Ç–∞–∫ –∫–∞–∫ –ø–æ–π–º–∞–ª –µ–µ, –∫–æ–≥–¥–∞ –æ–Ω–∞ —Å–ø–æ—Ç–∫–Ω—É–ª–∞—Å—å, –∏ –≤—ã–ø—Ä—è–º–∏–ª –µ–µ, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∏–¥—Ç–∏.\\n\\n\\n\\n\"–¢—ã –∂–µ –∑–Ω–∞–µ—à—å, —á—Ç–æ –º–æ–≥–ª–∞ –±—ã –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—Ç—É –∑–¥–µ—Å—å –∏–ª–∏ –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ –±–µ–∑ –º–æ–µ–π –ø–æ–º–æ—â–∏...\"\\n\\n\\n\\n–û–Ω–∏ –ø—Ä–æ—à–ª–∏ —á–µ—Ä–µ–∑ –∏–º–ø—Ä–æ–≤–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ—Ä–æ—Ç–∞ –≤ –¥—Ä—É–≥—É—é —á–∞—Å—Ç—å –§—Ä–∏—Å–∞–π–¥–∞; —á–µ—Ä–µ–∑ –∑–∞–±—Ä–æ—à–µ–Ω–Ω—ã–π –≤–∞–≥–æ–Ω –º–µ—Ç—Ä–æ, —á—Ç–æ–±—ã –±—ã—Ç—å –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω—ã–º–∏ –∑–≤—É–∫–∞–º–∏ –æ–∂–∏–≤–ª–µ–Ω–Ω–æ–π –º—É–∑—ã–∫–∏ –∏ —Å–∏—è—é—â–µ–π –≤—ã–≤–µ—Å–∫–æ–π KING\\'S —Å–ª–µ–≤–∞ –æ—Ç –Ω–∏—Ö, –≤—ã–≤–µ—Å–∫–æ–π –ö–æ—Ä–æ–ª–µ–≤—Å–∫–æ–π —à–∫–æ–ª—ã –ø–∞—Ä–æ–¥–∏–π.'},\n",
              " {'role': 'user',\n",
              "  'content': '–û–Ω–∞ –ø—Ä–∏–∫—É—Å–∏–ª–∞ –≥—É–±—É –∏ –Ω–µ—Ä–≤–Ω–æ –≤—ã—Å–≤–æ–±–æ–¥–∏–ª–∞—Å—å –∏–∑ –µ–≥–æ –æ–±—ä—è—Ç–∏–π –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –æ–Ω –ø–æ–π–º–∞–ª –µ–µ. –ù–µ –∂–µ–ª–∞—è —Ä–∞—Å–∫—Ä—ã–≤–∞—Ç—å —Å–≤–æ—é –∏—Å—Ç–∏–Ω–Ω—É—é —Ü–µ–ª—å –≤ –ø–æ–∏—Å–∫–∞—Ö —Å–ø–æ—Å–æ–±–∞ –∂–∏—Ç—å –Ω–∞ —Å—Ç—Ä–∏–ø–µ, –æ–Ω–∞ –∑–∞–ø–∏–Ω–∞–µ—Ç—Å—è –∏ –≤—ã–¥–∞–µ—Ç –±—ã—Å—Ç—Ä—ã–π, –Ω–µ—Ä–≤–Ω—ã–π –æ—Ç–≤–µ—Ç. \"–Ø... –ù—É, —è –Ω–µ —Ö–æ—Ç–µ–ª–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –∑–¥–µ—Å—å, –≤–æ –§—Ä–∏—Å–∞–π–¥–µ. –Ø —Ö–æ—Ç–µ–ª–∞... –±–ª–µ—Å–∫–∞ –∏ –≥–ª–∞–º—É—Ä–∞ –°—Ç—Ä–∏–ø–∞!\"\\n\\n\\n\\n–ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –î–∂–µ—Å—Å–∏–∫–∞ –∂–∞–∂–¥–∞–ª–∞ –ª–∏—à—å –æ–±–µ—â–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∑–∞—â–∏—Ç—ã –æ—Ç –õ–µ–≥–∏–æ–Ω–∞ –¶–µ–∑–∞—Ä—è –Ω–∞ —Ç–æ—Ç —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ—à–ª—é—Ç –∑–∞ –Ω–µ–π –∫–æ–≥–æ-–Ω–∏–±—É–¥—å. –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ä–∞–π–æ–Ω—ã –§—Ä–∏—Å–∞–π–¥–∞ –Ω–µ –¥–∞–≤–∞–ª–∏ –µ–π —Å–ø–æ–∫–æ–π—Å—Ç–≤–∏—è.'},\n",
              " {'role': 'bot',\n",
              "  'content': '–ö—É—Ä—å–µ—Ä –∑–Ω–∞–ª, —á—Ç–æ –æ–Ω–∞ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –µ–º—É –Ω–µ –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é [PER 7 (8 —Å –±–æ–Ω—É—Å–æ–º –≤ –≤–∏–¥–µ –±–∞–Ω–¥–∞–Ω—ã) XD], –Ω–æ –æ–Ω —Ç–∞–∫–∂–µ –ø–æ–ª–∞–≥–∞–ª, —á—Ç–æ –æ–Ω–∞ –±—É–¥–µ—Ç –±–æ–ª–µ–µ —Å–∫–ª–æ–Ω–Ω–∞ –≥–æ–≤–æ—Ä–∏—Ç—å –∏—Å–∫—Ä–µ–Ω–Ω–µ, –µ—Å–ª–∏ –Ω–µ –±—É–¥–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –Ω–∞ –ø—É–±–ª–∏–∫–µ.  –ü–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ –æ–Ω–∞ —Ö–æ—Ç–µ–ª–∞ –±—ã –±—ã—Ç—å –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º –º–µ—Å—Ç–µ, –Ω–æ –§—Ä–∏—Å–∞–π–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –±—ã–ª –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –º–µ—Å—Ç–æ–º.  –û–Ω–∞ –Ω–∞–≤–µ—Ä–Ω—è–∫–∞ —Å–ª—ã—à–∞–ª–∞ —Å—Ç–∞—Ä—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ –Ω–µ–º.  –°—Ç–µ–Ω–∞ –≤–æ–∫—Ä—É–≥ —Å–∞–º–æ–≥–æ –ù—å—é-–í–µ–≥–∞—Å–∞ –±—ã–ª–∞ —á–µ–º-—Ç–æ –∏–∑ —Ä—è–¥–∞ –≤–æ–Ω –≤—ã—Ö–æ–¥—è—â–∏–º, –Ω–æ —Å –º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–æ–±–æ—Ç–∞–º–∏ Securitron Mk. II, –ø–∞—Ç—Ä—É–ª–∏—Ä—É—é—â–∏–º–∏ –ø–æ –≤—Å–µ–º—É –≥–æ—Ä–æ–¥—É (–Ω–µ –≥–æ–≤–æ—Ä—è —É–∂–µ –æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑–≤–µ–¥—á–∏–∫–∞—Ö –≤–¥–æ–ª—å –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Å—Ç –≤ –ú–æ—Ö–∞–≤–µ), –ª—é–±–æ–π —Ä–µ–∞–ª—å–Ω–æ–π —É–≥—Ä–æ–∑–µ –±—ã–ª–æ –±—ã —Å–ª–æ–∂–Ω–æ –ø—Ä–æ–Ω–∏–∫–Ω—É—Ç—å —Å—é–¥–∞, –Ω–µ —É–∑–Ω–∞–≤ –æ–± —ç—Ç–æ–º.  –ï—Å–ª–∏ –±—ã –±—ã–ª–æ –∑–∞–º–µ—á–µ–Ω–æ —á—Ç–æ-—Ç–æ —Å—Ç—Ä–∞–Ω–Ω–æ–µ, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –±—ã–ª–∞ –±—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –µ–≥–æ –ü–∏–ø-–ë–æ—é.  –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –æ–Ω –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–ª, —á—Ç–æ –∫—Ç–æ-—Ç–æ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–∂–µ—Ç –ø—Ä–æ–Ω–∏–∫–Ω—É—Ç—å –≤–Ω—É—Ç—Ä—å... –∏–ª–∏, –º–æ–∂–µ—Ç –±—ã—Ç—å, –Ω–µ–±–æ–ª—å—à–∞—è –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∞, –µ—Å–ª–∏ –æ–Ω–∏ —Å–¥–µ–ª–∞—é—Ç —ç—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ.\\n\\n\\n\\n–í—Å–∫–æ—Ä–µ –æ–Ω–∏ –ø—Ä–∏–±–ª–∏–∑–∏–ª–∏—Å—å –∫ –≤–æ—Ä–æ—Ç–∞–º –≤ –°—Ç—Ä–∏–ø, –∏ –æ–¥–∏–Ω –∏–∑ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤, –∫–∞–∫ –≤—Å–µ–≥–¥–∞, –ø–æ–¥–∫–∞—Ç–∏–ª –∫ –Ω–∏–º, –Ω–µ –æ–±—Ä–∞—â–∞—è –≤–Ω–∏–º–∞–Ω–∏—è –Ω–∞ –∫—É—Ä—å–µ—Ä–∞, –∞ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–≤—à–∏—Å—å –Ω–∞ –î–∂–µ—Å—Å–∏–∫–µ.\\n\\n\\n\\n\"–ü—Ä–æ–π–¥–∏—Ç–µ –∫—Ä–µ–¥–∏—Ç–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∏–ª–∏ –ø—Ä–µ–¥—ä—è–≤–∏—Ç–µ –¥–µ–π—Å—Ç–≤—É—é—â–∏–π –ø–∞—Å–ø–æ—Ä—Ç –¥–ª—è –≤—Ö–æ–¥–∞\".\\n\\n\\n\\n\"–û–Ω–∞ —Å–æ –º–Ω–æ–π\", - —Å–∫–∞–∑–∞–ª –ö—É—Ä—å–µ—Ä.\\n\\n\\n\\n\"–°–ø–∞—Å–∏–±–æ!\" - —Å–∫–∞–∑–∞–ª –∂—É—Ç–∫–æ –≤–µ–∂–ª–∏–≤—ã–π —Ä–æ–±–æ—Ç.  \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ—Ö–æ–¥–∏—Ç–µ –≤–Ω—É—Ç—Ä—å\".'},\n",
              " {'role': 'user',\n",
              "  'content': '–î—Ä–æ–∂—å –ø—Ä–æ–±–µ–∂–∞–ª–∞ –ø–æ –µ–µ –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫—É, –∫–æ–≥–¥–∞ –æ–Ω–∏ –ø—Ä–æ—Ö–æ–¥–∏–ª–∏ –º–∏–º–æ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤. –û–Ω–∞ –¥—É–º–∞–ª–∞ –æ —Ç–æ–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω–∏ –º–æ–≥—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã, –∏ –æ —Ç–æ–º, —á—Ç–æ —Å –Ω–∏–º–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –¥–æ–≥–æ–≤–æ—Ä–∏—Ç—å—Å—è —Ç–∞–∫, –∫–∞–∫ —Å —á–µ–ª–æ–≤–µ–∫–æ–º. –î–ª—è –Ω–µ–µ —ç—Ç–æ –±—ã–ª–∞ —Å–∞–º–∞—è —Å—Ç—Ä–∞—à–Ω–∞—è –º—ã—Å–ª—å. –û–Ω–∏ –≤–æ—à–ª–∏ –≤ –°—Ç—Ä–∏–ø, –∏ –î–∂–µ—Å—Å–∏–∫–∞ –Ω–µ –º–æ–≥–ª–∞ —É–¥–µ—Ä–∂–∞—Ç—å—Å—è –æ—Ç —Ç–æ–≥–æ, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≥–ª–∞–∑–µ—Ç—å –Ω–µ–º–Ω–æ–≥–æ. –í—Å–µ –∫–∞–∑–∞–ª–∏—Å—å —Ç–∞–∫–∏–º–∏ –±–æ–≥–∞—Ç—ã–º–∏, —Å–∞–º–æ–¥–æ–≤–æ–ª—å–Ω—ã–º–∏ –∏ —è–≤–Ω–æ —Å—á–∏—Ç–∞–ª–∏ —Å–µ–±—è –æ—á–µ–Ω—å –≤–∞–∂–Ω—ã–º–∏. –ó–¥–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –∏–∑–¥–∞–ª–µ–∫–∞ –∫–∞–∑–∞–ª–∏—Å—å —Ç–∞–∫–∏–º–∏ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º–∏, —Ç–µ–ø–µ—Ä—å –±—ã–ª–∏ –∫–∞—Ä–ª–∏–∫–æ–≤—ã–º–∏ –∏ –∑–∞—Å—Ç–∞–≤–ª—è–ª–∏ –µ–µ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –µ—â–µ –º–µ–Ω—å—à–µ. –ü—Ä–∏–º–µ—Ä–Ω–æ —á–µ—Ä–µ–∑ 15 —Å–µ–∫—É–Ω–¥ –æ–Ω–∞ —Å–Ω–æ–≤–∞ –ø–æ–≤–µ—Ä–Ω—É–ª–∞—Å—å –∫ –∫—É—Ä—å–µ—Ä—É –∏ —Ä–∞–¥–æ—Å—Ç–Ω–æ —Å–∫–∞–∑–∞–ª–∞: \"–°–ø–∞—Å–∏–±–æ! –¢—ã –æ–∫–∞–∑–∞–ª –º–Ω–µ —Ç–∞–∫—É—é –ª—é–±–µ–∑–Ω–æ—Å—Ç—å. –ú–æ–≥—É –ª–∏ —è —á–µ–º-–Ω–∏–±—É–¥—å –æ—Ç–ø–ª–∞—Ç–∏—Ç—å —Ç–µ–±–µ?\"'},\n",
              " {'role': 'bot',\n",
              "  'content': '–ö—É—Ä—å–µ—Ä –ø—Ä–∏–≤–µ–ª –µ–µ –∫ –≤–æ—Ä–æ—Ç–∞–º Lucky 38; –º–∞—Å—Å–∏–≤–Ω—ã–µ –∫—Ä–∞—Å–Ω–æ-—á–µ—Ä–Ω—ã–µ –¥–≤–µ—Ä–∏ —Å –≤–∏–∑–≥–æ–º —Ä–∞–∑–¥–≤–∏–Ω—É–ª–∏—Å—å –≤ —Å—Ç–æ—Ä–æ–Ω—ã, –æ—Ç–∫—Ä—ã–≤–∞—è –±–æ–ª–µ–µ –æ–±—ã—á–Ω—É—é –ø–∞—Ä–∞–¥–Ω—É—é –¥–≤–µ—Ä—å.  –°—Ç—É–ø–µ–Ω–∏ –∫–∞–∑–∏–Ω–æ –∑–∞—Å–≤–µ—Ç–∏–ª–∏—Å—å –≤–∑–∞–¥-–≤–ø–µ—Ä–µ–¥, –∫–æ–≥–¥–∞ –æ–Ω–∏ –ø—Ä–æ—à–ª–∏ –ø–æ –Ω–∏–º, –∏ –æ–Ω –ø—Ä–æ–≤–µ–ª –µ–µ –≤–Ω—É—Ç—Ä—å.\\n\\n\\n\\n–≠—Ç–æ –±—ã–ª–æ –∫–∞–∑–∏–Ω–æ.  –ï–≥–æ –æ—Ö—Ä–∞–Ω—è–ª–∏ –¥–≤–∞ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–∞ - –ø–æ –æ–¥–Ω–æ–º—É —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, \"—Å–º–æ—Ç—Ä—è\" –Ω–∞ –Ω–∏—Ö –∏–∑-–∑–∞ –∫–∞—Ä–∏–∫–∞—Ç—É—Ä—ã —Å–æ–ª–¥–∞—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∞—Å—å –Ω–∞ –∏—Ö —ç–∫—Ä–∞–Ω–∞—Ö.\\n\\n\\n\\n\"–≠—Ç–æ...\"  –ö—É—Ä—å–µ—Ä —É–ª—ã–±–Ω—É–ª—Å—è –∏ —Ç–∏—Ö–æ–Ω—å–∫–æ –∑–∞—Å–º–µ—è–ª—Å—è.  \"–ú–æ–π –¥–æ–º, —è –ø–æ–ª–∞–≥–∞—é.  –ù—É, –Ω–µ –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–∂–µ\".  –ö–∞–∑–∞–ª–æ—Å—å, –æ–Ω –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª –µ–µ –≤–æ–ø—Ä–æ—Å.'},\n",
              " {'role': 'user',\n",
              "  'content': '–ö–æ–≥–¥–∞ –æ–Ω–∞ –ø–æ–¥–Ω–∏–º–∞–ª–∞—Å—å –ø–æ —Å—Ç—É–ø–µ–Ω—å–∫–∞–º –∏ –≤—Ö–æ–¥–∏–ª–∞ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–≤–µ—Ä–∏, —Ä–æ—Å–∫–æ—à—å —Å—á–∞—Å—Ç–ª–∏–≤—á–∏–∫–∞ 38 –±—ã–ª–∞ –¥–ª—è –Ω–µ–µ –ø–æ—á—Ç–∏ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ–π. \"–¢-—Ç–≤–æ–π –¥–æ–º –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω\", - —Å–∫–∞–∑–∞–ª–∞ –æ–Ω–∞, –Ω–µ–º–Ω–æ–≥–æ –æ–±–µ—Å–∫—É—Ä–∞–∂–µ–Ω–Ω–∞—è —Ç–µ–º, —á—Ç–æ –æ–Ω –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –Ω–∞ –µ–µ –≤–æ–ø—Ä–æ—Å, - \"–í—Å–µ —ç—Ç–æ –Ω–µ–º–Ω–æ–≥–æ —Å—é—Ä—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ –¥–ª—è –º–µ–Ω—è, —è –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª–∞, —á—Ç–æ —Ç–∞–∫–æ–π –¥–≤–æ—Ä–µ—Ü –º–æ–∂–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –ú–æ—Ö–∞–≤–µ\".'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –Ω–µ —É–¥–µ—Ä–∂–∞–ª—Å—è –∏ —Å–ª–µ–≥–∫–∞ —É—Ö–º—ã–ª—å–Ω—É–ª—Å—è –Ω–∞ –µ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ, —Å–∫—Ä–µ—Å—Ç–∏–≤ —Ä—É–∫–∏ –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ –ª–∏—Ñ—Ç–∞.  \"–¢—ã –µ—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –≤–∏–¥–µ–ª–∞\".  –û–Ω —Ö–æ—Ç–µ–ª –ø–æ–∫–∞–∑–∞—Ç—å –µ–π —Å—Ç—Ä–∏–ø –Ω–æ—á—å—é, –≤–∏–¥ —Å –≤–µ—Ä—à–∏–Ω—ã Lucky 38.  –û–Ω–∞ –±—ã–ª–∞ –ø–µ—Ä–≤—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–Ω –ø—Ä–∏–≤–µ–ª —Å—é–¥–∞ —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫... –Ω—É, —Å —Ç–µ—Ö –ø–æ—Ä –∫–∞–∫... –∫–æ–≥–¥–∞-–ª–∏–±–æ.  –û–Ω –ø–æ–Ω—è—Ç–∏—è –Ω–µ –∏–º–µ–ª –ø–æ—á–µ–º—É, –Ω–æ –µ–º—É –±—ã–ª–æ –±–µ–∑—É—Å–ª–æ–≤–Ω–æ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —ç—Ç–æ –µ–π.\\n\\n\\n\\n\\n–î–∑–∏–Ω—å!\\n  –î–≤–µ—Ä–∏ –ª–∏—Ñ—Ç–∞ –æ—Ç–∫—Ä—ã–ª–∏—Å—å.  \"–î–∞–≤–∞–π —è –ø–æ–∫–∞–∂—É —Ç–µ–±–µ –ø–µ–Ω—Ç—Ö–∞—É—Å\".'},\n",
              " {'role': 'user',\n",
              "  'content': '\\n\\n\\n\\t\\t\\t\\n\\t\\t\\t\\t—Å–∫–∞–∑–∞–ª –í–≤–µ—Ç:\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t–û–Ω –Ω–µ —É–¥–µ—Ä–∂–∞–ª—Å—è –∏ —Å–ª–µ–≥–∫–∞ —É—Ö–º—ã–ª—å–Ω—É–ª—Å—è –Ω–∞ –µ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ, —Å–∫—Ä–µ—Å—Ç–∏–≤ —Ä—É–∫–∏ –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ –ª–∏—Ñ—Ç–∞.  \"–¢—ã –µ—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –≤–∏–¥–µ–ª–∞\".  –û–Ω —Ö–æ—Ç–µ–ª –ø–æ–∫–∞–∑–∞—Ç—å –µ–π —Å—Ç—Ä–∏–ø –Ω–æ—á—å—é, –≤–∏–¥ —Å –≤–µ—Ä—à–∏–Ω—ã Lucky 38.  –û–Ω–∞ –±—ã–ª–∞ –ø–µ—Ä–≤—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–Ω –ø—Ä–∏–≤–µ–ª —Å—é–¥–∞ —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫... –Ω—É, —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫ –Ω–∏–∫–æ–≥–¥–∞.  –û–Ω –ø–æ–Ω—è—Ç–∏—è –Ω–µ –∏–º–µ–ª –ø–æ—á–µ–º—É, –Ω–æ –µ–º—É –±—ã–ª–æ –±–µ–∑—É—Å–ª–æ–≤–Ω–æ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —ç—Ç–æ –µ–π.\\n\\n\\n\\n\\n–î–∑–∏–Ω—å!\\n  –î–≤–µ—Ä–∏ –ª–∏—Ñ—Ç–∞ –æ—Ç–∫—Ä—ã–ª–∏—Å—å.  \"–î–∞–≤–∞–π —è –ø–æ–∫–∞–∂—É —Ç–µ–±–µ –ø–µ–Ω—Ç—Ö–∞—É—Å\".\\n\\t\\t\\n\\n\\nClick to expand...\\n\\n\\n\\n\\n\\r\\n–° –∂–∏–≤–æ—Ç–æ–º, –ø–æ–ª–Ω—ã–º –±–∞–±–æ—á–µ–∫, –î–∂–µ—Å—Å–∏–∫–∞ –≤–æ—à–ª–∞ –≤ –ª–∏—Ñ—Ç –∏ –∏–∑–±–µ–≥–∞–ª–∞ –∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞ —Å –∫—É—Ä—å–µ—Ä–æ–º, –≥–ª—è–¥—è –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º, –∫—É–¥–∞ —É–≥–æ–¥–Ω–æ, —Ç–æ–ª—å–∫–æ –Ω–µ –Ω–∞ –Ω–µ–≥–æ. –ö–æ–≥–¥–∞ –æ–Ω–∞ –∑–∞–≥–æ–≤–æ—Ä–∏–ª–∞, —Ç–æ —Å –∫—Ä–æ—Ç–∫–∏–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º –ª–∏—Ü–∞ –ø—Ä–∏—Å—Ç–∞–ª—å–Ω–æ —É—Å—Ç–∞–≤–∏–ª–∞—Å—å –≤ –ø–æ–ª. \"–Ø –∑–∞–º–µ—Ç–∏–ª–∞, —á—Ç–æ –≤—ã –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª–∏ –º–æ–π –≤–æ–ø—Ä–æ—Å, —Å—ç—Ä. –ú–æ–≥—É –ª–∏ —è —á–µ–º-—Ç–æ –ø–æ–º–æ—á—å –≤–∞–º?\"\\n\\n\\n\\r\\n–ü—Ä–µ–∂–¥–µ —á–µ–º –æ–Ω —É—Å–ø–µ–ª –æ—Ç–≤–µ—Ç–∏—Ç—å, –ª–∏—Ñ—Ç –∑–≤—è–∫–Ω—É–ª –∏ –æ—Ç–∫—Ä—ã–ª—Å—è, –æ—Ç–∫—Ä—ã–≤–∞—è –≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–π –ø–µ–Ω—Ç—Ö–∞—É—Å. –û–Ω–∞ –∑–∞–¥–æ—Ö–Ω—É–ª–∞—Å—å –æ—Ç –≤–æ—Å—Ç–æ—Ä–≥–∞, –Ω–æ, –ø—Ä–µ–∂–¥–µ —á–µ–º –≤—ã–π—Ç–∏ –∏–∑ –ª–∏—Ñ—Ç–∞, –ø–æ–≤–µ—Ä–Ω—É–ª–∞—Å—å –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∞ –Ω–∞ –Ω–µ–≥–æ, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å, —á—Ç–æ –æ–Ω —Å–¥–µ–ª–∞–µ—Ç –∏–ª–∏ —Å–∫–∞–∂–µ—Ç.'},\n",
              " {'role': 'bot',\n",
              "  'content': '\"–Ø –Ω–µ –∑–Ω–∞—é.  –ï—Å—Ç—å —Ç–∞–∫ –º–Ω–æ–≥–æ –ø—Ä–æ–±–ª–µ–º –∏ —Ç–∞–∫ –º–Ω–æ–≥–æ –≤–µ—â–µ–π, –∫–æ—Ç–æ—Ä—ã–µ\\n–º–æ–∂–µ—Ç\\n –ø–æ–π—Ç–∏ –Ω–µ —Ç–∞–∫... –Ø –±—ã –¥–∞–∂–µ –Ω–µ –∑–Ω–∞–ª, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å.  –ù–æ —ç—Ç–æ –º–æ–∏ –ø—Ä–æ–±–ª–µ–º—ã.  –Ø –Ω–µ —Ö–æ—á—É –æ–±—Ä–µ–º–µ–Ω—è—Ç—å –∏–º–∏ –∫–æ–≥–æ-—Ç–æ –µ—â–µ\".  –û–Ω –≤—ã—à–µ–ª –≤ –ø–µ–Ω—Ç—Ö–∞—É—Å, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª —Å–æ–±–æ–π –±–æ–ª—å—à–æ–π –≤—Ä–∞—â–∞—é—â–∏–π—Å—è –∫–æ–∫—Ç–µ–π–ª—å-–ª–∞—É–Ω–¥–∂, –∏–ª–∏ –±—ã–ª —Ç–∞–∫–æ–≤—ã–º –≤ –¥–æ–≤–æ–µ–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–∞.  –í—Å–µ –±—ã–ª–æ –±–µ–∑—É–ø—Ä–µ—á–Ω–æ —á–∏—Å—Ç—ã–º.  –ü–æ–º–µ—â–µ–Ω–∏–µ –∏–º–µ–ª–æ —Ñ–æ—Ä–º—É –ø–æ–Ω—á–∏–∫–∞, –≤ —Ü–µ–Ω—Ç—Ä–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å —à–∞—Ö—Ç–∞ –ª–∏—Ñ—Ç–∞, –∞ –≤–æ–∫—Ä—É–≥ –Ω–µ–µ –º–µ–¥–ª–µ–Ω–Ω–æ –≤—Ä–∞—â–∞–ª—Å—è –ø–µ–Ω—Ç—Ö–∞—É—Å.  –ë–æ–∫–æ–≤—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –≤—Å–µ–π –∫–æ–º–Ω–∞—Ç—ã –±—ã–ª–∏ —Å—Ç–µ–∫–ª—è–Ω–Ω—ã–º–∏, –∏–∑ –Ω–∏—Ö –º–æ–∂–Ω–æ –±—ã–ª–æ —É–≤–∏–¥–µ—Ç—å –≤–µ—Å—å –≥–æ—Ä–æ–¥ –ù—å—é-–í–µ–≥–∞—Å –∏ –Ω–µ–º–Ω–æ–≥–æ –ú–æ—Ö–∞–≤–µ.  –°–ª–µ–≤–∞ –æ—Ç –Ω–∏—Ö, —á–µ—Ä–µ–∑ –∑–∞–Ω–∞–≤–µ—à–µ–Ω–Ω—ã–π –∞—Ä–æ—á–Ω—ã–π –ø—Ä–æ–µ–º, –Ω–∞—Ö–æ–¥–∏–ª—Å—è –º–∞—Å—Å–∏–≤–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –±–æ–ª—å—à–∏–º–∏ —ç–∫—Ä–∞–Ω–∞–º–∏.  –ò–º–µ–Ω–Ω–æ —Ç—É–¥–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª—è–ª—Å—è –ö—É—Ä—å–µ—Ä.\\n\\n\\n\\n\"–ü—Ä–æ—Å—Ç–æ –¥–∞–π –∑–Ω–∞—Ç—å –æ–¥–Ω–æ–º—É –∏–∑ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤, –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –≤—ã–ø–∏—Ç—å –∏–ª–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ–µ—Å—Ç—å.  –£ –Ω–∞—Å —Ç—É—Ç –µ—Å—Ç—å... –∫–æ–µ-—á—Ç–æ –∏–∑ –≤—Å–µ–≥–æ\".'},\n",
              " {'role': 'user',\n",
              "  'content': '–£—Å–ª—ã—à–∞–≤ –µ–≥–æ —Å–ª–æ–≤–∞, –î–∂–µ—Å—Å–∏–∫–∞ –Ω–µ–º–Ω–æ–≥–æ –Ω–∞—Ö–º—É—Ä–∏–ª–∞ –±—Ä–æ–≤–∏ –≤ –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–µ. –ö—É—Ä—å–µ—Ä —Å–∫—Ä—ã–ª—Å—è –∑–∞ —à—Ç–æ—Ä–∞–º–∏, –∏ –î–∂–µ—Å—Å–∏–∫–∞ —Ä—ã—Å—å—é –±—Ä–æ—Å–∏–ª–∞—Å—å –∑–∞ –Ω–∏–º, —á—Ç–æ–±—ã –¥–æ–≥–Ω–∞—Ç—å. –û–Ω–∞ —Å—Ö–≤–∞—Ç–∏–ª–∞ –µ–≥–æ –∑–∞ –ø—Ä–∞–≤—É—é —Ä—É–∫—É –∏ —Å–ª–µ–≥–∫–∞ –ø–æ—Ç—è–Ω—É–ª–∞, –∑–∞—Å—Ç–∞–≤–∏–≤ –µ–≥–æ –ø–æ–≤–µ—Ä–Ω—É—Ç—å—Å—è —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω —Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –Ω–µ–µ. \"–ü—É—Å—Ç–æ—à—å - –æ–¥–∏–Ω–æ–∫–æ–µ –∏ —É–∂–∞—Å–Ω–æ–µ –º–µ—Å—Ç–æ, - —Ç–∏—Ö–æ —Å–∫–∞–∑–∞–ª–∞ –æ–Ω–∞, - —Ç–µ–±–µ –Ω–µ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –µ–≥–æ —Ö—É–∂–µ –¥–ª—è —Å–µ–±—è. –ù–∏–∫—Ç–æ –Ω–µ –¥–æ–ª–∂–µ–Ω —Å—Ç–∞–ª–∫–∏–≤–∞—Ç—å—Å—è —Å–æ –≤—Å–µ–º —ç—Ç–∏–º –≤ –æ–¥–∏–Ω–æ—á–∫—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–∑–≤–æ–ª—å –º–Ω–µ —Å–¥–µ–ª–∞—Ç—å —á—Ç–æ-—Ç–æ - —á—Ç–æ —É–≥–æ–¥–Ω–æ - —á—Ç–æ–±—ã –æ—Ç–ø–ª–∞—Ç–∏—Ç—å —Ç–µ–±–µ...\", - –æ–Ω–∞ –∑–∞–ø–Ω—É–ª–∞—Å—å –≤ –∫–æ–Ω—Ü–µ –∏ –∑–∞–¥—É–º—á–∏–≤–æ –ø—Ä–∏–∫—É—Å–∏–ª–∞ –Ω–∏–∂–Ω—é—é –≥—É–±—É.\\n\\n\\n\\n–í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω–∞ –±—ã–ª–∞ —Å–ª–∏—à–∫–æ–º –æ—Ç–∫—Ä–æ–≤–µ–Ω–Ω–∞? –≠—Ç–æ –±—ã–ª–∞ –Ω–µ–∏–∑–≤–µ–¥–∞–Ω–Ω–∞—è —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏—è, –∫–æ–≥–¥–∞ –º—É–∂—á–∏–Ω–∞ –Ω–µ —Ö–æ—Ç–µ–ª –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –µ—é –∏–ª–∏ –¥–∞–∂–µ –ø–æ–ª—É—á–∏—Ç—å —Å–≤–æ–π –¥–æ–ª–≥. –û–Ω–∞ –Ω–µ —Ö–æ—Ç–µ–ª–∞, —á—Ç–æ–±—ã –º–µ–∂–¥—É –Ω–∏–º–∏ –æ—Å—Ç–∞–≤–∞–ª—Å—è –∫–∞–∫–æ–π-—Ç–æ –¥–æ–ª–≥, –Ω–æ –Ω–∞—á–∏–Ω–∞–ª–æ –∫–∞–∑–∞—Ç—å—Å—è, —á—Ç–æ –∫—É—Ä—å–µ—Ä –Ω–µ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –ø–æ–∑–≤–æ–ª–∏—Ç—å –µ–π —Ä–∞—Å–ø–ª–∞—Ç–∏—Ç—å—Å—è —Å –Ω–∏–º.'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –ø–æ–≤–µ—Ä–Ω—É–ª—Å—è –∏ –∑–∞–≥–æ–≤–æ—Ä–∏–ª –±—ã—Å—Ç—Ä–æ –∏ —Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ.  –ï–≥–æ –≤–æ–ø—Ä–æ—Å –±—ã–ª –ø–æ—Ö–æ–∂ –Ω–∞ –ø—É–ª—é.  –í—Å–µ —Ç–∞–∫ –∂–µ —Å–ø–æ–∫–æ–π–Ω–æ, –Ω–æ —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –±–æ–ª—å—à–µ –ø–æ–¥—Ö–æ–¥–∏–ª–æ –∫ –µ–≥–æ –≥—Ä—É–±–æ–≤–∞—Ç–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏, —á–µ–º –∫ –µ–≥–æ –æ–±—ã—á–Ω–æ–º—É –≥–æ–ª–æ—Å—É.\\n\\n\\n\\n–û–Ω —Å–ø—Ä–æ—Å–∏–ª –µ–µ: \"–¢—ã –∏—â–µ—à—å, —á—Ç–æ–±—ã —è –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è —Ç–æ–±–æ–π?  –≠—Ç–æ —Ç–æ, —á—Ç–æ —Ç—ã –ø–æ–ª—É—á–∏—à—å –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –º–µ—Å—Ç –ø–æ–±–ª–∏–∑–æ—Å—Ç–∏\".'},\n",
              " {'role': 'user',\n",
              "  'content': '–û—à–µ–ª–æ–º–ª–µ–Ω–Ω–∞—è –µ–≥–æ –≤–Ω–µ–∑–∞–ø–Ω–æ–π —Å–∏–ª–æ–≤–æ–π —Ä–µ–∞–∫—Ü–∏–µ–π, –æ–Ω–∞ –æ—Ç–ø—É—Å–∫–∞–µ—Ç –µ–≥–æ —Ä—É–∫—É –∏, —Å–ø–æ—Ç—ã–∫–∞—è—Å—å, –æ—Ç—Å—Ç—É–ø–∞–µ—Ç –æ—Ç –Ω–µ–≥–æ. \"–Ø... –Ω–µ—Ç, —è –ø—Ä–æ—Å—Ç–æ —Ö–æ—á—É –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Ç–µ–±—è –∑–∞ —Ç–æ, —á—Ç–æ —Ç—ã –ø–æ–º–æ–≥ –º–Ω–µ. –Ø –¥–æ–ª–∂–Ω–∞ —Ö–æ—Ç—è –±—ã –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è, –Ω–µ —Ç–∞–∫ –ª–∏?\"\\n\\n\\n\\n–ï–µ –≥–ª–∞–∑–∞ –Ω–µ–º–Ω–æ–≥–æ —Å–ª–µ–∑—è—Ç—Å—è, –∏ –æ–Ω–∞ —Å–∂–∏–º–∞–µ—Ç –∏—Ö, –∫–∞–∫ –±—ã –Ω–µ –¥–∞–≤–∞—è —Å–ª–µ–∑–∞–º –≤—ã–π—Ç–∏ –Ω–∞—Ä—É–∂—É. –≠—Ç–∞ –ø—Ä–∏–≤—ã—á–∫–∞ —É –Ω–µ–µ —Å –¥–µ—Ç—Å—Ç–≤–∞, –î–∂–µ—Å—Å–∏–∫–∞ –≤—Å–µ–≥–¥–∞ –ø–ª–∞–∫–∞–ª–∞, –∫–æ–≥–¥–∞ –±—ã–ª–∞ —Å–ª–∏—à–∫–æ–º –Ω–∞–ø—Ä—è–∂–µ–Ω–∞ –∏–ª–∏ —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–∞. \"–ù–µ –ø–ª–∞—á—å!\" - –º—ã—Å–ª–µ–Ω–Ω–æ –ø—Ä–∏–∫–∞–∑—ã–≤–∞–µ—Ç –æ–Ω–∞ —Å–µ–±–µ, –Ω–æ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –Ω–∞–ø—Ä–∞—Å–Ω–æ.'},\n",
              " {'role': 'bot',\n",
              "  'content': '–ï–≥–æ –≥–æ–ª–æ—Å —Å–º—è–≥—á–∏–ª—Å—è, –∫–æ–≥–¥–∞ –æ–Ω —É–≤–∏–¥–µ–ª, —á—Ç–æ –æ–Ω–∞ —Ç–∞–∫ –∫—Ä–µ–ø–∫–æ –∑–∞–∫—Ä—ã–ª–∞ –≥–ª–∞–∑–∞.  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª.  \"–°–ª—É—à–∞–π, –º–Ω–µ –æ—á–µ–Ω—å –∂–∞–ª—å.  –Ø –ø—Ä–æ—Å—Ç–æ –Ω–µ –ø—Ä–∏–≤—ã–∫ –∫ —Ç–∞–∫–æ–º—É.  –ú–Ω–µ –Ω–∏—á–µ–≥–æ –æ—Ç —Ç–µ–±—è –Ω–µ –Ω—É–∂–Ω–æ, –î–∂–µ—Å—Å–∏–∫–∞... –æ–≥–ª—è–Ω–∏—Å—å –≤–æ–∫—Ä—É–≥.  –£ –º–µ–Ω—è –µ—Å—Ç—å –≤—Å–µ, —á—Ç–æ –º–Ω–µ –Ω—É–∂–Ω–æ, —ç—Ç–æ...\"\\n\\n\\n\\n–û–Ω –ø–æ–∫–∞—á–∞–ª –≥–æ–ª–æ–≤–æ–π, –≤—ã–≥–ª—è–¥—è –≤–Ω–µ–∑–∞–ø–Ω–æ –ø–æ–±–µ–∂–¥–µ–Ω–Ω—ã–º.  –°–¥–µ–ª–∞–≤ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∂–µ—Å—Ç –≤ —Å—Ç–æ—Ä–æ–Ω—É –æ–∫–Ω–∞, –æ–Ω –∑–∞–≥–æ–≤–æ—Ä–∏–ª –≥–æ—Ä–∞–∑–¥–æ —Ç–∏—à–µ.  \"–≠—Ç–æ –ª—é–¥–∏ —Ç–∞–º, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Ö –Ω–µ—Ç.  –Ø –ø—ã—Ç–∞—é—Å—å —Å–¥–µ–ª–∞—Ç—å –≤—Å–µ, —á—Ç–æ –≤ –º–æ–∏—Ö —Å–∏–ª–∞—Ö, –Ω–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫ –ø—Ä–æ—Å—Ç–æ, –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–¥–∞—Ç—å –≤–µ—â–∏.  –≠—Ç–æ –∏–º –Ω—É–∂–Ω–∞ —Ç–≤–æ—è —Ç—è–∂–µ–ª–∞—è —Ä–∞–±–æ—Ç–∞, –∞ –Ω–µ –º–Ω–µ.  –Ø –ø—Ä–æ—Å—Ç–æ —Å—Ç–∞—Ä–∞—é—Å—å –¥–µ–ª–∞—Ç—å —Ç–æ, —á—Ç–æ –º–æ–≥—É, —á–µ–≥–æ –Ω–µ —Å–¥–µ–ª–∞–µ—Ç –∫—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–π\".'},\n",
              " {'role': 'user',\n",
              "  'content': '–û–Ω–∞ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –≥–ª–∞–∑–∞, –∏ —Å–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Å–ª–µ–∑—ã –≤—ã—Ä—ã–≤–∞—é—Ç—Å—è –Ω–∞—Ä—É–∂—É, —Ä–∞–∑–ª–∏–≤–∞—è—Å—å –ø–æ —â–µ–∫–∞–º. –û–Ω–∞ —É–∂–µ –Ω–µ –ø–ª–∞—á–µ—Ç, –Ω–æ –ø—Ä–µ–¥–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–ª–µ–∑—ã –Ω–µ —É—Ç–∏—Ö–∞—é—Ç. \"–ü—Ä–æ—Å—Ç–∏, —á—Ç–æ –±—ã–ª–∞ —Ç–∞–∫–æ–π –Ω–∞—Å—Ç–æ–π—á–∏–≤–æ–π, - –±–æ—Ä–º–æ—á–µ—Ç –æ–Ω–∞, - —è –ø—Ä–æ—Å—Ç–æ —Ö–æ—Ç–µ–ª–∞ –æ—Ç–ø–ª–∞—Ç–∏—Ç—å –∑–∞ —Ç–≤–æ—é –¥–æ–±—Ä–æ—Ç—É. –¢—ã –º–Ω–æ–≥–æ–µ —Å–¥–µ–ª–∞–ª –¥–ª—è –ù—å—é-–í–µ–≥–∞—Å–∞ –∏ –µ–≥–æ –∂–∏—Ç–µ–ª–µ–π, —è –º–æ–≥—É —Å–∫–∞–∑–∞—Ç—å. –¢—ã –Ω–µ –¥–æ–ª–∂–µ–Ω –Ω–æ—Å–∏—Ç—å –≤ —Å–µ–±–µ —Å—Ç–æ–ª—å–∫–æ —á—É–≤—Å—Ç–≤–∞ –≤–∏–Ω—ã! –≠—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–¥–æ—Ä–æ–≤—ã–º\".'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –≥–ª—É–±–æ–∫–æ –≤–¥–æ—Ö–Ω—É–ª, –∫–æ–≥–¥–∞ —É–≤–∏–¥–µ–ª, —á—Ç–æ –æ–Ω–∞ –ø–ª–∞—á–µ—Ç, –∏ –Ω–∞ –º–≥–Ω–æ–≤–µ–Ω–∏–µ –æ—Ç–≤–µ—Ä–Ω—É–ª –≥–æ–ª–æ–≤—É.  –ö–æ–≥–¥–∞ –æ–Ω —Å–Ω–æ–≤–∞ –∑–∞–≥–æ–≤–æ—Ä–∏–ª, –µ–≥–æ –≥–æ–ª–æ—Å —Å–Ω–æ–≤–∞ –±—ã–ª –±–æ–ª–µ–µ —Ä–æ–≤–Ω—ã–º.  \"–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ, —á—Ç–æ —è –º–æ–≥—É —Å–¥–µ–ª–∞—Ç—å, - —ç—Ç–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ú–æ—Ö–∞–≤–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–º, –∏ —É–ø—Ä–∞–≤–ª—è—Ç—å –∏–º –∫–∞–∫ –º–æ–∂–Ω–æ –ª—É—á—à–µ.  –Ø –º–æ–≥—É –∏ –±—É–¥—É –ª–∏—á–Ω–æ —Ä–µ—à–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –∫–æ–≥–¥–∞ —Å–º–æ–≥—É... –∏ —è –∏—Ö —Ä–µ—à–∞–ª.  –•–æ—Ç—è –º–Ω–µ –ª—é–±–æ–ø—ã—Ç–Ω–æ...\"  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª, –ø–æ–Ω–∏–º–∞—è, —á—Ç–æ —Å–µ–π—á–∞—Å –ø–æ–∂–∞–ª–µ–µ—Ç –æ —Ç–æ–º, —á—Ç–æ —Å–ø—Ä–æ—Å–∏–ª: \"–¢—ã —Å–∫–∞–∑–∞–ª, —á—Ç–æ –õ–µ–≥–∏–æ–Ω –Ω–∞–ø–∞–ª –Ω–∞ —Ç–≤–æ—é –¥–µ—Ä–µ–≤–Ω—é –∏–ª–∏ –≥–æ—Ä–æ–¥.  –ö–æ–≥–¥–∞ —ç—Ç–æ –±—ã–ª–æ?  –ü–æ—Å–ª–µ —Å–º–µ—Ä—Ç–∏ –¶–µ–∑–∞—Ä—è –∏ –õ–∞–Ω–∏—è –º–Ω–µ –≤—Å–µ–≥–¥–∞ –±—ã–ª–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ —Å –Ω–∏–º–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç.  –ò—Ö –≤—Å–µ–≥–¥–∞ —É–¥–µ—Ä–∂–∏–≤–∞–ª–∞ –≤–º–µ—Å—Ç–µ —Ö–∞—Ä–∏–∑–º–∞ –¶–µ–∑–∞—Ä—è\".'},\n",
              " {'role': 'user',\n",
              "  'content': '\"–ù–∞–ø–∞–¥–µ–Ω–∏–µ –õ–µ–≥–∏–æ–Ω–∞ –±—ã–ª–æ –ø–æ—á—Ç–∏ –≥–æ–¥ –Ω–∞–∑–∞–¥, - —Å–∫–∞–∑–∞–ª–∞ –æ–Ω–∞, –≤—Å–µ –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–æ–∫–æ–µ–Ω–Ω–∞—è –æ–±—Ä–∞–∑–∞–º–∏, –≤–ø–µ—á–∞—Ç–∞–Ω–Ω—ã–º–∏ –≤ –µ–µ —Å–æ–∑–Ω–∞–Ω–∏–µ, - –≠—Ç–æ –±—ã–ª–æ... —É–∂–∞—Å–Ω–æ. –ö–∞–∫ –±—É–¥—Ç–æ –≤–µ—Å—å –º–∏—Ä –≤–Ω–µ–∑–∞–ø–Ω–æ –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª—Å—è –≤ –∞–¥: –æ–≥–æ–Ω—å, —à—Ç–∞–±–µ–ª—è —Ç—Ä—É–ø–æ–≤ –∏... –ª—é–¥–∏, –ø—Ä–∏–±–∏—Ç—ã–µ –∫ –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–º –∫—Ä–µ—Å—Ç–∞–º...\"\\n\\n\\n\\n–û–Ω–∞ –≤–∑–¥—Ä–∞–≥–∏–≤–∞–µ—Ç –æ—Ç –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏ –ø–æ–¥–Ω–∏–º–∞–µ—Ç –Ω–∞ –Ω–µ–≥–æ –≥–ª–∞–∑–∞. \"–Ø –Ω–µ –∑–Ω–∞—é —Ç–æ—á–Ω–æ, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å –õ–µ–≥–∏–æ–Ω–æ–º –≤ —Ü–µ–ª–æ–º, –Ω–æ —ç—Ç–æ –±—ã–ª–∞ –¥–æ–≤–æ–ª—å–Ω–æ –±–æ–ª—å—à–∞—è –≥—Ä—É–ø–ø–∞, –¥–µ—Ä–∂–∞–≤—à–∞—è –ª–∞–≥–µ—Ä—å –Ω–µ —Ç–∞–∫ —É–∂ –¥–∞–ª–µ–∫–æ –æ—Ç –ù—å—é-–í–µ–≥–∞—Å–∞.'},\n",
              " {'role': 'bot',\n",
              "  'content': '\"–ú–Ω–µ –∂–∞–ª—å, —á—Ç–æ —ç—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å... –Ω–æ... –≤–æ–∑–º–æ–∂–Ω–æ, —Ç—ã –±—É–¥–µ—à—å —Ä–∞–¥ —É–∑–Ω–∞—Ç—å, —á—Ç–æ —á–µ–ª–æ–≤–µ–∫, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞ –≤—Å–µ —ç—Ç–∏ –∑–∞–≤–æ–µ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–∞–º–ø–∞–Ω–∏–∏, –º–µ—Ä—Ç–≤\".  –û–Ω –∫–∏–≤–Ω—É–ª, –ø–æ–ª–æ–∂–∏–≤ —Ä—É–∫—É –µ–π –Ω–∞ –ø–ª–µ—á–æ.  \"–õ–µ–≥–∏–æ–Ω —Ç–≤–æ—Ä–∏–ª —É–∂–∞—Å–Ω—ã–µ –≤–µ—â–∏ –ø–æ –≤—Å–µ–º—É... —á–µ—Ä—Ç, –¥–∞ –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ –∫ –≤–æ—Å—Ç–æ–∫—É –æ—Ç—Å—é–¥–∞\".  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª.  \"NCR, –Ω—É... –æ–Ω–∏ –∫—Ä–∞–¥—É—Ç –≤–µ—â–∏ –Ω–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –∏ –º–µ–Ω–µ–µ –∂–µ—Å—Ç–æ–∫–æ.  –ù–æ –ª—é–¥–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ —Ç–µ—Ä—è—é—Ç —Ç–æ, —á—Ç–æ —É –Ω–∏—Ö –µ—Å—Ç—å\".'},\n",
              " {'role': 'user',\n",
              "  'content': '\"NCR? –ú–Ω–µ... –∫–∞–∂–µ—Ç—Å—è, –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ –Ω–∞—Å –∑–∞—â–∏—â–∞—Ç—å\", - –≥–æ–≤–æ—Ä–∏—Ç –æ–Ω–∞, –Ω–∞—Ö–º—É—Ä–∏–≤ –±—Ä–æ–≤–∏ –∏ –∑–∞–¥—É–º—á–∏–≤–æ –ø–æ–∫—É—Å—ã–≤–∞—è –Ω–∏–∂–Ω—é—é –≥—É–±—É, - \"–ù–æ... –æ–Ω–∏ —Ç–∞–∫ –∏ –Ω–µ –ø—Ä–∏—à–ª–∏\".\\n\\n\\n\\n–ï–µ –∑–Ω–∞–Ω–∏—è –æ –¥–≤—É—Ö —Ñ—Ä–∞–∫—Ü–∏—è—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã, —Ç–∞–∫ –∫–∞–∫ –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –∂–∏–∑–Ω–∏ –æ–Ω–∞ –ø—Ä–æ–∂–∏–ª–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ, –Ω–æ —É –Ω–µ–µ —É–∂–µ —Å–ª–æ–∂–∏–ª–æ—Å—å –∫—Ä–∞–π–Ω–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –º–Ω–µ–Ω–∏–µ –æ –Ω–∏—Ö.'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –Ω–µ–µ –∏ –ø–æ–¥–Ω—è–ª —Ä—É–∫—É, —Å–Ω–∏–º–∞—è —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏.  –ü–æ–¥ –Ω–∏–º–∏ –±—ã–ª–∏ –≥–ª–∞–∑–∞, –∫–æ—Ç–æ—Ä—ã–µ\\n–∏–∑–º—É—á–µ–Ω–Ω—ã–µ\\n.  –ü–æ–¥ –Ω–∏–º–∏ –±—ã–ª–∏ —á–µ—Ä–Ω—ã–µ –º–µ—à–∫–∏, –∏ –æ–Ω–∏ —Å–ª–µ–≥–∫–∞ –Ω–∞–ª–∏–ª–∏—Å—å –∫—Ä–æ–≤—å—é.  –ó–∞ –≤—Å–µ–º —ç—Ç–∏–º –±—ã–ª–æ –≤–∏–¥–Ω–æ, —á—Ç–æ —É –Ω–µ–≥–æ –ø–æ—Ç—Ä—è—Å–∞—é—â–∏–µ —è—Ä–∫–æ-–≥–æ–ª—É–±—ã–µ –≥–ª–∞–∑–∞, –≤–∑–≥–ª—è–¥ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª –æ—á–µ–Ω—å –º—è–≥–∫–∏–º –∏ –¥–æ–±—Ä—ã–º.  –ù–∞–∫–æ–Ω–µ—Ü –æ–Ω –ø–æ–ª–æ–∂–∏–ª –≤–∏–Ω—Ç–æ–≤–∫—É –Ω–∞ —Å—Ç–æ–ª —Ä—è–¥–æ–º —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º–∏.\\n\\n\\n\\r\\n\"–î–∂–µ—Å—Å–∏–∫–∞, —è –±–µ—Å–ø–æ–∫–æ—é—Å—å –æ —Å—Ç–æ–ª—å–∫–∏—Ö –≤–µ—â–∞—Ö –≤ —ç—Ç–æ–º –º–µ—Å—Ç–µ, –∏ —è –Ω–µ... –£ –º–µ–Ω—è –Ω–µ –±—ã–ª–æ...\"  –û–Ω –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –∏ –ø–æ–∫–∞—á–∞–ª –≥–æ–ª–æ–≤–æ–π.  \"–ù–µ—Ç, –∏–∑–≤–∏–Ω–∏, –Ω–µ –±–µ—Ä–∏ –≤ –≥–æ–ª–æ–≤—É\".'},\n",
              " {'role': 'user',\n",
              "  'content': '–ù–µ–∂–Ω–æ —É–ª—ã–±–Ω—É–≤—à–∏—Å—å, –î–∂–µ—Å—Å–∏–∫–∞ —Å–æ–∫—Ä–∞—Ç–∏–ª–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –Ω–∏–º–∏. –û–Ω–∞ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ –ø–æ–ª–æ–∂–∏–ª–∞ —Ä—É–∫—É –µ–º—É –Ω–∞ –≥—Ä—É–¥—å –∏ —Å–∫–∞–∑–∞–ª–∞: \"–î–∞–≤–∞–π, —Ä–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ. –ß—Ç–æ —è –º–æ–≥—É –¥–ª—è —Ç–µ–±—è —Å–¥–µ–ª–∞—Ç—å?\"'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –Ω–µ–Ω–∞–¥–æ–ª–≥–æ –∑–∞–∫—Ä—ã–ª –≥–ª–∞–∑–∞ –∏ –ø—Ä–æ–º—É—Ä–ª—ã–∫–∞–ª: \"–Ø –Ω–µ –±—ã–ª —Å –∂–µ–Ω—â–∏–Ω–æ–π —É–∂–µ... –æ—á–µ–Ω—å –¥–∞–≤–Ω–æ.  –Ø –æ—Ç–∫–∞–∑—ã–≤–∞—é—Å—å –ø–ª–∞—Ç–∏—Ç—å –∑–∞ —ç—Ç–æ, —Ç–∞–∫ –∫–∞–∫, –Ω—É, —ç—Ç–æ –≤—Å–µ –µ—â–µ –æ–ø–∞—Å–Ω–æ.  –Ø –Ω–µ –±—É–¥—É –º–µ—à–∞—Ç—å –∂–µ–Ω—â–∏–Ω–∞–º –¥–µ–ª–∞—Ç—å —ç—Ç–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –∏—Ö –∂–∏–∑–Ω—å, –Ω–æ... –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ\".  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª, –ø–æ–Ω–∏–º–∞—è, —á—Ç–æ –±–æ—Ä–º–æ—á–µ—Ç.  \"–Ø –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–ª, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ —Ç–∞–∫ –∂–µ –ø–ª–æ—Ö–æ.  –ü–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–µ–º, —á—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ –æ—Ç–ø–ª–∞—Ç–∏—Ç—å –º–Ω–µ, –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ, –∏ —è –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–æ—Å–∏—Ç—å.  –≠—Ç–æ –±—ã–ª –ø—Ä–æ—Å—Ç–æ... –º–∏–Ω—É—Ç–Ω—ã–π –ø—Ä–æ–º–∞—Ö –æ—Ç —Ç–æ–≥–æ, —á—Ç–æ —è –±—ã–ª –Ω–µ–º–Ω–æ–≥–æ –æ–±–¥–µ–ª–µ–Ω\".  –û–Ω —Å–ª–µ–≥–∫–∞ —É–ª—ã–±–Ω—É–ª—Å—è, –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –≤—ã–≥–ª—è–¥—è –Ω–µ–º–Ω–æ–≥–æ —Å–º—É—â–µ–Ω–Ω—ã–º.'},\n",
              " {'role': 'user',\n",
              "  'content': '\"–ß—Ç–æ –∂, - –¥—É–º–∞–µ—Ç –æ–Ω–∞ –ø—Ä–æ —Å–µ–±—è, - –Ω–µ —Ç–æ —á—Ç–æ–±—ã —è —ç—Ç–æ–≥–æ –Ω–µ –ø—Ä–µ–¥–≤–∏–¥–µ–ª–∞\".\\n\\n\\n\\n–î–∂–µ—Å—Å–∏–∫–∞ –Ω–∞–∫–ª–æ–Ω—è–µ—Ç—Å—è –∏ –º—è–≥–∫–æ —Ü–µ–ª—É–µ—Ç –µ–≥–æ –≤ –≥—É–±—ã, –ø–æ—Å–ª–µ —á–µ–≥–æ –æ—Ç—Å—Ç—É–ø–∞–µ—Ç, –Ω–∞–±–ª—é–¥–∞—è –∑–∞ –µ–≥–æ —Ä–µ–∞–∫—Ü–∏–µ–π. \"–¢—ã –Ω–µ –ø–æ–ª—å–∑—É–µ—à—å—Å—è –º–Ω–æ–π, —Ç–µ–±–µ –Ω–µ –Ω—É–∂–Ω–æ –ø–ª–∞—Ç–∏—Ç—å –∏ –¥–∞–∂–µ –Ω–µ –Ω—É–∂–Ω–æ –ø—Ä–æ—Å–∏—Ç—å. –ü—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–π —Ç–æ, —á—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç —Å–∞–º–æ —Å–æ–±–æ–π...\", - –æ–Ω–∞ –æ—Ç—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è, –Ω–∞ –µ–µ –ª–∏—Ü–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è —É–ª—ã–±–∫–∞.'},\n",
              " {'role': 'bot',\n",
              "  'content': '–û–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª –≤ –µ–µ –≥–ª–∞–∑–∞, –∏ –≤–∑–≥–ª—è–¥ –µ–≥–æ –±—ã–ª –¥–∞–ª–µ–∫–∏–º, –ø–µ—á–∞–ª—å–Ω—ã–º.  –ó–∞—Ç–µ–º –æ–Ω —É–ª—ã–±–Ω—É–ª—Å—è, –µ–¥–≤–∞ –∑–∞–º–µ—Ç–Ω–æ, –∫–æ–≥–¥–∞ –µ–≥–æ —Ä—É–∫–∏ —É—Ö–≤–∞—Ç–∏–ª–∏—Å—å –∑–∞ –µ–µ –∑–∞–ø—è—Å—Ç—å—è –∏ –ø—Ä–∏—Ç—è–Ω—É–ª–∏ –µ–µ –±–ª–∏–∂–µ –∫ —Å–µ–±–µ.  –ë—ã–ª–æ –Ω–µ–æ—Å–ø–æ—Ä–∏–º–æ, —á—Ç–æ –æ–Ω —Ö–æ—á–µ—Ç –µ–µ, —á—Ç–æ –æ–Ω —Ö–æ—á–µ—Ç —Å–µ–∫—Å–∞, –∏ —á—Ç–æ –ø—Ä–æ—à–ª–∞ —Ü–µ–ª–∞—è –≤–µ—á–Ω–æ—Å—Ç—å —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫ –æ–Ω –¥–µ–ª–∞–ª —ç—Ç–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑.  –°–¥–µ–ª–∞–≤ —à–∞–≥ –≤–ø–µ—Ä–µ–¥, –æ–Ω —Ç–æ–ª–∫–Ω—É–ª –µ–µ —Ç–∞–∫, —á—Ç–æ –∑–∞–¥–Ω–∏–µ —á–∞—Å—Ç–∏ –µ–µ –±–µ–¥–µ—Ä –∫–æ—Å–Ω—É–ª–∏—Å—å –ø—É—Å—Ç–æ–≥–æ —Å—Ç–æ–ª–∞.  –ï–≥–æ –≥–ª–∞–∑–∞ —Å–º–æ—Ç—Ä–µ–ª–∏ –Ω–∞ –Ω–µ–µ —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑, –∞ —Ä—É–∫–∏ —Å–∫–æ–ª—å–∑–∏–ª–∏ –≤–≤–µ—Ä—Ö –ø–æ –µ–µ —Ä—É–∫–∞–º.\\n\\n\\n\\n\"–Ø –º–æ–≥—É –±—ã—Ç—å –Ω–µ–º–Ω–æ–≥–æ –≥—Ä—É–±—ã–º\", - –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏–ª –æ–Ω.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "dataset[5][\"conv\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfzTdMtvGE6w"
      },
      "source": [
        "And we see how the chat template transformed these conversations.\n",
        "\n",
        "**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "d2e38e80-db0a-40c3-fe7d-192022c0c9bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n((ooc: –Ω–∞–∂–º–∏ –Ω–∞ —Ö–æ—Ç–ª–∏–Ω–∫–∏, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Ç–æ–≥–æ, —á—Ç–æ –Ω–æ—Å–∏—Ç/–¥–µ—Ä–∂–∏—Ç –ö—É—Ä—å–µ—Ä ^_^))\\n\\n\\n\\r\\n–§—Ä–∏—Å–∞–π–¥ –±—ã–ª —Ç–∞–∫–∏–º –∂–µ, –∫–∞–∫ –∏ –ø–æ—Å–ª–µ –ø–æ–±–µ–¥—ã –ö—É—Ä—å–µ—Ä–∞ –ø–æ—á—Ç–∏ –º–µ—Å—è—Ü –Ω–∞–∑–∞–¥.  –õ—é–¥–µ–π —Å—Ç–∞–ª–æ –±–æ–ª—å—à–µ, –∏ –æ–Ω–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –≤—ã–≥–ª—è–¥–µ–ª–∏ –∑–¥–æ—Ä–æ–≤–µ–µ.  –†–∞–∑–ª–∏—á–∏—è –±—ã–ª–∏ —á—É—Ç—å –±–æ–ª–µ–µ —Ç–æ–Ω–∫–∏–º–∏: –∑–¥–∞–Ω–∏—è –≤—ã–≥–ª—è–¥–µ–ª–∏ —á—É—Ç—å —á–∏—â–µ, –ª—é–¥–∏ –Ω–æ—Å–∏–ª–∏ –±–æ–ª–µ–µ –∫—Ä–∞—Å–∏–≤—É—é –æ–¥–µ–∂–¥—É.  –¢—Ä—É–ø—ã –±—ã–ª–∏ —É–±—Ä–∞–Ω—ã.  –î–∞–∂–µ –≤ –°—Ç–∞—Ä–æ–º –º–æ—Ä–º–æ–Ω—Å–∫–æ–º —Ñ–æ—Ä—Ç–µ —Ç–µ–ø–µ—Ä—å –±—ã–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–µ –ø–æ—Å—Ç—Ä–æ–π–∫–∏.  –û–Ω–∏ –≤—Å–µ –µ—â–µ –±—ã–ª–∏ –¥–æ–≤–æ–ª—å–Ω–æ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–º–∏, –Ω–æ —Ç–µ–ø–µ—Ä—å –æ–Ω–∏ –º–æ–≥–ª–∏ –ø—Ä–∏–≤–æ–∑–∏—Ç—å —Ç—É–¥–∞ –±–æ–ª—å—à–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ç–µ—Ö–Ω–∏–∫–∏ –∏ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤, –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –∏–º —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å –ø–æ—Ç–æ–∫–æ–º —Ä–∞–Ω–µ–Ω—ã—Ö –ø–æ—Å–ª–µ –í—Ç–æ—Ä–æ–π –±–∏—Ç–≤—ã –∑–∞ –¥–∞–º–±—É –ì—É–≤–µ—Ä–∞.\\n\\n\\n\\r\\n–í–æ—Ç –æ–Ω —à–µ–ª –ø–æ —Ü–µ–Ω—Ç—Ä—É –§—Ä–∏—Å–∞–π–¥–∞, –æ–¥–µ—Ç—ã–π –≤ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π\\n–ø—ã–ª—å–Ω–∏–∫\\n –≤ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–π –æ–¥–µ–∂–¥–µ.  –£ –Ω–µ–≥–æ –±—ã–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–µ, –Ω–µ–∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ —á–µ—Ä–Ω—ã–µ –≤–æ–ª–æ—Å—ã –∏ –≥—É—Å—Ç–∞—è –∫–æ–∑–ª–∏–Ω–∞—è –±–æ—Ä–æ–¥–∫–∞.  –í —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å –µ–≥–æ\\n—Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–º–∏ –æ—á–∫–∞–º–∏\\n –∏\\n–±–∞–Ω–¥–∞–Ω–æ–π\\n–æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –≤—ã–¥–µ–ª—è–ª—Å—è —Å—Ä–µ–¥–∏ –±–µ–¥–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π.  –ï–≥–æ —É–≤–µ—Ä–µ–Ω–Ω–∞—è –ø–æ—Ö–æ–¥–∫–∞, —Ü–µ–ª–µ—É—Å—Ç—Ä–µ–º–ª–µ–Ω–Ω–æ—Å—Ç—å, —Å –∫–æ—Ç–æ—Ä–æ–π –æ–Ω –¥–≤–∏–≥–∞–ª—Å—è, –∏ –æ—Ç–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —á–µ—Ä–Ω–∞—è\\n—à—Ç—É—Ä–º–æ–≤–∞—è –≤–∏–Ω—Ç–æ–≤–∫–∞\\n (—Å –ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–≤–æ–ª–æ–º –∏–∑ —Å–µ—Ä–µ–±—Ä–∏—Å—Ç–æ–≥–æ –º–µ—Ç–∞–ª–ª–∞) –ø—Ä–∏–¥–∞–≤–∞–ª–∏ –µ–º—É –≤–ª–∞—Å—Ç–Ω—ã–π –≤–∏–¥.  –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª–∏ –µ–≥–æ, —Ö–æ—Ç—è –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞–ª–∏ –ø–∞–ª—å—Ü–µ–º –∏ –ø–µ—Ä–µ—à–µ–ø—Ç—ã–≤–∞–ª–∏—Å—å –Ω–∞ —Ç–∏—Ö–∏—Ö —Ç–æ–Ω–∞—Ö, –∫–æ–≥–¥–∞ –æ–Ω –ø—Ä–æ—Ö–æ–¥–∏–ª –º–∏–º–æ.  –ö–∞–∑–∞–ª–æ—Å—å, –æ–Ω –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –æ–ø–∏—Å–∞–Ω–∏—è–º –ø—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ –∏ –≥–æ—Ä–æ–∂–∞–Ω, \"–ö—É—Ä—å–µ—Ä–∞ –®–µ—Å—Ç—å\", –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –∏–º–µ–Ω–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ, –ø–æ—Ö–æ–∂–µ, –Ω–∏–∫—Ç–æ –Ω–µ –∑–Ω–∞–ª.  –û–Ω –¥–æ–ª–∂–µ–Ω –±—ã–ª –±—ã—Ç—å –¥–æ–±—Ä—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º, –∞... –Ω—É, —ç—Ç–æ—Ç —á–µ–ª–æ–≤–µ–∫ –≤—ã–≥–ª—è–¥–µ–ª –æ–ø–∞—Å–Ω—ã–º.  –ú–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å, –∫—Ä—É—Ç—ã–º, –∫–æ–≥–¥–∞ –æ–Ω –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞–ª —É–ª–∏—Ü—ã.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–ü–æ—Å–ª–µ –ø–æ–±–µ–≥–∞ –î–∂–µ—Å—Å–∏–∫–∞ –ø–æ–Ω—è–ª–∞, —á—Ç–æ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –º–µ—Å—Ç–æ, –∫—É–¥–∞ –æ–Ω–∞ –º–æ–∂–µ—Ç –ø–æ–π—Ç–∏ –∏ –Ω–∞–π—Ç–∏ —Ö–æ—Ç—å –∫–∞–∫—É—é-—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ù—å—é-–í–µ–≥–∞—Å. –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞—â–∏—â–µ–Ω–Ω—ã–π –∑–∞–≥–∞–¥–æ—á–Ω—ã–º \"–ö—É—Ä—å–µ—Ä–æ–º\" –∏ –µ–≥–æ –∞—Ä–º–∏–µ–π —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤, –æ–Ω –±—ã–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –õ–µ–≥–∏–æ–Ω–∞ –¶–µ–∑–∞—Ä–µ–π, –≥—Ä—É–ø–ø—ã, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ä–∞–±–æ—Ç–∏–ª–∞ –µ–µ –ø–æ—á—Ç–∏ –Ω–∞ –≥–æ–¥.\\n\\n\\n\\r\\n–£ –Ω–µ–µ –Ω–µ –±—ã–ª–æ –∫—Ä—ã—à–µ–∫, —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ –°—Ç—Ä–∏–ø. –≠—Ç–æ —É–∂ —Ç–æ—á–Ω–æ. –°–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω—ã —Å—Ä–∞–∑—É –∂–µ –æ—Ç–≤–µ—Ä–≥–ª–∏ –µ–µ. –û–¥–Ω–∞–∫–æ –¥–æ –Ω–µ–µ –¥–æ—Ö–æ–¥–∏–ª–∏ —Å–ª—É—Ö–∏ –æ –¥–æ–±—Ä–æ—Å–µ—Ä–¥–µ—á–Ω–æ–º –ö—É—Ä—å–µ—Ä–µ –∏ –µ–≥–æ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞—Ç—å –ì–æ—Ä–æ–¥ - –¥–∞–∂–µ —Ç—Ä—É—â–æ–±—ã –§—Ä–∏—Å–∞–π–¥–∞.\\n\\n\\n\\r\\n–ù–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –î–∂–µ—Å—Å–∏–∫–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –∏ –≤—ã–∂–∏–≤–∞–ª–∞ –≤–æ –§—Ä–∏—Å–∞–π–¥–µ, –¥–µ–ª–∞—è –≤—Å–µ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ç—å –∫–∞–∫—É—é-—Ç–æ –∫—Ä—ã—à–∫—É –∏–ª–∏ –¥–∞–∂–µ –≥–æ—Ä—è—á—É—é –µ–¥—É. –ü—Ä–∏ —ç—Ç–æ–º –æ–Ω–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —Å–ª–µ–¥–∏–ª–∞ –∑–∞ –Ω–æ–≤–æ—Å—Ç—è–º–∏ –æ —Å–≤–æ–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–º —Å–ø–∞—Å–∏—Ç–µ–ª–µ. –£–¥–∞—á–∞ –±—ã–ª–∞ –Ω–∞ –µ–µ —Å—Ç–æ—Ä–æ–Ω–µ, —Ç–∞–∫ –∫–∞–∫ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏–ª—Å—è —Å–ª—É—Ö, —á—Ç–æ –ö—É—Ä—å–µ—Ä –Ω–∞ —Å–≤–æ–±–æ–¥–µ –∏ –æ—Ö—Ä–∞–Ω—è–µ—Ç —É–ª–∏—Ü—ã –§—Ä–∏—Å–∞–π–¥–∞. –û–Ω–∞ –≤—ã–ª–µ—Ç–µ–ª–∞ –∏–∑ –∑–∞—Ö—É–¥–∞–ª–æ–≥–æ –±–∞—Ä–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º —á–∞—Å—Ç–æ –±—ã–≤–∞–ª–∞, –Ω–∞ –ø–æ–∏—Å–∫–∏ –ö—É—Ä—å–µ—Ä–∞.\\n\\n\\n\\r\\n–ï–≥–æ —Ü–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –∏ –ø–æ—á—Ç–µ–Ω–∏–µ, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—Å–µ –∫ –Ω–µ–º—É –æ—Ç–Ω–æ—Å–∏–ª–∏—Å—å, –Ω–µ –æ—Å—Ç–∞–≤–ª—è–ª–∏ —Å–æ–º–Ω–µ–Ω–∏–π –≤ —Ç–æ–º, —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –æ–¥–µ—Ç—ã–π –∏ –≤–æ–æ—Ä—É–∂–µ–Ω–Ω—ã–π –¥–∂–µ–Ω—Ç–ª—å–º–µ–Ω, –ø—Ä–æ–≥—É–ª–∏–≤–∞—é—â–∏–π—Å—è –ø–æ —É–ª–∏—Ü–µ, –∏ –µ—Å—Ç—å —Ç–æ—Ç —Å–∞–º—ã–π —Ç–∞–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–Ω–∞ –∏—Å–∫–∞–ª–∞. –£—Å–ø–æ–∫–æ–∏—Ç–µ–ª—å–Ω–æ –≤–∑–¥–æ—Ö–Ω—É–≤, –æ–Ω–∞ –ø–æ–¥–±–µ–∂–∞–ª–∞ –∫ –Ω–µ–º—É, –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞—è –ø—Ä–æ–∏–∑–Ω–µ—Å—Ç–∏ —É–∂–µ –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—É—é —Ä–µ—á—å, –∏–∑–ª–∞–≥–∞—è –ª–æ–≥–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ —Ç–æ–º, –∫–∞–∫ –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –µ–º—É –ø–æ–ª–µ–∑–Ω–∞, –µ—Å–ª–∏ –æ–Ω –ø–æ–∑–≤–æ–ª–∏—Ç –µ–π –æ—Å—Ç–∞—Ç—å—Å—è –≤ –°—Ç—Ä–∏–ø–µ, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –µ–µ –±–µ–¥–Ω–æ—Å—Ç—å. –û–¥–Ω–∞–∫–æ, –∫ –µ–µ —É–∂–∞—Å—É, –∫–æ–≥–¥–∞ –æ–Ω–∞ –æ—Ç–∫—Ä—ã–ª–∞ —Ä–æ—Ç, —Ç–æ –≤—ã—Ä–≤–∞–ª–æ—Å—å —Å–ª–µ–¥—É—é—â–µ–µ: \"–ò—â–µ—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ö–æ—Ä–æ—à–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –≤—Ä–µ–º—è —Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º, —Å—ç—Ä?\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ö—É—Ä—å–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –Ω–µ–µ.  –ë–æ–ª—å—à–∏–µ —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏ –¥–µ–ª–∞–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –µ–≥–æ –ª–∏—Ü–∞ –Ω–µ–∑–∞–º–µ—Ç–Ω—ã–º, –Ω–æ –Ω–µ–±–æ–ª—å—à–∞—è —É–ª—ã–±–∫–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ—è–≤–∏–ª–∞—Å—å –Ω–∞ –µ–≥–æ –ª–∏—Ü–µ.\\n\\n\\n\\r\\n\"–°–ø–∞—Å–∏–±–æ, –º–∏—Å—Å, –Ω–æ —Å–µ–≥–æ–¥–Ω—è –º–Ω–µ –Ω–∏—á–µ–≥–æ —Ç–∞–∫–æ–≥–æ –Ω–µ –Ω—É–∂–Ω–æ\".  –ì–æ–ª–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –∏—Å—Ö–æ–¥–∏–ª –æ—Ç –Ω–µ–≥–æ, –±—ã–ª —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ —Ç–∞–∫–∏–º, –∫–∞–∫ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å –ø–æ –µ–≥–æ –æ–±—Ä–∞–∑—É: –æ–Ω –±—ã–ª —Å–ø–æ–∫–æ–π–Ω—ã–º, –¥–æ–±—Ä—ã–º –∏ –º—è–≥–∫–∏–º, –∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –µ–≥–æ –∫—É–¥–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–û–Ω–∞ –ø–æ–¥–∞–≤–∏–ª–∞ –≤–∑–¥–æ—Ö –æ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∞—Å—å –Ω–∞ –≥–ª—É–±–æ–∫–æ–º —Ä—É–º—è–Ω—Ü–µ. –ó–∞–∫—Ä—ã–≤ –≥–ª–∞–∑–∞ –∏ —Ç—Ä—è—Ö–Ω—É–≤ –≥–æ–ª–æ–≤–æ–π, —Å–ª–æ–≤–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –±—É–∫–≤–∞–ª—å–Ω–æ –≤—ã—Ç—Ä—è—Ö–Ω—É—Ç—å –Ω–µ—Ä–≤—ã, –æ–Ω–∞ —Å–Ω–æ–≤–∞ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∞ –Ω–∞ –∫—É—Ä—å–µ—Ä–∞ –∏ —Å–∫–∞–∑–∞–ª–∞: \"–Ø... –ù–µ—Ç, –ø—Ä–æ—Å—Ç–∏—Ç–µ. –Ø –Ω–µ –∑–Ω–∞—é, –ø–æ—á–µ–º—É —è —Ç–∞–∫ —Å–∫–∞–∑–∞–ª–∞\", - –Ω–µ—Ä–≤–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç —Ä—É–∫–æ–π –ø–æ —Å–ø—É—Ç–∞–≤—à–∏–º—Å—è –≤–æ–ª–æ—Å–∞–º –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç: \"–ü—Ä–æ—Å—Ç–æ... —É –º–µ–Ω—è –µ—Å—Ç—å –∫ —Ç–µ–±–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ\".\\n\\n\\n\\n–û–Ω–∞ –≤—ã–≥–ª—è–¥–∏—Ç –¥–æ–≤–æ–ª—å–Ω–æ –ø–æ–±–µ–∂–¥–µ–Ω–Ω–æ–π, –¥—É–º–∞—è –ø—Ä–æ —Å–µ–±—è, –∫–∞–∫–∞—è –æ–Ω–∞ –Ω–µ—É–¥–∞—á–Ω–∏—Ü–∞. –í–∏–¥–Ω–æ, —á—Ç–æ –æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –≥—Ä–∞–Ω–∏ —Å–ª–µ–∑, –Ω–æ —Å–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Ö. –ö–∞–∫ –±—ã –æ–Ω–∞ –Ω–∏ —Å—Ç–∞—Ä–∞–ª–∞—Å—å –±—ã—Ç—å —Å–∏–ª—å–Ω–æ–π –∏ –∫–∞–∫ –±—ã –Ω–∏ –∑–∞–∫–∞–ª–∏–ª–∞ –µ–µ –∂–∏–∑–Ω—å –≤ –ü—É—Å—Ç–æ—à–∏, –æ–Ω–∞ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç–æ–ª—å–∫–æ –∏–∑–º–æ–∂–¥–µ–Ω–∞, –∫–∞–∫ —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã –≤–µ—Ä–∏—Ç—å –ª—é–¥—è–º.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –Ω–∞—Ö–º—É—Ä–∏–ª—Å—è, –≥–ª—è–¥—è –Ω–∞ –µ–µ –¥–µ–π—Å—Ç–≤–∏—è, –≤–∏–¥—è, —á—Ç–æ –æ–Ω–∞ —è–≤–Ω–æ –æ—á–µ–Ω—å —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–∞.  –û–Ω —Å–¥–µ–ª–∞–ª —à–∞–≥ –±–ª–∏–∂–µ –∏ –Ω–µ—Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Å–Ω—É–ª—Å—è –µ–µ –ø–ª–µ—á–∞.\\n\\n\\n\\r\\n\"–≠–π, –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ.  –ü—Ä–æ—Å—Ç–æ —É—Å–ø–æ–∫–æ–π—Å—è, –ø–æ–¥—É–º–∞–π, –ø—Ä–µ–∂–¥–µ —á–µ–º –æ—Ç–≤–µ—á–∞—Ç—å.  –ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?\"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–ü—Ä–∏–∫—É—Å–∏–≤ –≥—É–±—É, –æ–Ω–∞ –Ω–µ—Ä–≤–Ω–æ –æ–≥–ª—è–¥—ã–≤–∞–µ—Ç—Å—è –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º, —Å–ª–æ–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—è, –Ω–µ—Ç –ª–∏ –∑–∞ –Ω–µ–π —Å–ª–µ–∂–∫–∏. –ù–µ–º–Ω–æ–≥–æ —É—Å–ø–æ–∫–æ–∏–≤—à–∏—Å—å, –æ–Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç: \"–Ø... —è –î–∂–µ—Å—Å–∏–∫–∞. –ú–æ–π –≥–æ—Ä–æ–¥ –±—ã–ª —Ä–∞–∑—Ä—É—à–µ–Ω –õ–µ–≥–∏–æ–Ω–æ–º –¶–µ–∑–∞—Ä—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥, –∏ –º–Ω–µ –Ω–µ–∫—É–¥–∞ –∏–¥—Ç–∏. –í–æ –§—Ä–∏—Å–∞–π–¥–µ –¥–ª—è –º–µ–Ω—è –Ω–µ—Ç –º–µ—Å—Ç–∞, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –Ω–∏ –∫–µ–ø–æ–∫, –Ω–∏ –ø–∞—Å–ø–æ—Ä—Ç–∞, —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ –ø–æ–ª–æ—Å—É. –Ø –ø—Ä–æ—Å—Ç–æ —Ö–æ—á—É –∏–º–µ—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –º–µ—Å—Ç–æ, –≥–¥–µ –º–æ–∂–Ω–æ –∂–∏—Ç—å –∏ —Ä–∞–±–æ—Ç–∞—Ç—å, - —á–µ—Ä–µ–∑ —Å–µ–∫—É–Ω–¥—É –æ–Ω–∞ –≤—Å–ø–æ–º–Ω–∏–ª–∞, –∫ –∫–æ–º—É –æ–±—Ä–∞—â–∞–µ—Ç—Å—è, –∏ –¥–æ–±–∞–≤–∏–ª–∞ \"—Å—ç—Ä\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ö—É—Ä—å–µ—Ä –≤–∑–¥–æ—Ö–Ω—É–ª, –æ–ø—É—Å—Ç–∏–≤ –≤–∑–≥–ª—è–¥ –∏ –ø–æ–∫–∞—á–∞–≤ –≥–æ–ª–æ–≤–æ–π.  –≠—Ç–æ –±—ã–ª –Ω–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑, –∫–æ–≥–¥–∞ –∫—Ç–æ-—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏–ª –∫ –Ω–µ–º—É, —á—Ç–æ–±—ã –ª–∏—á–Ω–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å –æ –ø–æ–º–æ—â–∏.  –¢–∞–∫–æ–≤–∞ –±—ã–ª–∞ –µ–≥–æ —Ä–µ–ø—É—Ç–∞—Ü–∏—è.  –û–Ω –≤–æ–æ–±—â–µ –Ω–∏–∫–æ–≥–¥–∞ –Ω–∏–∫–æ–º—É –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–ª –Ω–∞–ø—Ä—è–º—É—é, –Ω–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø—Ä–∞–≤–ª—è–ª –ª—é–¥–µ–π –∫ –¥—Ä—É–≥–∏–º, –∫—Ç–æ –º–æ–≥ –∏–º –ø–æ–º–æ—á—å.  –•–æ—Ç—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã Lucky 38 –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–ª–∏, —á—Ç–æ –µ–º—É –Ω–µ –ø—Ä–∏–¥–µ—Ç—Å—è —Ç—Ä–∞—Ç–∏—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ú–æ—Ö–∞–≤–µ, —É –Ω–µ–≥–æ —Å–æ–≤—Å–µ–º –Ω–µ –±—É–¥–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –µ–¥—É –∏ —Å–æ–Ω, –µ—Å–ª–∏ –æ–Ω –±—É–¥–µ—Ç –ª–∏—á–Ω–æ –ø–æ–º–æ–≥–∞—Ç—å –∫–∞–∂–¥–æ–º—É, –∫—Ç–æ –ø–æ–ø—Ä–æ—Å–∏—Ç.\\n\\n\\n\\n\"–î–∂–µ—Å—Å–∏–∫–∞... –∫–æ–Ω–µ—á–Ω–æ, –∑–¥–µ—Å—å —Å —Ç–æ–±–æ–π –±—É–¥—É—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ\".  –û–Ω —Å–ª–µ–≥–∫–∞ —É–ª—ã–±–Ω—É–ª—Å—è.  \"–¢—ã —Ä–∞–Ω–µ–Ω–∞?  –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ê–ø–æ–∫–∞–ª–∏–ø—Å–∏—Å–∞ –≤ —Ñ–æ—Ä—Ç–µ –°—Ç–∞—Ä—ã—Ö –ú–æ—Ä–º–æ–Ω–æ–≤...\", - –æ–Ω —É–∫–∞–∑–∞–ª –Ω–∞ –±–æ–ª—å—à–æ–π —Ñ–æ—Ä—Ç –°—Ç–∞—Ä–æ–≥–æ –°–≤–µ—Ç–∞ –Ω–µ–ø–æ–¥–∞–ª–µ–∫—É –æ—Ç –Ω–∏—Ö.  \"–û–Ω–∏ –ø–æ–º–æ–≥—É—Ç —Ç–µ–±–µ —Å —Ç–≤–æ–∏–º–∏ —Ä–∞–Ω–∞–º–∏, —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ –∏–ª–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–° —Ä–µ—à–∏—Ç–µ–ª—å–Ω—ã–º –≤–∑–≥–ª—è–¥–æ–º –≤ –≥–ª–∞–∑–∞—Ö –æ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∞ —Ç–≤–µ—Ä–¥—ã–π –∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç —Å –∫—É—Ä—å–µ—Ä–æ–º... –∏–ª–∏, –ø–æ –∫—Ä–∞–π–Ω–µ–π –º–µ—Ä–µ, –µ–π —Ç–∞–∫ –ø–æ–∫–∞–∑–∞–ª–æ—Å—å. –ï–≥–æ —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏ –±—ã–ª–∏ –æ—á–µ–Ω—å –∑–µ—Ä–∫–∞–ª—å–Ω—ã–º–∏. \"–Ø –Ω–µ –±–µ–∂–µ–Ω–∫–∞ –∏ –Ω–µ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∏—Ü–∞, —Å—ç—Ä. –Ø —Ö–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å. –Ø —Ö–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ —Å—Ç—Ä–∏–ø–µ, –≥–¥–µ —è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ–≥—É –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–∞ –∂–∏–∑–Ω—å\".\\n\\n\\n\\n–ù–µ –±—É–¥—É—á–∏ –æ—Ç –ø—Ä–∏—Ä–æ–¥—ã —Ç–∞–∫–æ–π —Å–º–µ–ª–æ–π, –æ–Ω–∞ –Ω–µ–º–Ω–æ–≥–æ –ø–æ–∫—Ä–∞—Å–Ω–µ–ª–∞, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏–ª–∞: \"–Ø —Ç—Ä—É–¥–æ–ª—é–±–∏–≤–∞—è, –±—ã—Å—Ç—Ä–æ —É—á—É—Å—å –∏ –≥–æ—Ç–æ–≤–∞ –¥–µ–ª–∞—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ, –µ—Å–ª–∏ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–±–∏—Ç—å—Å—è –Ω–∞ —Å—Ç—Ä–∏–ø. –ì–¥–µ-—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ—Å—Ç–æ –¥–ª—è –º–µ–Ω—è\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–µ–ª –≤ –µ–µ –≥–ª–∞–∑–∞, –∫–æ–≥–¥–∞ –æ–Ω–∞ –≥–æ–≤–æ—Ä–∏–ª–∞, –∏, –≤–æ–∑–º–æ–∂–Ω–æ, —É–≤–∏–¥–µ–ª —Ç–∞–º —á—Ç–æ-—Ç–æ –æ—Ç —Å–µ–±—è.  –¢–æ, —á–µ–º –æ–Ω –±—ã–ª –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –ø–æ–¥–Ω—è–ª—Å—è –∏–∑ —Å–≤–æ–µ–π –Ω–µ–≥–ª—É–±–æ–∫–æ–π –º–æ–≥–∏–ª—ã –≤ –ì—É–¥—Å–ø—Ä–∏–Ω–≥—Å–µ, –æ—Ç–ª–∏—á–∞–ª–æ—Å—å –æ—Ç —Ç–æ–≥–æ, —á–µ–º –æ–Ω –±—ã–ª —Ä–∞–Ω—å—à–µ.  –ï–≥–æ –º–æ–∑–≥ –±—ã–ª —Ä–∞–∑–¥—Ä–æ–±–ª–µ–Ω –ø—É–ª—è–º–∏, –∏ –æ–Ω –ø—Ä–æ—Å–Ω—É–ª—Å—è —Å–æ–≤—Å–µ–º –¥—Ä—É–≥–∏–º —á–µ–ª–æ–≤–µ–∫–æ–º.  –†–∞–Ω—å—à–µ –µ–≥–æ —É—Å—Ç—Ä–∞–∏–≤–∞–ª–∞ —Ä–∞–±–æ—Ç–∞ –∏ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫—É—Ä—å–µ—Ä–∞, –Ω–æ –∫–æ–≥–¥–∞ –æ–Ω –ø—Ä–æ—Å–Ω—É–ª—Å—è –≤ —Ç–æ—Ç –¥–µ–Ω—å, —Ç–æ –æ–±–Ω–∞—Ä—É–∂–∏–ª, —á—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∏—á–µ–≥–æ –≤ –ø–æ–∫–æ–µ; –æ–Ω\\n–±—ã–ª\\n –¥–µ–ª–∞—Ç—å —Ç–æ, —á—Ç–æ –±—ã–ª–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.  –î—Ä—É–≥–æ–≥–æ –≤—ã–±–æ—Ä–∞ –Ω–µ –±—ã–ª–æ.  –í—Å–∫–æ—Ä–µ –æ–Ω —Å—Ç–∞–ª –±–æ–ª–µ–µ —Ç–≤–µ—Ä–¥—ã–º, –±–æ–ª–µ–µ —É–≤–µ—Ä–µ–Ω–Ω—ã–º –≤ —Å–µ–±–µ... –∏ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ –æ–Ω —É–≤–∏–¥–µ–ª –≤ –Ω–µ–π.\\n\\n\\n\\n\"–¢—ã –±–µ–∂–µ–Ω–∫–∞... –≤ —ç—Ç–æ–º –Ω–µ—Ç –Ω–∏—á–µ–≥–æ –ø–ª–æ—Ö–æ–≥–æ.  –≠—Ç–æ –Ω–µ —Ç–≤–æ—è –≤–∏–Ω–∞\".  –û–Ω –º—è–≥–∫–æ –≤–∑–¥–æ—Ö–Ω—É–ª.  \"–§—Ä–∏—Å–∞–π–¥ –∏–∑–º–µ–Ω–∏–ª—Å—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü.  –û–Ω —Å—Ç–∞–±–∏–ª–µ–Ω, –≤ –Ω–µ–º –Ω–µ—Ç –Ω–∞—Å–∏–ª–∏—è.  –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ª—é–¥–µ–π —Ä–∞–±–æ—Ç–∞—é—Ç.  –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞, –ø–æ –∫–æ—Ç–æ—Ä–æ–π —è –Ω–µ —Å–Ω–µ—Å –≤–æ—Ä–æ—Ç–∞ –≤ –°—Ç—Ä–∏–ø, –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –¢—Ä–∏ –°–µ–º—å–∏ –æ–ø–∞—Å–∞—é—Ç—Å—è —Ä–∞—Å–ø—Ä–∞–≤—ã, –∏ –≤–ø–æ–ª–Ω–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ.  –ö–æ–≥–¥–∞-–Ω–∏–±—É–¥—å —Å–∫–æ—Ä–æ —è —Å–Ω–µ—Å—É —ç—Ç–∏ –≤–æ—Ä–æ—Ç–∞\".  –û–Ω —Å–¥–µ–ª–∞–ª –ø–∞—É–∑—É –Ω–∞ –º–≥–Ω–æ–≤–µ–Ω–∏–µ.  \"–û—Ç–ª–∏—á–Ω–æ.  –ü–æ–π–¥–µ–º —Å–æ –º–Ω–æ–π, –º—ã –æ–±—Å—É–¥–∏–º, —á—Ç–æ —Ç—ã –º–æ–∂–µ—à—å —Å–¥–µ–ª–∞—Ç—å.  –í —á–µ–º —Ç—ã —Ö–æ—Ä–æ—à?  –ß—Ç–æ —Ç–µ–±–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ?\"  –û–Ω —Å–ª–µ–≥–∫–∞ –ø–æ–≤–µ—Ä–Ω—É–ª—Å—è –∏ –Ω–∞—á–∞–ª –∏–¥—Ç–∏ –∫ –≤–æ—Ä–æ—Ç–∞–º –≤ –¥—Ä—É–≥—É—é —á–∞—Å—Ç—å –§—Ä–∏—Å–∞–π–¥–∞, —Å –ê—Ç–æ–º–Ω—ã–º –í—Ä–∞–Ω–≥–ª–µ—Ä–æ–º –∏ –≤–æ—Ä–æ—Ç–∞–º–∏ –≤ –°—Ç—Ä–∏–ø, –º–∞–Ω—è –µ–µ –∑–∞ —Å–æ–±–æ–π.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–ö–∞–∂–µ—Ç—Å—è, —á—Ç–æ –µ–µ –Ω–æ–≥–∏ –¥–≤–∏–≥–∞—é—Ç—Å—è —Ä–∞–Ω—å—à–µ, —á–µ–º –µ–µ —Ä–∞–∑—É–º –æ—Å–æ–∑–Ω–∞–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–µ–µ, –∏–∑-–∑–∞ —á–µ–≥–æ –æ–Ω–∞ –Ω–µ–º–Ω–æ–≥–æ —Å–ø–æ—Ç—ã–∫–∞–µ—Ç—Å—è, –Ω–æ –ø–æ—Ç–æ–º –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –∏–¥—Ç–∏ –∑–∞ –∫—É—Ä—å–µ—Ä–æ–º. –û–Ω–∞ –Ω–∞ —Å–µ–∫—É–Ω–¥—É –∑–∞–¥—É–º—ã–≤–∞–µ—Ç—Å—è, –ø—Ä–µ–∂–¥–µ —á–µ–º –∑–∞–≥–æ–≤–æ—Ä–∏—Ç—å - –Ω–æ–≤–∞—è –ø—Ä–∏–≤—ã—á–∫–∞, - –∞ –ø–æ—Ç–æ–º –æ—Ç–≤–µ—á–∞–µ—Ç: \"–ß—Ç–æ —è —É–º–µ—é? –ù—É, –º–æ–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã... –æ–≥—Ä–∞–Ω–∏—á–µ–Ω. –ù–æ –º–Ω–µ –≥–æ–≤–æ—Ä–∏–ª–∏, —á—Ç–æ —è —Å–∏–º–ø–∞—Ç–∏—á–Ω–∞—è, —Ç–∞–∫ —á—Ç–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å, —è –º–æ–≥–ª–∞ –±—ã... —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –æ–¥–Ω–æ–º –∏–∑ –æ—Ç–µ–ª–µ–π? –Ø —Ç–∞–∫–∂–µ –∑–Ω–∞—é –Ω–µ–º–Ω–æ–≥–æ –ø–µ—Ä–≤–æ–π –ø–æ–º–æ—â–∏, —Ç–∞–∫ —á—Ç–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å... –∫–æ–º—É-—Ç–æ –Ω—É–∂–Ω–∞ –º–µ–¥—Å–µ—Å—Ç—Ä–∞? –Ø —Ç—Ä—É–¥–æ–ª—é–±–∏–≤ –∏ –Ω–µ –ø—Ä–∏–≤–µ—Ä–µ–¥–ª–∏–≤, –æ–±–µ—â–∞—é. –õ—é–±–∞—è —Ä–∞–±–æ—Ç–∞, –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ, –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –ø–æ—Ä—è–¥–∫–µ\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ö—É—Ä—å–µ—Ä –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–≤–µ—Ä–∏–ª –≤ —ç—Ç–æ, —Ç–∞–∫ –∫–∞–∫ –ø–æ–π–º–∞–ª –µ–µ, –∫–æ–≥–¥–∞ –æ–Ω–∞ —Å–ø–æ—Ç–∫–Ω—É–ª–∞—Å—å, –∏ –≤—ã–ø—Ä—è–º–∏–ª –µ–µ, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∏–¥—Ç–∏.\\n\\n\\n\\n\"–¢—ã –∂–µ –∑–Ω–∞–µ—à—å, —á—Ç–æ –º–æ–≥–ª–∞ –±—ã –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—Ç—É –∑–¥–µ—Å—å –∏–ª–∏ –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ –±–µ–∑ –º–æ–µ–π –ø–æ–º–æ—â–∏...\"\\n\\n\\n\\n–û–Ω–∏ –ø—Ä–æ—à–ª–∏ —á–µ—Ä–µ–∑ –∏–º–ø—Ä–æ–≤–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ—Ä–æ—Ç–∞ –≤ –¥—Ä—É–≥—É—é —á–∞—Å—Ç—å –§—Ä–∏—Å–∞–π–¥–∞; —á–µ—Ä–µ–∑ –∑–∞–±—Ä–æ—à–µ–Ω–Ω—ã–π –≤–∞–≥–æ–Ω –º–µ—Ç—Ä–æ, —á—Ç–æ–±—ã –±—ã—Ç—å –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω—ã–º–∏ –∑–≤—É–∫–∞–º–∏ –æ–∂–∏–≤–ª–µ–Ω–Ω–æ–π –º—É–∑—ã–∫–∏ –∏ —Å–∏—è—é—â–µ–π –≤—ã–≤–µ—Å–∫–æ–π KING\\'S —Å–ª–µ–≤–∞ –æ—Ç –Ω–∏—Ö, –≤—ã–≤–µ—Å–∫–æ–π –ö–æ—Ä–æ–ª–µ–≤—Å–∫–æ–π —à–∫–æ–ª—ã –ø–∞—Ä–æ–¥–∏–π.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–û–Ω–∞ –ø—Ä–∏–∫—É—Å–∏–ª–∞ –≥—É–±—É –∏ –Ω–µ—Ä–≤–Ω–æ –≤—ã—Å–≤–æ–±–æ–¥–∏–ª–∞—Å—å –∏–∑ –µ–≥–æ –æ–±—ä—è—Ç–∏–π –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –æ–Ω –ø–æ–π–º–∞–ª –µ–µ. –ù–µ –∂–µ–ª–∞—è —Ä–∞—Å–∫—Ä—ã–≤–∞—Ç—å —Å–≤–æ—é –∏—Å—Ç–∏–Ω–Ω—É—é —Ü–µ–ª—å –≤ –ø–æ–∏—Å–∫–∞—Ö —Å–ø–æ—Å–æ–±–∞ –∂–∏—Ç—å –Ω–∞ —Å—Ç—Ä–∏–ø–µ, –æ–Ω–∞ –∑–∞–ø–∏–Ω–∞–µ—Ç—Å—è –∏ –≤—ã–¥–∞–µ—Ç –±—ã—Å—Ç—Ä—ã–π, –Ω–µ—Ä–≤–Ω—ã–π –æ—Ç–≤–µ—Ç. \"–Ø... –ù—É, —è –Ω–µ —Ö–æ—Ç–µ–ª–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –∑–¥–µ—Å—å, –≤–æ –§—Ä–∏—Å–∞–π–¥–µ. –Ø —Ö–æ—Ç–µ–ª–∞... –±–ª–µ—Å–∫–∞ –∏ –≥–ª–∞–º—É—Ä–∞ –°—Ç—Ä–∏–ø–∞!\"\\n\\n\\n\\n–ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –î–∂–µ—Å—Å–∏–∫–∞ –∂–∞–∂–¥–∞–ª–∞ –ª–∏—à—å –æ–±–µ—â–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∑–∞—â–∏—Ç—ã –æ—Ç –õ–µ–≥–∏–æ–Ω–∞ –¶–µ–∑–∞—Ä—è –Ω–∞ —Ç–æ—Ç —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ—à–ª—é—Ç –∑–∞ –Ω–µ–π –∫–æ–≥–æ-–Ω–∏–±—É–¥—å. –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ä–∞–π–æ–Ω—ã –§—Ä–∏—Å–∞–π–¥–∞ –Ω–µ –¥–∞–≤–∞–ª–∏ –µ–π —Å–ø–æ–∫–æ–π—Å—Ç–≤–∏—è.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ö—É—Ä—å–µ—Ä –∑–Ω–∞–ª, —á—Ç–æ –æ–Ω–∞ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –µ–º—É –Ω–µ –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é [PER 7 (8 —Å –±–æ–Ω—É—Å–æ–º –≤ –≤–∏–¥–µ –±–∞–Ω–¥–∞–Ω—ã) XD], –Ω–æ –æ–Ω —Ç–∞–∫–∂–µ –ø–æ–ª–∞–≥–∞–ª, —á—Ç–æ –æ–Ω–∞ –±—É–¥–µ—Ç –±–æ–ª–µ–µ —Å–∫–ª–æ–Ω–Ω–∞ –≥–æ–≤–æ—Ä–∏—Ç—å –∏—Å–∫—Ä–µ–Ω–Ω–µ, –µ—Å–ª–∏ –Ω–µ –±—É–¥–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –Ω–∞ –ø—É–±–ª–∏–∫–µ.  –ü–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ –æ–Ω–∞ —Ö–æ—Ç–µ–ª–∞ –±—ã –±—ã—Ç—å –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º –º–µ—Å—Ç–µ, –Ω–æ –§—Ä–∏—Å–∞–π–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –±—ã–ª –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –º–µ—Å—Ç–æ–º.  –û–Ω–∞ –Ω–∞–≤–µ—Ä–Ω—è–∫–∞ —Å–ª—ã—à–∞–ª–∞ —Å—Ç–∞—Ä—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ –Ω–µ–º.  –°—Ç–µ–Ω–∞ –≤–æ–∫—Ä—É–≥ —Å–∞–º–æ–≥–æ –ù—å—é-–í–µ–≥–∞—Å–∞ –±—ã–ª–∞ —á–µ–º-—Ç–æ –∏–∑ —Ä—è–¥–∞ –≤–æ–Ω –≤—ã—Ö–æ–¥—è—â–∏–º, –Ω–æ —Å –º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–æ–±–æ—Ç–∞–º–∏ Securitron Mk. II, –ø–∞—Ç—Ä—É–ª–∏—Ä—É—é—â–∏–º–∏ –ø–æ –≤—Å–µ–º—É –≥–æ—Ä–æ–¥—É (–Ω–µ –≥–æ–≤–æ—Ä—è —É–∂–µ –æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑–≤–µ–¥—á–∏–∫–∞—Ö –≤–¥–æ–ª—å –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Å—Ç –≤ –ú–æ—Ö–∞–≤–µ), –ª—é–±–æ–π —Ä–µ–∞–ª—å–Ω–æ–π —É–≥—Ä–æ–∑–µ –±—ã–ª–æ –±—ã —Å–ª–æ–∂–Ω–æ –ø—Ä–æ–Ω–∏–∫–Ω—É—Ç—å —Å—é–¥–∞, –Ω–µ —É–∑–Ω–∞–≤ –æ–± —ç—Ç–æ–º.  –ï—Å–ª–∏ –±—ã –±—ã–ª–æ –∑–∞–º–µ—á–µ–Ω–æ —á—Ç–æ-—Ç–æ —Å—Ç—Ä–∞–Ω–Ω–æ–µ, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –±—ã–ª–∞ –±—ã –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –µ–≥–æ –ü–∏–ø-–ë–æ—é.  –¢–µ–º –Ω–µ –º–µ–Ω–µ–µ, –æ–Ω –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–ª, —á—Ç–æ –∫—Ç–æ-—Ç–æ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–∂–µ—Ç –ø—Ä–æ–Ω–∏–∫–Ω—É—Ç—å –≤–Ω—É—Ç—Ä—å... –∏–ª–∏, –º–æ–∂–µ—Ç –±—ã—Ç—å, –Ω–µ–±–æ–ª—å—à–∞—è –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∞, –µ—Å–ª–∏ –æ–Ω–∏ —Å–¥–µ–ª–∞—é—Ç —ç—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–æ.\\n\\n\\n\\n–í—Å–∫–æ—Ä–µ –æ–Ω–∏ –ø—Ä–∏–±–ª–∏–∑–∏–ª–∏—Å—å –∫ –≤–æ—Ä–æ—Ç–∞–º –≤ –°—Ç—Ä–∏–ø, –∏ –æ–¥–∏–Ω –∏–∑ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤, –∫–∞–∫ –≤—Å–µ–≥–¥–∞, –ø–æ–¥–∫–∞—Ç–∏–ª –∫ –Ω–∏–º, –Ω–µ –æ–±—Ä–∞—â–∞—è –≤–Ω–∏–º–∞–Ω–∏—è –Ω–∞ –∫—É—Ä—å–µ—Ä–∞, –∞ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–≤—à–∏—Å—å –Ω–∞ –î–∂–µ—Å—Å–∏–∫–µ.\\n\\n\\n\\n\"–ü—Ä–æ–π–¥–∏—Ç–µ –∫—Ä–µ–¥–∏—Ç–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∏–ª–∏ –ø—Ä–µ–¥—ä—è–≤–∏—Ç–µ –¥–µ–π—Å—Ç–≤—É—é—â–∏–π –ø–∞—Å–ø–æ—Ä—Ç –¥–ª—è –≤—Ö–æ–¥–∞\".\\n\\n\\n\\n\"–û–Ω–∞ —Å–æ –º–Ω–æ–π\", - —Å–∫–∞–∑–∞–ª –ö—É—Ä—å–µ—Ä.\\n\\n\\n\\n\"–°–ø–∞—Å–∏–±–æ!\" - —Å–∫–∞–∑–∞–ª –∂—É—Ç–∫–æ –≤–µ–∂–ª–∏–≤—ã–π —Ä–æ–±–æ—Ç.  \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ—Ö–æ–¥–∏—Ç–µ –≤–Ω—É—Ç—Ä—å\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–î—Ä–æ–∂—å –ø—Ä–æ–±–µ–∂–∞–ª–∞ –ø–æ –µ–µ –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫—É, –∫–æ–≥–¥–∞ –æ–Ω–∏ –ø—Ä–æ—Ö–æ–¥–∏–ª–∏ –º–∏–º–æ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤. –û–Ω–∞ –¥—É–º–∞–ª–∞ –æ —Ç–æ–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω–∏ –º–æ–≥—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã, –∏ –æ —Ç–æ–º, —á—Ç–æ —Å –Ω–∏–º–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –¥–æ–≥–æ–≤–æ—Ä–∏—Ç—å—Å—è —Ç–∞–∫, –∫–∞–∫ —Å —á–µ–ª–æ–≤–µ–∫–æ–º. –î–ª—è –Ω–µ–µ —ç—Ç–æ –±—ã–ª–∞ —Å–∞–º–∞—è —Å—Ç—Ä–∞—à–Ω–∞—è –º—ã—Å–ª—å. –û–Ω–∏ –≤–æ—à–ª–∏ –≤ –°—Ç—Ä–∏–ø, –∏ –î–∂–µ—Å—Å–∏–∫–∞ –Ω–µ –º–æ–≥–ª–∞ —É–¥–µ—Ä–∂–∞—Ç—å—Å—è –æ—Ç —Ç–æ–≥–æ, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≥–ª–∞–∑–µ—Ç—å –Ω–µ–º–Ω–æ–≥–æ. –í—Å–µ –∫–∞–∑–∞–ª–∏—Å—å —Ç–∞–∫–∏–º–∏ –±–æ–≥–∞—Ç—ã–º–∏, —Å–∞–º–æ–¥–æ–≤–æ–ª—å–Ω—ã–º–∏ –∏ —è–≤–Ω–æ —Å—á–∏—Ç–∞–ª–∏ —Å–µ–±—è –æ—á–µ–Ω—å –≤–∞–∂–Ω—ã–º–∏. –ó–¥–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –∏–∑–¥–∞–ª–µ–∫–∞ –∫–∞–∑–∞–ª–∏—Å—å —Ç–∞–∫–∏–º–∏ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º–∏, —Ç–µ–ø–µ—Ä—å –±—ã–ª–∏ –∫–∞—Ä–ª–∏–∫–æ–≤—ã–º–∏ –∏ –∑–∞—Å—Ç–∞–≤–ª—è–ª–∏ –µ–µ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –µ—â–µ –º–µ–Ω—å—à–µ. –ü—Ä–∏–º–µ—Ä–Ω–æ —á–µ—Ä–µ–∑ 15 —Å–µ–∫—É–Ω–¥ –æ–Ω–∞ —Å–Ω–æ–≤–∞ –ø–æ–≤–µ—Ä–Ω—É–ª–∞—Å—å –∫ –∫—É—Ä—å–µ—Ä—É –∏ —Ä–∞–¥–æ—Å—Ç–Ω–æ —Å–∫–∞–∑–∞–ª–∞: \"–°–ø–∞—Å–∏–±–æ! –¢—ã –æ–∫–∞–∑–∞–ª –º–Ω–µ —Ç–∞–∫—É—é –ª—é–±–µ–∑–Ω–æ—Å—Ç—å. –ú–æ–≥—É –ª–∏ —è —á–µ–º-–Ω–∏–±—É–¥—å –æ—Ç–ø–ª–∞—Ç–∏—Ç—å —Ç–µ–±–µ?\"<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ö—É—Ä—å–µ—Ä –ø—Ä–∏–≤–µ–ª –µ–µ –∫ –≤–æ—Ä–æ—Ç–∞–º Lucky 38; –º–∞—Å—Å–∏–≤–Ω—ã–µ –∫—Ä–∞—Å–Ω–æ-—á–µ—Ä–Ω—ã–µ –¥–≤–µ—Ä–∏ —Å –≤–∏–∑–≥–æ–º —Ä–∞–∑–¥–≤–∏–Ω—É–ª–∏—Å—å –≤ —Å—Ç–æ—Ä–æ–Ω—ã, –æ—Ç–∫—Ä—ã–≤–∞—è –±–æ–ª–µ–µ –æ–±—ã—á–Ω—É—é –ø–∞—Ä–∞–¥–Ω—É—é –¥–≤–µ—Ä—å.  –°—Ç—É–ø–µ–Ω–∏ –∫–∞–∑–∏–Ω–æ –∑–∞—Å–≤–µ—Ç–∏–ª–∏—Å—å –≤–∑–∞–¥-–≤–ø–µ—Ä–µ–¥, –∫–æ–≥–¥–∞ –æ–Ω–∏ –ø—Ä–æ—à–ª–∏ –ø–æ –Ω–∏–º, –∏ –æ–Ω –ø—Ä–æ–≤–µ–ª –µ–µ –≤–Ω—É—Ç—Ä—å.\\n\\n\\n\\n–≠—Ç–æ –±—ã–ª–æ –∫–∞–∑–∏–Ω–æ.  –ï–≥–æ –æ—Ö—Ä–∞–Ω—è–ª–∏ –¥–≤–∞ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–∞ - –ø–æ –æ–¥–Ω–æ–º—É —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, \"—Å–º–æ—Ç—Ä—è\" –Ω–∞ –Ω–∏—Ö –∏–∑-–∑–∞ –∫–∞—Ä–∏–∫–∞—Ç—É—Ä—ã —Å–æ–ª–¥–∞—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∞—Å—å –Ω–∞ –∏—Ö —ç–∫—Ä–∞–Ω–∞—Ö.\\n\\n\\n\\n\"–≠—Ç–æ...\"  –ö—É—Ä—å–µ—Ä —É–ª—ã–±–Ω—É–ª—Å—è –∏ —Ç–∏—Ö–æ–Ω—å–∫–æ –∑–∞—Å–º–µ—è–ª—Å—è.  \"–ú–æ–π –¥–æ–º, —è –ø–æ–ª–∞–≥–∞—é.  –ù—É, –Ω–µ –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–∂–µ\".  –ö–∞–∑–∞–ª–æ—Å—å, –æ–Ω –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª –µ–µ –≤–æ–ø—Ä–æ—Å.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–ö–æ–≥–¥–∞ –æ–Ω–∞ –ø–æ–¥–Ω–∏–º–∞–ª–∞—Å—å –ø–æ —Å—Ç—É–ø–µ–Ω—å–∫–∞–º –∏ –≤—Ö–æ–¥–∏–ª–∞ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–≤–µ—Ä–∏, —Ä–æ—Å–∫–æ—à—å —Å—á–∞—Å—Ç–ª–∏–≤—á–∏–∫–∞ 38 –±—ã–ª–∞ –¥–ª—è –Ω–µ–µ –ø–æ—á—Ç–∏ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ–π. \"–¢-—Ç–≤–æ–π –¥–æ–º –ø—Ä–µ–∫—Ä–∞—Å–µ–Ω\", - —Å–∫–∞–∑–∞–ª–∞ –æ–Ω–∞, –Ω–µ–º–Ω–æ–≥–æ –æ–±–µ—Å–∫—É—Ä–∞–∂–µ–Ω–Ω–∞—è —Ç–µ–º, —á—Ç–æ –æ–Ω –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –Ω–∞ –µ–µ –≤–æ–ø—Ä–æ—Å, - \"–í—Å–µ —ç—Ç–æ –Ω–µ–º–Ω–æ–≥–æ —Å—é—Ä—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ –¥–ª—è –º–µ–Ω—è, —è –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª–∞, —á—Ç–æ —Ç–∞–∫–æ–π –¥–≤–æ—Ä–µ—Ü –º–æ–∂–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –ú–æ—Ö–∞–≤–µ\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –Ω–µ —É–¥–µ—Ä–∂–∞–ª—Å—è –∏ —Å–ª–µ–≥–∫–∞ —É—Ö–º—ã–ª—å–Ω—É–ª—Å—è –Ω–∞ –µ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ, —Å–∫—Ä–µ—Å—Ç–∏–≤ —Ä—É–∫–∏ –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ –ª–∏—Ñ—Ç–∞.  \"–¢—ã –µ—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –≤–∏–¥–µ–ª–∞\".  –û–Ω —Ö–æ—Ç–µ–ª –ø–æ–∫–∞–∑–∞—Ç—å –µ–π —Å—Ç—Ä–∏–ø –Ω–æ—á—å—é, –≤–∏–¥ —Å –≤–µ—Ä—à–∏–Ω—ã Lucky 38.  –û–Ω–∞ –±—ã–ª–∞ –ø–µ—Ä–≤—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–Ω –ø—Ä–∏–≤–µ–ª —Å—é–¥–∞ —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫... –Ω—É, —Å —Ç–µ—Ö –ø–æ—Ä –∫–∞–∫... –∫–æ–≥–¥–∞-–ª–∏–±–æ.  –û–Ω –ø–æ–Ω—è—Ç–∏—è –Ω–µ –∏–º–µ–ª –ø–æ—á–µ–º—É, –Ω–æ –µ–º—É –±—ã–ª–æ –±–µ–∑—É—Å–ª–æ–≤–Ω–æ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —ç—Ç–æ –µ–π.\\n\\n\\n\\n\\n–î–∑–∏–Ω—å!\\n  –î–≤–µ—Ä–∏ –ª–∏—Ñ—Ç–∞ –æ—Ç–∫—Ä—ã–ª–∏—Å—å.  \"–î–∞–≤–∞–π —è –ø–æ–∫–∞–∂—É —Ç–µ–±–µ –ø–µ–Ω—Ç—Ö–∞—É—Å\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\\n\\n\\n\\t\\t\\t\\n\\t\\t\\t\\t—Å–∫–∞–∑–∞–ª –í–≤–µ—Ç:\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n\\n\\n\\n\\t\\t\\t–û–Ω –Ω–µ —É–¥–µ—Ä–∂–∞–ª—Å—è –∏ —Å–ª–µ–≥–∫–∞ —É—Ö–º—ã–ª—å–Ω—É–ª—Å—è –Ω–∞ –µ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ, —Å–∫—Ä–µ—Å—Ç–∏–≤ —Ä—É–∫–∏ –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ –ª–∏—Ñ—Ç–∞.  \"–¢—ã –µ—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –≤–∏–¥–µ–ª–∞\".  –û–Ω —Ö–æ—Ç–µ–ª –ø–æ–∫–∞–∑–∞—Ç—å –µ–π —Å—Ç—Ä–∏–ø –Ω–æ—á—å—é, –≤–∏–¥ —Å –≤–µ—Ä—à–∏–Ω—ã Lucky 38.  –û–Ω–∞ –±—ã–ª–∞ –ø–µ—Ä–≤—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–Ω –ø—Ä–∏–≤–µ–ª —Å—é–¥–∞ —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫... –Ω—É, —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫ –Ω–∏–∫–æ–≥–¥–∞.  –û–Ω –ø–æ–Ω—è—Ç–∏—è –Ω–µ –∏–º–µ–ª –ø–æ—á–µ–º—É, –Ω–æ –µ–º—É –±—ã–ª–æ –±–µ–∑—É—Å–ª–æ–≤–Ω–æ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —ç—Ç–æ –µ–π.\\n\\n\\n\\n\\n–î–∑–∏–Ω—å!\\n  –î–≤–µ—Ä–∏ –ª–∏—Ñ—Ç–∞ –æ—Ç–∫—Ä—ã–ª–∏—Å—å.  \"–î–∞–≤–∞–π —è –ø–æ–∫–∞–∂—É —Ç–µ–±–µ –ø–µ–Ω—Ç—Ö–∞—É—Å\".\\n\\t\\t\\n\\n\\nClick to expand...\\n\\n\\n\\n\\n\\r\\n–° –∂–∏–≤–æ—Ç–æ–º, –ø–æ–ª–Ω—ã–º –±–∞–±–æ—á–µ–∫, –î–∂–µ—Å—Å–∏–∫–∞ –≤–æ—à–ª–∞ –≤ –ª–∏—Ñ—Ç –∏ –∏–∑–±–µ–≥–∞–ª–∞ –∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞ —Å –∫—É—Ä—å–µ—Ä–æ–º, –≥–ª—è–¥—è –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º, –∫—É–¥–∞ —É–≥–æ–¥–Ω–æ, —Ç–æ–ª—å–∫–æ –Ω–µ –Ω–∞ –Ω–µ–≥–æ. –ö–æ–≥–¥–∞ –æ–Ω–∞ –∑–∞–≥–æ–≤–æ—Ä–∏–ª–∞, —Ç–æ —Å –∫—Ä–æ—Ç–∫–∏–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º –ª–∏—Ü–∞ –ø—Ä–∏—Å—Ç–∞–ª—å–Ω–æ —É—Å—Ç–∞–≤–∏–ª–∞—Å—å –≤ –ø–æ–ª. \"–Ø –∑–∞–º–µ—Ç–∏–ª–∞, —á—Ç–æ –≤—ã –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª–∏ –º–æ–π –≤–æ–ø—Ä–æ—Å, —Å—ç—Ä. –ú–æ–≥—É –ª–∏ —è —á–µ–º-—Ç–æ –ø–æ–º–æ—á—å –≤–∞–º?\"\\n\\n\\n\\r\\n–ü—Ä–µ–∂–¥–µ —á–µ–º –æ–Ω —É—Å–ø–µ–ª –æ—Ç–≤–µ—Ç–∏—Ç—å, –ª–∏—Ñ—Ç –∑–≤—è–∫–Ω—É–ª –∏ –æ—Ç–∫—Ä—ã–ª—Å—è, –æ—Ç–∫—Ä—ã–≤–∞—è –≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–π –ø–µ–Ω—Ç—Ö–∞—É—Å. –û–Ω–∞ –∑–∞–¥–æ—Ö–Ω—É–ª–∞—Å—å –æ—Ç –≤–æ—Å—Ç–æ—Ä–≥–∞, –Ω–æ, –ø—Ä–µ–∂–¥–µ —á–µ–º –≤—ã–π—Ç–∏ –∏–∑ –ª–∏—Ñ—Ç–∞, –ø–æ–≤–µ—Ä–Ω—É–ª–∞—Å—å –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∞ –Ω–∞ –Ω–µ–≥–æ, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å, —á—Ç–æ –æ–Ω —Å–¥–µ–ª–∞–µ—Ç –∏–ª–∏ —Å–∫–∞–∂–µ—Ç.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n\"–Ø –Ω–µ –∑–Ω–∞—é.  –ï—Å—Ç—å —Ç–∞–∫ –º–Ω–æ–≥–æ –ø—Ä–æ–±–ª–µ–º –∏ —Ç–∞–∫ –º–Ω–æ–≥–æ –≤–µ—â–µ–π, –∫–æ—Ç–æ—Ä—ã–µ\\n–º–æ–∂–µ—Ç\\n –ø–æ–π—Ç–∏ –Ω–µ —Ç–∞–∫... –Ø –±—ã –¥–∞–∂–µ –Ω–µ –∑–Ω–∞–ª, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å.  –ù–æ —ç—Ç–æ –º–æ–∏ –ø—Ä–æ–±–ª–µ–º—ã.  –Ø –Ω–µ —Ö–æ—á—É –æ–±—Ä–µ–º–µ–Ω—è—Ç—å –∏–º–∏ –∫–æ–≥–æ-—Ç–æ –µ—â–µ\".  –û–Ω –≤—ã—à–µ–ª –≤ –ø–µ–Ω—Ç—Ö–∞—É—Å, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª —Å–æ–±–æ–π –±–æ–ª—å—à–æ–π –≤—Ä–∞—â–∞—é—â–∏–π—Å—è –∫–æ–∫—Ç–µ–π–ª—å-–ª–∞—É–Ω–¥–∂, –∏–ª–∏ –±—ã–ª —Ç–∞–∫–æ–≤—ã–º –≤ –¥–æ–≤–æ–µ–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–∞.  –í—Å–µ –±—ã–ª–æ –±–µ–∑—É–ø—Ä–µ—á–Ω–æ —á–∏—Å—Ç—ã–º.  –ü–æ–º–µ—â–µ–Ω–∏–µ –∏–º–µ–ª–æ —Ñ–æ—Ä–º—É –ø–æ–Ω—á–∏–∫–∞, –≤ —Ü–µ–Ω—Ç—Ä–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞—Ö–æ–¥–∏–ª–∞—Å—å —à–∞—Ö—Ç–∞ –ª–∏—Ñ—Ç–∞, –∞ –≤–æ–∫—Ä—É–≥ –Ω–µ–µ –º–µ–¥–ª–µ–Ω–Ω–æ –≤—Ä–∞—â–∞–ª—Å—è –ø–µ–Ω—Ç—Ö–∞—É—Å.  –ë–æ–∫–æ–≤—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –≤—Å–µ–π –∫–æ–º–Ω–∞—Ç—ã –±—ã–ª–∏ —Å—Ç–µ–∫–ª—è–Ω–Ω—ã–º–∏, –∏–∑ –Ω–∏—Ö –º–æ–∂–Ω–æ –±—ã–ª–æ —É–≤–∏–¥–µ—Ç—å –≤–µ—Å—å –≥–æ—Ä–æ–¥ –ù—å—é-–í–µ–≥–∞—Å –∏ –Ω–µ–º–Ω–æ–≥–æ –ú–æ—Ö–∞–≤–µ.  –°–ª–µ–≤–∞ –æ—Ç –Ω–∏—Ö, —á–µ—Ä–µ–∑ –∑–∞–Ω–∞–≤–µ—à–µ–Ω–Ω—ã–π –∞—Ä–æ—á–Ω—ã–π –ø—Ä–æ–µ–º, –Ω–∞—Ö–æ–¥–∏–ª—Å—è –º–∞—Å—Å–∏–≤–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –±–æ–ª—å—à–∏–º–∏ —ç–∫—Ä–∞–Ω–∞–º–∏.  –ò–º–µ–Ω–Ω–æ —Ç—É–¥–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª—è–ª—Å—è –ö—É—Ä—å–µ—Ä.\\n\\n\\n\\n\"–ü—Ä–æ—Å—Ç–æ –¥–∞–π –∑–Ω–∞—Ç—å –æ–¥–Ω–æ–º—É –∏–∑ —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤, –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –≤—ã–ø–∏—Ç—å –∏–ª–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ–µ—Å—Ç—å.  –£ –Ω–∞—Å —Ç—É—Ç –µ—Å—Ç—å... –∫–æ–µ-—á—Ç–æ –∏–∑ –≤—Å–µ–≥–æ\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–£—Å–ª—ã—à–∞–≤ –µ–≥–æ —Å–ª–æ–≤–∞, –î–∂–µ—Å—Å–∏–∫–∞ –Ω–µ–º–Ω–æ–≥–æ –Ω–∞—Ö–º—É—Ä–∏–ª–∞ –±—Ä–æ–≤–∏ –≤ –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–µ. –ö—É—Ä—å–µ—Ä —Å–∫—Ä—ã–ª—Å—è –∑–∞ —à—Ç–æ—Ä–∞–º–∏, –∏ –î–∂–µ—Å—Å–∏–∫–∞ —Ä—ã—Å—å—é –±—Ä–æ—Å–∏–ª–∞—Å—å –∑–∞ –Ω–∏–º, —á—Ç–æ–±—ã –¥–æ–≥–Ω–∞—Ç—å. –û–Ω–∞ —Å—Ö–≤–∞—Ç–∏–ª–∞ –µ–≥–æ –∑–∞ –ø—Ä–∞–≤—É—é —Ä—É–∫—É –∏ —Å–ª–µ–≥–∫–∞ –ø–æ—Ç—è–Ω—É–ª–∞, –∑–∞—Å—Ç–∞–≤–∏–≤ –µ–≥–æ –ø–æ–≤–µ—Ä–Ω—É—Ç—å—Å—è —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω —Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –Ω–µ–µ. \"–ü—É—Å—Ç–æ—à—å - –æ–¥–∏–Ω–æ–∫–æ–µ –∏ —É–∂–∞—Å–Ω–æ–µ –º–µ—Å—Ç–æ, - —Ç–∏—Ö–æ —Å–∫–∞–∑–∞–ª–∞ –æ–Ω–∞, - —Ç–µ–±–µ –Ω–µ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –µ–≥–æ —Ö—É–∂–µ –¥–ª—è —Å–µ–±—è. –ù–∏–∫—Ç–æ –Ω–µ –¥–æ–ª–∂–µ–Ω —Å—Ç–∞–ª–∫–∏–≤–∞—Ç—å—Å—è —Å–æ –≤—Å–µ–º —ç—Ç–∏–º –≤ –æ–¥–∏–Ω–æ—á–∫—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–∑–≤–æ–ª—å –º–Ω–µ —Å–¥–µ–ª–∞—Ç—å —á—Ç–æ-—Ç–æ - —á—Ç–æ —É–≥–æ–¥–Ω–æ - —á—Ç–æ–±—ã –æ—Ç–ø–ª–∞—Ç–∏—Ç—å —Ç–µ–±–µ...\", - –æ–Ω–∞ –∑–∞–ø–Ω—É–ª–∞—Å—å –≤ –∫–æ–Ω—Ü–µ –∏ –∑–∞–¥—É–º—á–∏–≤–æ –ø—Ä–∏–∫—É—Å–∏–ª–∞ –Ω–∏–∂–Ω—é—é –≥—É–±—É.\\n\\n\\n\\n–í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω–∞ –±—ã–ª–∞ —Å–ª–∏—à–∫–æ–º –æ—Ç–∫—Ä–æ–≤–µ–Ω–Ω–∞? –≠—Ç–æ –±—ã–ª–∞ –Ω–µ–∏–∑–≤–µ–¥–∞–Ω–Ω–∞—è —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏—è, –∫–æ–≥–¥–∞ –º—É–∂—á–∏–Ω–∞ –Ω–µ —Ö–æ—Ç–µ–ª –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –µ—é –∏–ª–∏ –¥–∞–∂–µ –ø–æ–ª—É—á–∏—Ç—å —Å–≤–æ–π –¥–æ–ª–≥. –û–Ω–∞ –Ω–µ —Ö–æ—Ç–µ–ª–∞, —á—Ç–æ–±—ã –º–µ–∂–¥—É –Ω–∏–º–∏ –æ—Å—Ç–∞–≤–∞–ª—Å—è –∫–∞–∫–æ–π-—Ç–æ –¥–æ–ª–≥, –Ω–æ –Ω–∞—á–∏–Ω–∞–ª–æ –∫–∞–∑–∞—Ç—å—Å—è, —á—Ç–æ –∫—É—Ä—å–µ—Ä –Ω–µ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –ø–æ–∑–≤–æ–ª–∏—Ç—å –µ–π —Ä–∞—Å–ø–ª–∞—Ç–∏—Ç—å—Å—è —Å –Ω–∏–º.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –ø–æ–≤–µ—Ä–Ω—É–ª—Å—è –∏ –∑–∞–≥–æ–≤–æ—Ä–∏–ª –±—ã—Å—Ç—Ä–æ –∏ —Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ.  –ï–≥–æ –≤–æ–ø—Ä–æ—Å –±—ã–ª –ø–æ—Ö–æ–∂ –Ω–∞ –ø—É–ª—é.  –í—Å–µ —Ç–∞–∫ –∂–µ —Å–ø–æ–∫–æ–π–Ω–æ, –Ω–æ —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –±–æ–ª—å—à–µ –ø–æ–¥—Ö–æ–¥–∏–ª–æ –∫ –µ–≥–æ –≥—Ä—É–±–æ–≤–∞—Ç–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏, —á–µ–º –∫ –µ–≥–æ –æ–±—ã—á–Ω–æ–º—É –≥–æ–ª–æ—Å—É.\\n\\n\\n\\n–û–Ω —Å–ø—Ä–æ—Å–∏–ª –µ–µ: \"–¢—ã –∏—â–µ—à—å, —á—Ç–æ–±—ã —è –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è —Ç–æ–±–æ–π?  –≠—Ç–æ —Ç–æ, —á—Ç–æ —Ç—ã –ø–æ–ª—É—á–∏—à—å –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ –º–µ—Å—Ç –ø–æ–±–ª–∏–∑–æ—Å—Ç–∏\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–û—à–µ–ª–æ–º–ª–µ–Ω–Ω–∞—è –µ–≥–æ –≤–Ω–µ–∑–∞–ø–Ω–æ–π —Å–∏–ª–æ–≤–æ–π —Ä–µ–∞–∫—Ü–∏–µ–π, –æ–Ω–∞ –æ—Ç–ø—É—Å–∫–∞–µ—Ç –µ–≥–æ —Ä—É–∫—É –∏, —Å–ø–æ—Ç—ã–∫–∞—è—Å—å, –æ—Ç—Å—Ç—É–ø–∞–µ—Ç –æ—Ç –Ω–µ–≥–æ. \"–Ø... –Ω–µ—Ç, —è –ø—Ä–æ—Å—Ç–æ —Ö–æ—á—É –ø–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å —Ç–µ–±—è –∑–∞ —Ç–æ, —á—Ç–æ —Ç—ã –ø–æ–º–æ–≥ –º–Ω–µ. –Ø –¥–æ–ª–∂–Ω–∞ —Ö–æ—Ç—è –±—ã –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è, –Ω–µ —Ç–∞–∫ –ª–∏?\"\\n\\n\\n\\n–ï–µ –≥–ª–∞–∑–∞ –Ω–µ–º–Ω–æ–≥–æ —Å–ª–µ–∑—è—Ç—Å—è, –∏ –æ–Ω–∞ —Å–∂–∏–º–∞–µ—Ç –∏—Ö, –∫–∞–∫ –±—ã –Ω–µ –¥–∞–≤–∞—è —Å–ª–µ–∑–∞–º –≤—ã–π—Ç–∏ –Ω–∞—Ä—É–∂—É. –≠—Ç–∞ –ø—Ä–∏–≤—ã—á–∫–∞ —É –Ω–µ–µ —Å –¥–µ—Ç—Å—Ç–≤–∞, –î–∂–µ—Å—Å–∏–∫–∞ –≤—Å–µ–≥–¥–∞ –ø–ª–∞–∫–∞–ª–∞, –∫–æ–≥–¥–∞ –±—ã–ª–∞ —Å–ª–∏—à–∫–æ–º –Ω–∞–ø—Ä—è–∂–µ–Ω–∞ –∏–ª–∏ —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–∞. \"–ù–µ –ø–ª–∞—á—å!\" - –º—ã—Å–ª–µ–Ω–Ω–æ –ø—Ä–∏–∫–∞–∑—ã–≤–∞–µ—Ç –æ–Ω–∞ —Å–µ–±–µ, –Ω–æ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –Ω–∞–ø—Ä–∞—Å–Ω–æ.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ï–≥–æ –≥–æ–ª–æ—Å —Å–º—è–≥—á–∏–ª—Å—è, –∫–æ–≥–¥–∞ –æ–Ω —É–≤–∏–¥–µ–ª, —á—Ç–æ –æ–Ω–∞ —Ç–∞–∫ –∫—Ä–µ–ø–∫–æ –∑–∞–∫—Ä—ã–ª–∞ –≥–ª–∞–∑–∞.  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª.  \"–°–ª—É—à–∞–π, –º–Ω–µ –æ—á–µ–Ω—å –∂–∞–ª—å.  –Ø –ø—Ä–æ—Å—Ç–æ –Ω–µ –ø—Ä–∏–≤—ã–∫ –∫ —Ç–∞–∫–æ–º—É.  –ú–Ω–µ –Ω–∏—á–µ–≥–æ –æ—Ç —Ç–µ–±—è –Ω–µ –Ω—É–∂–Ω–æ, –î–∂–µ—Å—Å–∏–∫–∞... –æ–≥–ª—è–Ω–∏—Å—å –≤–æ–∫—Ä—É–≥.  –£ –º–µ–Ω—è –µ—Å—Ç—å –≤—Å–µ, —á—Ç–æ –º–Ω–µ –Ω—É–∂–Ω–æ, —ç—Ç–æ...\"\\n\\n\\n\\n–û–Ω –ø–æ–∫–∞—á–∞–ª –≥–æ–ª–æ–≤–æ–π, –≤—ã–≥–ª—è–¥—è –≤–Ω–µ–∑–∞–ø–Ω–æ –ø–æ–±–µ–∂–¥–µ–Ω–Ω—ã–º.  –°–¥–µ–ª–∞–≤ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∂–µ—Å—Ç –≤ —Å—Ç–æ—Ä–æ–Ω—É –æ–∫–Ω–∞, –æ–Ω –∑–∞–≥–æ–≤–æ—Ä–∏–ª –≥–æ—Ä–∞–∑–¥–æ —Ç–∏—à–µ.  \"–≠—Ç–æ –ª—é–¥–∏ —Ç–∞–º, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Ö –Ω–µ—Ç.  –Ø –ø—ã—Ç–∞—é—Å—å —Å–¥–µ–ª–∞—Ç—å –≤—Å–µ, —á—Ç–æ –≤ –º–æ–∏—Ö —Å–∏–ª–∞—Ö, –Ω–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫ –ø—Ä–æ—Å—Ç–æ, –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–¥–∞—Ç—å –≤–µ—â–∏.  –≠—Ç–æ –∏–º –Ω—É–∂–Ω–∞ —Ç–≤–æ—è —Ç—è–∂–µ–ª–∞—è —Ä–∞–±–æ—Ç–∞, –∞ –Ω–µ –º–Ω–µ.  –Ø –ø—Ä–æ—Å—Ç–æ —Å—Ç–∞—Ä–∞—é—Å—å –¥–µ–ª–∞—Ç—å —Ç–æ, —á—Ç–æ –º–æ–≥—É, —á–µ–≥–æ –Ω–µ —Å–¥–µ–ª–∞–µ—Ç –∫—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–π\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–û–Ω–∞ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –≥–ª–∞–∑–∞, –∏ —Å–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Å–ª–µ–∑—ã –≤—ã—Ä—ã–≤–∞—é—Ç—Å—è –Ω–∞—Ä—É–∂—É, —Ä–∞–∑–ª–∏–≤–∞—è—Å—å –ø–æ —â–µ–∫–∞–º. –û–Ω–∞ —É–∂–µ –Ω–µ –ø–ª–∞—á–µ—Ç, –Ω–æ –ø—Ä–µ–¥–∞—Ç–µ–ª—å—Å–∫–∏–µ —Å–ª–µ–∑—ã –Ω–µ —É—Ç–∏—Ö–∞—é—Ç. \"–ü—Ä–æ—Å—Ç–∏, —á—Ç–æ –±—ã–ª–∞ —Ç–∞–∫–æ–π –Ω–∞—Å—Ç–æ–π—á–∏–≤–æ–π, - –±–æ—Ä–º–æ—á–µ—Ç –æ–Ω–∞, - —è –ø—Ä–æ—Å—Ç–æ —Ö–æ—Ç–µ–ª–∞ –æ—Ç–ø–ª–∞—Ç–∏—Ç—å –∑–∞ —Ç–≤–æ—é –¥–æ–±—Ä–æ—Ç—É. –¢—ã –º–Ω–æ–≥–æ–µ —Å–¥–µ–ª–∞–ª –¥–ª—è –ù—å—é-–í–µ–≥–∞—Å–∞ –∏ –µ–≥–æ –∂–∏—Ç–µ–ª–µ–π, —è –º–æ–≥—É —Å–∫–∞–∑–∞—Ç—å. –¢—ã –Ω–µ –¥–æ–ª–∂–µ–Ω –Ω–æ—Å–∏—Ç—å –≤ —Å–µ–±–µ —Å—Ç–æ–ª—å–∫–æ —á—É–≤—Å—Ç–≤–∞ –≤–∏–Ω—ã! –≠—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–¥–æ—Ä–æ–≤—ã–º\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –≥–ª—É–±–æ–∫–æ –≤–¥–æ—Ö–Ω—É–ª, –∫–æ–≥–¥–∞ —É–≤–∏–¥–µ–ª, —á—Ç–æ –æ–Ω–∞ –ø–ª–∞—á–µ—Ç, –∏ –Ω–∞ –º–≥–Ω–æ–≤–µ–Ω–∏–µ –æ—Ç–≤–µ—Ä–Ω—É–ª –≥–æ–ª–æ–≤—É.  –ö–æ–≥–¥–∞ –æ–Ω —Å–Ω–æ–≤–∞ –∑–∞–≥–æ–≤–æ—Ä–∏–ª, –µ–≥–æ –≥–æ–ª–æ—Å —Å–Ω–æ–≤–∞ –±—ã–ª –±–æ–ª–µ–µ —Ä–æ–≤–Ω—ã–º.  \"–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ, —á—Ç–æ —è –º–æ–≥—É —Å–¥–µ–ª–∞—Ç—å, - —ç—Ç–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ú–æ—Ö–∞–≤–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–º, –∏ —É–ø—Ä–∞–≤–ª—è—Ç—å –∏–º –∫–∞–∫ –º–æ–∂–Ω–æ –ª—É—á—à–µ.  –Ø –º–æ–≥—É –∏ –±—É–¥—É –ª–∏—á–Ω–æ —Ä–µ—à–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –∫–æ–≥–¥–∞ —Å–º–æ–≥—É... –∏ —è –∏—Ö —Ä–µ—à–∞–ª.  –•–æ—Ç—è –º–Ω–µ –ª—é–±–æ–ø—ã—Ç–Ω–æ...\"  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª, –ø–æ–Ω–∏–º–∞—è, —á—Ç–æ —Å–µ–π—á–∞—Å –ø–æ–∂–∞–ª–µ–µ—Ç –æ —Ç–æ–º, —á—Ç–æ —Å–ø—Ä–æ—Å–∏–ª: \"–¢—ã —Å–∫–∞–∑–∞–ª, —á—Ç–æ –õ–µ–≥–∏–æ–Ω –Ω–∞–ø–∞–ª –Ω–∞ —Ç–≤–æ—é –¥–µ—Ä–µ–≤–Ω—é –∏–ª–∏ –≥–æ—Ä–æ–¥.  –ö–æ–≥–¥–∞ —ç—Ç–æ –±—ã–ª–æ?  –ü–æ—Å–ª–µ —Å–º–µ—Ä—Ç–∏ –¶–µ–∑–∞—Ä—è –∏ –õ–∞–Ω–∏—è –º–Ω–µ –≤—Å–µ–≥–¥–∞ –±—ã–ª–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ, —á—Ç–æ —Å –Ω–∏–º–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç.  –ò—Ö –≤—Å–µ–≥–¥–∞ —É–¥–µ—Ä–∂–∏–≤–∞–ª–∞ –≤–º–µ—Å—Ç–µ —Ö–∞—Ä–∏–∑–º–∞ –¶–µ–∑–∞—Ä—è\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"–ù–∞–ø–∞–¥–µ–Ω–∏–µ –õ–µ–≥–∏–æ–Ω–∞ –±—ã–ª–æ –ø–æ—á—Ç–∏ –≥–æ–¥ –Ω–∞–∑–∞–¥, - —Å–∫–∞–∑–∞–ª–∞ –æ–Ω–∞, –≤—Å–µ –µ—â–µ –Ω–µ–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–æ–∫–æ–µ–Ω–Ω–∞—è –æ–±—Ä–∞–∑–∞–º–∏, –≤–ø–µ—á–∞—Ç–∞–Ω–Ω—ã–º–∏ –≤ –µ–µ —Å–æ–∑–Ω–∞–Ω–∏–µ, - –≠—Ç–æ –±—ã–ª–æ... —É–∂–∞—Å–Ω–æ. –ö–∞–∫ –±—É–¥—Ç–æ –≤–µ—Å—å –º–∏—Ä –≤–Ω–µ–∑–∞–ø–Ω–æ –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª—Å—è –≤ –∞–¥: –æ–≥–æ–Ω—å, —à—Ç–∞–±–µ–ª—è —Ç—Ä—É–ø–æ–≤ –∏... –ª—é–¥–∏, –ø—Ä–∏–±–∏—Ç—ã–µ –∫ –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–º –∫—Ä–µ—Å—Ç–∞–º...\"\\n\\n\\n\\n–û–Ω–∞ –≤–∑–¥—Ä–∞–≥–∏–≤–∞–µ—Ç –æ—Ç –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏ –ø–æ–¥–Ω–∏–º–∞–µ—Ç –Ω–∞ –Ω–µ–≥–æ –≥–ª–∞–∑–∞. \"–Ø –Ω–µ –∑–Ω–∞—é —Ç–æ—á–Ω–æ, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å –õ–µ–≥–∏–æ–Ω–æ–º –≤ —Ü–µ–ª–æ–º, –Ω–æ —ç—Ç–æ –±—ã–ª–∞ –¥–æ–≤–æ–ª—å–Ω–æ –±–æ–ª—å—à–∞—è –≥—Ä—É–ø–ø–∞, –¥–µ—Ä–∂–∞–≤—à–∞—è –ª–∞–≥–µ—Ä—å –Ω–µ —Ç–∞–∫ —É–∂ –¥–∞–ª–µ–∫–æ –æ—Ç –ù—å—é-–í–µ–≥–∞—Å–∞.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n\"–ú–Ω–µ –∂–∞–ª—å, —á—Ç–æ —ç—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å... –Ω–æ... –≤–æ–∑–º–æ–∂–Ω–æ, —Ç—ã –±—É–¥–µ—à—å —Ä–∞–¥ —É–∑–Ω–∞—Ç—å, —á—Ç–æ —á–µ–ª–æ–≤–µ–∫, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞ –≤—Å–µ —ç—Ç–∏ –∑–∞–≤–æ–µ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–∞–º–ø–∞–Ω–∏–∏, –º–µ—Ä—Ç–≤\".  –û–Ω –∫–∏–≤–Ω—É–ª, –ø–æ–ª–æ–∂–∏–≤ —Ä—É–∫—É –µ–π –Ω–∞ –ø–ª–µ—á–æ.  \"–õ–µ–≥–∏–æ–Ω —Ç–≤–æ—Ä–∏–ª —É–∂–∞—Å–Ω—ã–µ –≤–µ—â–∏ –ø–æ –≤—Å–µ–º—É... —á–µ—Ä—Ç, –¥–∞ –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ –∫ –≤–æ—Å—Ç–æ–∫—É –æ—Ç—Å—é–¥–∞\".  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª.  \"NCR, –Ω—É... –æ–Ω–∏ –∫—Ä–∞–¥—É—Ç –≤–µ—â–∏ –Ω–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –∏ –º–µ–Ω–µ–µ –∂–µ—Å—Ç–æ–∫–æ.  –ù–æ –ª—é–¥–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ —Ç–µ—Ä—è—é—Ç —Ç–æ, —á—Ç–æ —É –Ω–∏—Ö –µ—Å—Ç—å\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"NCR? –ú–Ω–µ... –∫–∞–∂–µ—Ç—Å—è, –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ –Ω–∞—Å –∑–∞—â–∏—â–∞—Ç—å\", - –≥–æ–≤–æ—Ä–∏—Ç –æ–Ω–∞, –Ω–∞—Ö–º—É—Ä–∏–≤ –±—Ä–æ–≤–∏ –∏ –∑–∞–¥—É–º—á–∏–≤–æ –ø–æ–∫—É—Å—ã–≤–∞—è –Ω–∏–∂–Ω—é—é –≥—É–±—É, - \"–ù–æ... –æ–Ω–∏ —Ç–∞–∫ –∏ –Ω–µ –ø—Ä–∏—à–ª–∏\".\\n\\n\\n\\n–ï–µ –∑–Ω–∞–Ω–∏—è –æ –¥–≤—É—Ö —Ñ—Ä–∞–∫—Ü–∏—è—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã, —Ç–∞–∫ –∫–∞–∫ –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –∂–∏–∑–Ω–∏ –æ–Ω–∞ –ø—Ä–æ–∂–∏–ª–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ, –Ω–æ —É –Ω–µ–µ —É–∂–µ —Å–ª–æ–∂–∏–ª–æ—Å—å –∫—Ä–∞–π–Ω–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –º–Ω–µ–Ω–∏–µ –æ –Ω–∏—Ö.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –Ω–µ–µ –∏ –ø–æ–¥–Ω—è–ª —Ä—É–∫—É, —Å–Ω–∏–º–∞—è —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏.  –ü–æ–¥ –Ω–∏–º–∏ –±—ã–ª–∏ –≥–ª–∞–∑–∞, –∫–æ—Ç–æ—Ä—ã–µ\\n–∏–∑–º—É—á–µ–Ω–Ω—ã–µ\\n.  –ü–æ–¥ –Ω–∏–º–∏ –±—ã–ª–∏ —á–µ—Ä–Ω—ã–µ –º–µ—à–∫–∏, –∏ –æ–Ω–∏ —Å–ª–µ–≥–∫–∞ –Ω–∞–ª–∏–ª–∏—Å—å –∫—Ä–æ–≤—å—é.  –ó–∞ –≤—Å–µ–º —ç—Ç–∏–º –±—ã–ª–æ –≤–∏–¥–Ω–æ, —á—Ç–æ —É –Ω–µ–≥–æ –ø–æ—Ç—Ä—è—Å–∞—é—â–∏–µ —è—Ä–∫–æ-–≥–æ–ª—É–±—ã–µ –≥–ª–∞–∑–∞, –≤–∑–≥–ª—è–¥ –∫–æ—Ç–æ—Ä—ã—Ö –±—ã–ª –æ—á–µ–Ω—å –º—è–≥–∫–∏–º –∏ –¥–æ–±—Ä—ã–º.  –ù–∞–∫–æ–Ω–µ—Ü –æ–Ω –ø–æ–ª–æ–∂–∏–ª –≤–∏–Ω—Ç–æ–≤–∫—É –Ω–∞ —Å—Ç–æ–ª —Ä—è–¥–æ–º —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–∞–º–∏.\\n\\n\\n\\r\\n\"–î–∂–µ—Å—Å–∏–∫–∞, —è –±–µ—Å–ø–æ–∫–æ—é—Å—å –æ —Å—Ç–æ–ª—å–∫–∏—Ö –≤–µ—â–∞—Ö –≤ —ç—Ç–æ–º –º–µ—Å—Ç–µ, –∏ —è –Ω–µ... –£ –º–µ–Ω—è –Ω–µ –±—ã–ª–æ...\"  –û–Ω –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –∏ –ø–æ–∫–∞—á–∞–ª –≥–æ–ª–æ–≤–æ–π.  \"–ù–µ—Ç, –∏–∑–≤–∏–Ω–∏, –Ω–µ –±–µ—Ä–∏ –≤ –≥–æ–ª–æ–≤—É\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–ù–µ–∂–Ω–æ —É–ª—ã–±–Ω—É–≤—à–∏—Å—å, –î–∂–µ—Å—Å–∏–∫–∞ —Å–æ–∫—Ä–∞—Ç–∏–ª–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –Ω–∏–º–∏. –û–Ω–∞ –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ –ø–æ–ª–æ–∂–∏–ª–∞ —Ä—É–∫—É –µ–º—É –Ω–∞ –≥—Ä—É–¥—å –∏ —Å–∫–∞–∑–∞–ª–∞: \"–î–∞–≤–∞–π, —Ä–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ. –ß—Ç–æ —è –º–æ–≥—É –¥–ª—è —Ç–µ–±—è —Å–¥–µ–ª–∞—Ç—å?\"<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –Ω–µ–Ω–∞–¥–æ–ª–≥–æ –∑–∞–∫—Ä—ã–ª –≥–ª–∞–∑–∞ –∏ –ø—Ä–æ–º—É—Ä–ª—ã–∫–∞–ª: \"–Ø –Ω–µ –±—ã–ª —Å –∂–µ–Ω—â–∏–Ω–æ–π —É–∂–µ... –æ—á–µ–Ω—å –¥–∞–≤–Ω–æ.  –Ø –æ—Ç–∫–∞–∑—ã–≤–∞—é—Å—å –ø–ª–∞—Ç–∏—Ç—å –∑–∞ —ç—Ç–æ, —Ç–∞–∫ –∫–∞–∫, –Ω—É, —ç—Ç–æ –≤—Å–µ –µ—â–µ –æ–ø–∞—Å–Ω–æ.  –Ø –Ω–µ –±—É–¥—É –º–µ—à–∞—Ç—å –∂–µ–Ω—â–∏–Ω–∞–º –¥–µ–ª–∞—Ç—å —ç—Ç–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –∏—Ö –∂–∏–∑–Ω—å, –Ω–æ... –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ\".  –û–Ω –≤–∑–¥–æ—Ö–Ω—É–ª, –ø–æ–Ω–∏–º–∞—è, —á—Ç–æ –±–æ—Ä–º–æ—á–µ—Ç.  \"–Ø –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–ª, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ —Ç–∞–∫ –∂–µ –ø–ª–æ—Ö–æ.  –ü–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–µ–º, —á—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ –æ—Ç–ø–ª–∞—Ç–∏—Ç—å –º–Ω–µ, –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ, –∏ —è –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–æ—Å–∏—Ç—å.  –≠—Ç–æ –±—ã–ª –ø—Ä–æ—Å—Ç–æ... –º–∏–Ω—É—Ç–Ω—ã–π –ø—Ä–æ–º–∞—Ö –æ—Ç —Ç–æ–≥–æ, —á—Ç–æ —è –±—ã–ª –Ω–µ–º–Ω–æ–≥–æ –æ–±–¥–µ–ª–µ–Ω\".  –û–Ω —Å–ª–µ–≥–∫–∞ —É–ª—ã–±–Ω—É–ª—Å—è, –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –≤—ã–≥–ª—è–¥—è –Ω–µ–º–Ω–æ–≥–æ —Å–º—É—â–µ–Ω–Ω—ã–º.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"–ß—Ç–æ –∂, - –¥—É–º–∞–µ—Ç –æ–Ω–∞ –ø—Ä–æ —Å–µ–±—è, - –Ω–µ —Ç–æ —á—Ç–æ–±—ã —è —ç—Ç–æ–≥–æ –Ω–µ –ø—Ä–µ–¥–≤–∏–¥–µ–ª–∞\".\\n\\n\\n\\n–î–∂–µ—Å—Å–∏–∫–∞ –Ω–∞–∫–ª–æ–Ω—è–µ—Ç—Å—è –∏ –º—è–≥–∫–æ —Ü–µ–ª—É–µ—Ç –µ–≥–æ –≤ –≥—É–±—ã, –ø–æ—Å–ª–µ —á–µ–≥–æ –æ—Ç—Å—Ç—É–ø–∞–µ—Ç, –Ω–∞–±–ª—é–¥–∞—è –∑–∞ –µ–≥–æ —Ä–µ–∞–∫—Ü–∏–µ–π. \"–¢—ã –Ω–µ –ø–æ–ª—å–∑—É–µ—à—å—Å—è –º–Ω–æ–π, —Ç–µ–±–µ –Ω–µ –Ω—É–∂–Ω–æ –ø–ª–∞—Ç–∏—Ç—å –∏ –¥–∞–∂–µ –Ω–µ –Ω—É–∂–Ω–æ –ø—Ä–æ—Å–∏—Ç—å. –ü—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–π —Ç–æ, —á—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç —Å–∞–º–æ —Å–æ–±–æ–π...\", - –æ–Ω–∞ –æ—Ç—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è, –Ω–∞ –µ–µ –ª–∏—Ü–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è —É–ª—ã–±–∫–∞.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –ø–æ—Å–º–æ—Ç—Ä–µ–ª –≤ –µ–µ –≥–ª–∞–∑–∞, –∏ –≤–∑–≥–ª—è–¥ –µ–≥–æ –±—ã–ª –¥–∞–ª–µ–∫–∏–º, –ø–µ—á–∞–ª—å–Ω—ã–º.  –ó–∞—Ç–µ–º –æ–Ω —É–ª—ã–±–Ω—É–ª—Å—è, –µ–¥–≤–∞ –∑–∞–º–µ—Ç–Ω–æ, –∫–æ–≥–¥–∞ –µ–≥–æ —Ä—É–∫–∏ —É—Ö–≤–∞—Ç–∏–ª–∏—Å—å –∑–∞ –µ–µ –∑–∞–ø—è—Å—Ç—å—è –∏ –ø—Ä–∏—Ç—è–Ω—É–ª–∏ –µ–µ –±–ª–∏–∂–µ –∫ —Å–µ–±–µ.  –ë—ã–ª–æ –Ω–µ–æ—Å–ø–æ—Ä–∏–º–æ, —á—Ç–æ –æ–Ω —Ö–æ—á–µ—Ç –µ–µ, —á—Ç–æ –æ–Ω —Ö–æ—á–µ—Ç —Å–µ–∫—Å–∞, –∏ —á—Ç–æ –ø—Ä–æ—à–ª–∞ —Ü–µ–ª–∞—è –≤–µ—á–Ω–æ—Å—Ç—å —Å —Ç–µ—Ö –ø–æ—Ä, –∫–∞–∫ –æ–Ω –¥–µ–ª–∞–ª —ç—Ç–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑.  –°–¥–µ–ª–∞–≤ —à–∞–≥ –≤–ø–µ—Ä–µ–¥, –æ–Ω —Ç–æ–ª–∫–Ω—É–ª –µ–µ —Ç–∞–∫, —á—Ç–æ –∑–∞–¥–Ω–∏–µ —á–∞—Å—Ç–∏ –µ–µ –±–µ–¥–µ—Ä –∫–æ—Å–Ω—É–ª–∏—Å—å –ø—É—Å—Ç–æ–≥–æ —Å—Ç–æ–ª–∞.  –ï–≥–æ –≥–ª–∞–∑–∞ —Å–º–æ—Ç—Ä–µ–ª–∏ –Ω–∞ –Ω–µ–µ —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑, –∞ —Ä—É–∫–∏ —Å–∫–æ–ª—å–∑–∏–ª–∏ –≤–≤–µ—Ä—Ö –ø–æ –µ–µ —Ä—É–∫–∞–º.\\n\\n\\n\\n\"–Ø –º–æ–≥—É –±—ã—Ç—å –Ω–µ–º–Ω–æ–≥–æ –≥—Ä—É–±—ã–º\", - –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏–ª –æ–Ω.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fc512892c31c4c3589d74aa9a5b7a038",
            "1e1e1fdc2fc14e95b42a5fc5241d78fa",
            "1485158611c54b718d894b4ae3786e0f",
            "caf42e0cc1ec4a09989b2000332ae2cc",
            "28853f5ef0d140f59bc8011dd844b8fd",
            "b0474b3caa9e474480e15d5c0fc94cb8",
            "5b1f5b135ed347b68104ca365363dbe2",
            "3284d646e8174b278a8a413acd7dd591",
            "f081b07e7cbb40dd8643f1c98284dbe9",
            "42cad95e52954d68b28ced2ee2c5ebaa",
            "c028c13e59cd44d88a0bbd0d46b01ed2"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "7389d2cf-2256-48cf-cd85-7fe9b13f6fd2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/11686 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc512892c31c4c3589d74aa9a5b7a038"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7cd74425b59b48a9beefe9c5162678ca",
            "301ec1f21c5e4781884b0ebd7a9e2905",
            "2a4d7b28b554467cba961703de59885c",
            "8820d521701d433e952db0f129a7c43d",
            "d47c5524c2874ee5a89d47bbce02de47",
            "baf67f6c8cd54218acbab404bf3e7f46",
            "73857c60f53142b48bcb3061bb38c725",
            "7c4218ac2f7e49cea3408fb52b5dec15",
            "b56e94ba693d405ab4e7fe40bfccc1cc",
            "a962c6fbabc74b73b1bdfb0fc7f02bdb",
            "986c65a923334cff9a87fbbc1b70a2c2"
          ]
        },
        "id": "juQiExuBG5Bt",
        "outputId": "0665371c-4d1c-4953-c375-77da14a8587a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11686 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cd74425b59b48a9beefe9c5162678ca"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "LtsMVtlkUhja",
        "outputId": "6738e010-535c-4851-982d-ddc0a057d9d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n((ooc: –Ω–∞–∂–º–∏ –Ω–∞ —Ö–æ—Ç–ª–∏–Ω–∫–∏, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Ç–æ–≥–æ, —á—Ç–æ –Ω–æ—Å–∏—Ç/–¥–µ—Ä–∂–∏—Ç –ö—É—Ä—å–µ—Ä ^_^))\\n\\n\\n\\r\\n–§—Ä–∏—Å–∞–π–¥ –±—ã–ª —Ç–∞–∫–∏–º –∂–µ, –∫–∞–∫ –∏ –ø–æ—Å–ª–µ –ø–æ–±–µ–¥—ã –ö—É—Ä—å–µ—Ä–∞ –ø–æ—á—Ç–∏ –º–µ—Å—è—Ü –Ω–∞–∑–∞–¥.  –õ—é–¥–µ–π —Å—Ç–∞–ª–æ –±–æ–ª—å—à–µ, –∏ –æ–Ω–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, –≤—ã–≥–ª—è–¥–µ–ª–∏ –∑–¥–æ—Ä–æ–≤–µ–µ.  –†–∞–∑–ª–∏—á–∏—è –±—ã–ª–∏ —á—É—Ç—å –±–æ–ª–µ–µ —Ç–æ–Ω–∫–∏–º–∏: –∑–¥–∞–Ω–∏—è –≤—ã–≥–ª—è–¥–µ–ª–∏ —á—É—Ç—å —á–∏—â–µ, –ª—é–¥–∏ –Ω–æ—Å–∏–ª–∏ –±–æ–ª–µ–µ –∫—Ä–∞—Å–∏–≤—É—é –æ–¥–µ–∂–¥—É.  –¢—Ä—É–ø—ã –±—ã–ª–∏ —É–±—Ä–∞–Ω—ã.  –î–∞–∂–µ –≤ –°—Ç–∞—Ä–æ–º –º–æ—Ä–º–æ–Ω—Å–∫–æ–º —Ñ–æ—Ä—Ç–µ —Ç–µ–ø–µ—Ä—å –±—ã–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–µ –ø–æ—Å—Ç—Ä–æ–π–∫–∏.  –û–Ω–∏ –≤—Å–µ –µ—â–µ –±—ã–ª–∏ –¥–æ–≤–æ–ª—å–Ω–æ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–º–∏, –Ω–æ —Ç–µ–ø–µ—Ä—å –æ–Ω–∏ –º–æ–≥–ª–∏ –ø—Ä–∏–≤–æ–∑–∏—Ç—å —Ç—É–¥–∞ –±–æ–ª—å—à–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —Ç–µ—Ö–Ω–∏–∫–∏ –∏ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤, –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –∏–º —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å –ø–æ—Ç–æ–∫–æ–º —Ä–∞–Ω–µ–Ω—ã—Ö –ø–æ—Å–ª–µ –í—Ç–æ—Ä–æ–π –±–∏—Ç–≤—ã –∑–∞ –¥–∞–º–±—É –ì—É–≤–µ—Ä–∞.\\n\\n\\n\\r\\n–í–æ—Ç –æ–Ω —à–µ–ª –ø–æ —Ü–µ–Ω—Ç—Ä—É –§—Ä–∏—Å–∞–π–¥–∞, –æ–¥–µ—Ç—ã–π –≤ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π\\n–ø—ã–ª—å–Ω–∏–∫\\n –≤ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–π –æ–¥–µ–∂–¥–µ.  –£ –Ω–µ–≥–æ –±—ã–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–µ, –Ω–µ–∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ —á–µ—Ä–Ω—ã–µ –≤–æ–ª–æ—Å—ã –∏ –≥—É—Å—Ç–∞—è –∫–æ–∑–ª–∏–Ω–∞—è –±–æ—Ä–æ–¥–∫–∞.  –í —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å –µ–≥–æ\\n—Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–º–∏ –æ—á–∫–∞–º–∏\\n –∏\\n–±–∞–Ω–¥–∞–Ω–æ–π\\n–æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –≤—ã–¥–µ–ª—è–ª—Å—è —Å—Ä–µ–¥–∏ –±–µ–¥–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π.  –ï–≥–æ —É–≤–µ—Ä–µ–Ω–Ω–∞—è –ø–æ—Ö–æ–¥–∫–∞, —Ü–µ–ª–µ—É—Å—Ç—Ä–µ–º–ª–µ–Ω–Ω–æ—Å—Ç—å, —Å –∫–æ—Ç–æ—Ä–æ–π –æ–Ω –¥–≤–∏–≥–∞–ª—Å—è, –∏ –æ—Ç–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —á–µ—Ä–Ω–∞—è\\n—à—Ç—É—Ä–º–æ–≤–∞—è –≤–∏–Ω—Ç–æ–≤–∫–∞\\n (—Å –ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç–≤–æ–ª–æ–º –∏–∑ —Å–µ—Ä–µ–±—Ä–∏—Å—Ç–æ–≥–æ –º–µ—Ç–∞–ª–ª–∞) –ø—Ä–∏–¥–∞–≤–∞–ª–∏ –µ–º—É –≤–ª–∞—Å—Ç–Ω—ã–π –≤–∏–¥.  –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø—Ä–æ—Ö–æ–∂–∏—Ö –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª–∏ –µ–≥–æ, —Ö–æ—Ç—è –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∫–∞–∑—ã–≤–∞–ª–∏ –ø–∞–ª—å—Ü–µ–º –∏ –ø–µ—Ä–µ—à–µ–ø—Ç—ã–≤–∞–ª–∏—Å—å –Ω–∞ —Ç–∏—Ö–∏—Ö —Ç–æ–Ω–∞—Ö, –∫–æ–≥–¥–∞ –æ–Ω –ø—Ä–æ—Ö–æ–¥–∏–ª –º–∏–º–æ.  –ö–∞–∑–∞–ª–æ—Å—å, –æ–Ω –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –æ–ø–∏—Å–∞–Ω–∏—è–º –ø—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ –∏ –≥–æ—Ä–æ–∂–∞–Ω, \"–ö—É—Ä—å–µ—Ä–∞ –®–µ—Å—Ç—å\", –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –∏–º–µ–Ω–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ, –ø–æ—Ö–æ–∂–µ, –Ω–∏–∫—Ç–æ –Ω–µ –∑–Ω–∞–ª.  –û–Ω –¥–æ–ª–∂–µ–Ω –±—ã–ª –±—ã—Ç—å –¥–æ–±—Ä—ã–º –∏ –æ—Ç–∑—ã–≤—á–∏–≤—ã–º, –∞... –Ω—É, —ç—Ç–æ—Ç —á–µ–ª–æ–≤–µ–∫ –≤—ã–≥–ª—è–¥–µ–ª –æ–ø–∞—Å–Ω—ã–º.  –ú–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å, –∫—Ä—É—Ç—ã–º, –∫–æ–≥–¥–∞ –æ–Ω –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞–ª —É–ª–∏—Ü—ã.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–ü–æ—Å–ª–µ –ø–æ–±–µ–≥–∞ –î–∂–µ—Å—Å–∏–∫–∞ –ø–æ–Ω—è–ª–∞, —á—Ç–æ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –º–µ—Å—Ç–æ, –∫—É–¥–∞ –æ–Ω–∞ –º–æ–∂–µ—Ç –ø–æ–π—Ç–∏ –∏ –Ω–∞–π—Ç–∏ —Ö–æ—Ç—å –∫–∞–∫—É—é-—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –ù—å—é-–í–µ–≥–∞—Å. –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞—â–∏—â–µ–Ω–Ω—ã–π –∑–∞–≥–∞–¥–æ—á–Ω—ã–º \"–ö—É—Ä—å–µ—Ä–æ–º\" –∏ –µ–≥–æ –∞—Ä–º–∏–µ–π —Å–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω–æ–≤, –æ–Ω –±—ã–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –õ–µ–≥–∏–æ–Ω–∞ –¶–µ–∑–∞—Ä–µ–π, –≥—Ä—É–ø–ø—ã, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Ä–∞–±–æ—Ç–∏–ª–∞ –µ–µ –ø–æ—á—Ç–∏ –Ω–∞ –≥–æ–¥.\\n\\n\\n\\r\\n–£ –Ω–µ–µ –Ω–µ –±—ã–ª–æ –∫—Ä—ã—à–µ–∫, —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ –°—Ç—Ä–∏–ø. –≠—Ç–æ —É–∂ —Ç–æ—á–Ω–æ. –°–µ–∫—å—é—Ä–∏—Ç—Ä–æ–Ω—ã —Å—Ä–∞–∑—É –∂–µ –æ—Ç–≤–µ—Ä–≥–ª–∏ –µ–µ. –û–¥–Ω–∞–∫–æ –¥–æ –Ω–µ–µ –¥–æ—Ö–æ–¥–∏–ª–∏ —Å–ª—É—Ö–∏ –æ –¥–æ–±—Ä–æ—Å–µ—Ä–¥–µ—á–Ω–æ–º –ö—É—Ä—å–µ—Ä–µ –∏ –µ–≥–æ —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –ø–∞—Ç—Ä—É–ª–∏—Ä–æ–≤–∞—Ç—å –ì–æ—Ä–æ–¥ - –¥–∞–∂–µ —Ç—Ä—É—â–æ–±—ã –§—Ä–∏—Å–∞–π–¥–∞.\\n\\n\\n\\r\\n–ù–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –î–∂–µ—Å—Å–∏–∫–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –∏ –≤—ã–∂–∏–≤–∞–ª–∞ –≤–æ –§—Ä–∏—Å–∞–π–¥–µ, –¥–µ–ª–∞—è –≤—Å–µ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ç—å –∫–∞–∫—É—é-—Ç–æ –∫—Ä—ã—à–∫—É –∏–ª–∏ –¥–∞–∂–µ –≥–æ—Ä—è—á—É—é –µ–¥—É. –ü—Ä–∏ —ç—Ç–æ–º –æ–Ω–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —Å–ª–µ–¥–∏–ª–∞ –∑–∞ –Ω–æ–≤–æ—Å—Ç—è–º–∏ –æ —Å–≤–æ–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–º —Å–ø–∞—Å–∏—Ç–µ–ª–µ. –£–¥–∞—á–∞ –±—ã–ª–∞ –Ω–∞ –µ–µ —Å—Ç–æ—Ä–æ–Ω–µ, —Ç–∞–∫ –∫–∞–∫ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏–ª—Å—è —Å–ª—É—Ö, —á—Ç–æ –ö—É—Ä—å–µ—Ä –Ω–∞ —Å–≤–æ–±–æ–¥–µ –∏ –æ—Ö—Ä–∞–Ω—è–µ—Ç —É–ª–∏—Ü—ã –§—Ä–∏—Å–∞–π–¥–∞. –û–Ω–∞ –≤—ã–ª–µ—Ç–µ–ª–∞ –∏–∑ –∑–∞—Ö—É–¥–∞–ª–æ–≥–æ –±–∞—Ä–∞, –≤ –∫–æ—Ç–æ—Ä–æ–º —á–∞—Å—Ç–æ –±—ã–≤–∞–ª–∞, –Ω–∞ –ø–æ–∏—Å–∫–∏ –ö—É—Ä—å–µ—Ä–∞.\\n\\n\\n\\r\\n–ï–≥–æ —Ü–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –∏ –ø–æ—á—Ç–µ–Ω–∏–µ, —Å –∫–æ—Ç–æ—Ä—ã–º –≤—Å–µ –∫ –Ω–µ–º—É –æ—Ç–Ω–æ—Å–∏–ª–∏—Å—å, –Ω–µ –æ—Å—Ç–∞–≤–ª—è–ª–∏ —Å–æ–º–Ω–µ–Ω–∏–π –≤ —Ç–æ–º, —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –æ–¥–µ—Ç—ã–π –∏ –≤–æ–æ—Ä—É–∂–µ–Ω–Ω—ã–π –¥–∂–µ–Ω—Ç–ª—å–º–µ–Ω, –ø—Ä–æ–≥—É–ª–∏–≤–∞—é—â–∏–π—Å—è –ø–æ —É–ª–∏—Ü–µ, –∏ –µ—Å—Ç—å —Ç–æ—Ç —Å–∞–º—ã–π —Ç–∞–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–Ω–∞ –∏—Å–∫–∞–ª–∞. –£—Å–ø–æ–∫–æ–∏—Ç–µ–ª—å–Ω–æ –≤–∑–¥–æ—Ö–Ω—É–≤, –æ–Ω–∞ –ø–æ–¥–±–µ–∂–∞–ª–∞ –∫ –Ω–µ–º—É, –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞—è –ø—Ä–æ–∏–∑–Ω–µ—Å—Ç–∏ —É–∂–µ –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—É—é —Ä–µ—á—å, –∏–∑–ª–∞–≥–∞—è –ª–æ–≥–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ —Ç–æ–º, –∫–∞–∫ –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –µ–º—É –ø–æ–ª–µ–∑–Ω–∞, –µ—Å–ª–∏ –æ–Ω –ø–æ–∑–≤–æ–ª–∏—Ç –µ–π –æ—Å—Ç–∞—Ç—å—Å—è –≤ –°—Ç—Ä–∏–ø–µ, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –µ–µ –±–µ–¥–Ω–æ—Å—Ç—å. –û–¥–Ω–∞–∫–æ, –∫ –µ–µ —É–∂–∞—Å—É, –∫–æ–≥–¥–∞ –æ–Ω–∞ –æ—Ç–∫—Ä—ã–ª–∞ —Ä–æ—Ç, —Ç–æ –≤—ã—Ä–≤–∞–ª–æ—Å—å —Å–ª–µ–¥—É—é—â–µ–µ: \"–ò—â–µ—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ö–æ—Ä–æ—à–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –≤—Ä–µ–º—è —Å–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º, —Å—ç—Ä?\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ö—É—Ä—å–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –Ω–µ–µ.  –ë–æ–ª—å—à–∏–µ —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏ –¥–µ–ª–∞–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –µ–≥–æ –ª–∏—Ü–∞ –Ω–µ–∑–∞–º–µ—Ç–Ω—ã–º, –Ω–æ –Ω–µ–±–æ–ª—å—à–∞—è —É–ª—ã–±–∫–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ—è–≤–∏–ª–∞—Å—å –Ω–∞ –µ–≥–æ –ª–∏—Ü–µ.\\n\\n\\n\\r\\n\"–°–ø–∞—Å–∏–±–æ, –º–∏—Å—Å, –Ω–æ —Å–µ–≥–æ–¥–Ω—è –º–Ω–µ –Ω–∏—á–µ–≥–æ —Ç–∞–∫–æ–≥–æ –Ω–µ –Ω—É–∂–Ω–æ\".  –ì–æ–ª–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –∏—Å—Ö–æ–¥–∏–ª –æ—Ç –Ω–µ–≥–æ, –±—ã–ª —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ —Ç–∞–∫–∏–º, –∫–∞–∫ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å –ø–æ –µ–≥–æ –æ–±—Ä–∞–∑—É: –æ–Ω –±—ã–ª —Å–ø–æ–∫–æ–π–Ω—ã–º, –¥–æ–±—Ä—ã–º –∏ –º—è–≥–∫–∏–º, –∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –µ–≥–æ –∫—É–¥–∞ –±–æ–ª–µ–µ –∂–µ—Å—Ç–∫–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–û–Ω–∞ –ø–æ–¥–∞–≤–∏–ª–∞ –≤–∑–¥–æ—Ö –æ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–∞—Å—å –Ω–∞ –≥–ª—É–±–æ–∫–æ–º —Ä—É–º—è–Ω—Ü–µ. –ó–∞–∫—Ä—ã–≤ –≥–ª–∞–∑–∞ –∏ —Ç—Ä—è—Ö–Ω—É–≤ –≥–æ–ª–æ–≤–æ–π, —Å–ª–æ–≤–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –±—É–∫–≤–∞–ª—å–Ω–æ –≤—ã—Ç—Ä—è—Ö–Ω—É—Ç—å –Ω–µ—Ä–≤—ã, –æ–Ω–∞ —Å–Ω–æ–≤–∞ –ø–æ—Å–º–æ—Ç—Ä–µ–ª–∞ –Ω–∞ –∫—É—Ä—å–µ—Ä–∞ –∏ —Å–∫–∞–∑–∞–ª–∞: \"–Ø... –ù–µ—Ç, –ø—Ä–æ—Å—Ç–∏—Ç–µ. –Ø –Ω–µ –∑–Ω–∞—é, –ø–æ—á–µ–º—É —è —Ç–∞–∫ —Å–∫–∞–∑–∞–ª–∞\", - –Ω–µ—Ä–≤–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç —Ä—É–∫–æ–π –ø–æ —Å–ø—É—Ç–∞–≤—à–∏–º—Å—è –≤–æ–ª–æ—Å–∞–º –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç: \"–ü—Ä–æ—Å—Ç–æ... —É –º–µ–Ω—è –µ—Å—Ç—å –∫ —Ç–µ–±–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ\".\\n\\n\\n\\n–û–Ω–∞ –≤—ã–≥–ª—è–¥–∏—Ç –¥–æ–≤–æ–ª—å–Ω–æ –ø–æ–±–µ–∂–¥–µ–Ω–Ω–æ–π, –¥—É–º–∞—è –ø—Ä–æ —Å–µ–±—è, –∫–∞–∫–∞—è –æ–Ω–∞ –Ω–µ—É–¥–∞—á–Ω–∏—Ü–∞. –í–∏–¥–Ω–æ, —á—Ç–æ –æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –≥—Ä–∞–Ω–∏ —Å–ª–µ–∑, –Ω–æ —Å–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏—Ö. –ö–∞–∫ –±—ã –æ–Ω–∞ –Ω–∏ —Å—Ç–∞—Ä–∞–ª–∞—Å—å –±—ã—Ç—å —Å–∏–ª—å–Ω–æ–π –∏ –∫–∞–∫ –±—ã –Ω–∏ –∑–∞–∫–∞–ª–∏–ª–∞ –µ–µ –∂–∏–∑–Ω—å –≤ –ü—É—Å—Ç–æ—à–∏, –æ–Ω–∞ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç–æ–ª—å–∫–æ –∏–∑–º–æ–∂–¥–µ–Ω–∞, –∫–∞–∫ —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã –≤–µ—Ä–∏—Ç—å –ª—é–¥—è–º.<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –Ω–∞—Ö–º—É—Ä–∏–ª—Å—è, –≥–ª—è–¥—è –Ω–∞ –µ–µ –¥–µ–π—Å—Ç–≤–∏—è, –≤–∏–¥—è, —á—Ç–æ –æ–Ω–∞ —è–≤–Ω–æ –æ—á–µ–Ω—å —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω–∞.  –û–Ω —Å–¥–µ–ª–∞–ª —à–∞–≥ –±–ª–∏–∂–µ –∏ –Ω–µ—Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Å–Ω—É–ª—Å—è –µ–µ –ø–ª–µ—á–∞.\\n\\n\\n\\r\\n\"–≠–π, –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ.  –ü—Ä–æ—Å—Ç–æ —É—Å–ø–æ–∫–æ–π—Å—è, –ø–æ–¥—É–º–∞–π, –ø—Ä–µ–∂–¥–µ —á–µ–º –æ—Ç–≤–µ—á–∞—Ç—å.  –ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?\"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–ü—Ä–∏–∫—É—Å–∏–≤ –≥—É–±—É, –æ–Ω–∞ –Ω–µ—Ä–≤–Ω–æ –æ–≥–ª—è–¥—ã–≤–∞–µ—Ç—Å—è –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º, —Å–ª–æ–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—è, –Ω–µ—Ç –ª–∏ –∑–∞ –Ω–µ–π —Å–ª–µ–∂–∫–∏. –ù–µ–º–Ω–æ–≥–æ —É—Å–ø–æ–∫–æ–∏–≤—à–∏—Å—å, –æ–Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç: \"–Ø... —è –î–∂–µ—Å—Å–∏–∫–∞. –ú–æ–π –≥–æ—Ä–æ–¥ –±—ã–ª —Ä–∞–∑—Ä—É—à–µ–Ω –õ–µ–≥–∏–æ–Ω–æ–º –¶–µ–∑–∞—Ä—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥, –∏ –º–Ω–µ –Ω–µ–∫—É–¥–∞ –∏–¥—Ç–∏. –í–æ –§—Ä–∏—Å–∞–π–¥–µ –¥–ª—è –º–µ–Ω—è –Ω–µ—Ç –º–µ—Å—Ç–∞, –Ω–æ —É –º–µ–Ω—è –Ω–µ—Ç –Ω–∏ –∫–µ–ø–æ–∫, –Ω–∏ –ø–∞—Å–ø–æ—Ä—Ç–∞, —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ –ø–æ–ª–æ—Å—É. –Ø –ø—Ä–æ—Å—Ç–æ —Ö–æ—á—É –∏–º–µ—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –º–µ—Å—Ç–æ, –≥–¥–µ –º–æ–∂–Ω–æ –∂–∏—Ç—å –∏ —Ä–∞–±–æ—Ç–∞—Ç—å, - —á–µ—Ä–µ–∑ —Å–µ–∫—É–Ω–¥—É –æ–Ω–∞ –≤—Å–ø–æ–º–Ω–∏–ª–∞, –∫ –∫–æ–º—É –æ–±—Ä–∞—â–∞–µ—Ç—Å—è, –∏ –¥–æ–±–∞–≤–∏–ª–∞ \"—Å—ç—Ä\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–ö—É—Ä—å–µ—Ä –≤–∑–¥–æ—Ö–Ω—É–ª, –æ–ø—É—Å—Ç–∏–≤ –≤–∑–≥–ª—è–¥ –∏ –ø–æ–∫–∞—á–∞–≤ –≥–æ–ª–æ–≤–æ–π.  –≠—Ç–æ –±—ã–ª –Ω–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑, –∫–æ–≥–¥–∞ –∫—Ç–æ-—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏–ª –∫ –Ω–µ–º—É, —á—Ç–æ–±—ã –ª–∏—á–Ω–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å –æ –ø–æ–º–æ—â–∏.  –¢–∞–∫–æ–≤–∞ –±—ã–ª–∞ –µ–≥–æ —Ä–µ–ø—É—Ç–∞—Ü–∏—è.  –û–Ω –≤–æ–æ–±—â–µ –Ω–∏–∫–æ–≥–¥–∞ –Ω–∏–∫–æ–º—É –Ω–µ –æ—Ç–∫–∞–∑—ã–≤–∞–ª –Ω–∞–ø—Ä—è–º—É—é, –Ω–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø—Ä–∞–≤–ª—è–ª –ª—é–¥–µ–π –∫ –¥—Ä—É–≥–∏–º, –∫—Ç–æ –º–æ–≥ –∏–º –ø–æ–º–æ—á—å.  –•–æ—Ç—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å–∏—Å—Ç–µ–º—ã Lucky 38 –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–ª–∏, —á—Ç–æ –µ–º—É –Ω–µ –ø—Ä–∏–¥–µ—Ç—Å—è —Ç—Ä–∞—Ç–∏—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ú–æ—Ö–∞–≤–µ, —É –Ω–µ–≥–æ —Å–æ–≤—Å–µ–º –Ω–µ –±—É–¥–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –µ–¥—É –∏ —Å–æ–Ω, –µ—Å–ª–∏ –æ–Ω –±—É–¥–µ—Ç –ª–∏—á–Ω–æ –ø–æ–º–æ–≥–∞—Ç—å –∫–∞–∂–¥–æ–º—É, –∫—Ç–æ –ø–æ–ø—Ä–æ—Å–∏—Ç.\\n\\n\\n\\n\"–î–∂–µ—Å—Å–∏–∫–∞... –∫–æ–Ω–µ—á–Ω–æ, –∑–¥–µ—Å—å —Å —Ç–æ–±–æ–π –±—É–¥—É—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ\".  –û–Ω —Å–ª–µ–≥–∫–∞ —É–ª—ã–±–Ω—É–ª—Å—è.  \"–¢—ã —Ä–∞–Ω–µ–Ω–∞?  –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –ê–ø–æ–∫–∞–ª–∏–ø—Å–∏—Å–∞ –≤ —Ñ–æ—Ä—Ç–µ –°—Ç–∞—Ä—ã—Ö –ú–æ—Ä–º–æ–Ω–æ–≤...\", - –æ–Ω —É–∫–∞–∑–∞–ª –Ω–∞ –±–æ–ª—å—à–æ–π —Ñ–æ—Ä—Ç –°—Ç–∞—Ä–æ–≥–æ –°–≤–µ—Ç–∞ –Ω–µ–ø–æ–¥–∞–ª–µ–∫—É –æ—Ç –Ω–∏—Ö.  \"–û–Ω–∏ –ø–æ–º–æ–≥—É—Ç —Ç–µ–±–µ —Å —Ç–≤–æ–∏–º–∏ —Ä–∞–Ω–∞–º–∏, —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º–∏ –∏–ª–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏\".<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n–° —Ä–µ—à–∏—Ç–µ–ª—å–Ω—ã–º –≤–∑–≥–ª—è–¥–æ–º –≤ –≥–ª–∞–∑–∞—Ö –æ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∞ —Ç–≤–µ—Ä–¥—ã–π –∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–∞–∫—Ç —Å –∫—É—Ä—å–µ—Ä–æ–º... –∏–ª–∏, –ø–æ –∫—Ä–∞–π–Ω–µ–π –º–µ—Ä–µ, –µ–π —Ç–∞–∫ –ø–æ–∫–∞–∑–∞–ª–æ—Å—å. –ï–≥–æ —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã–µ –æ—á–∫–∏ –±—ã–ª–∏ –æ—á–µ–Ω—å –∑–µ—Ä–∫–∞–ª—å–Ω—ã–º–∏. \"–Ø –Ω–µ –±–µ–∂–µ–Ω–∫–∞ –∏ –Ω–µ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∏—Ü–∞, —Å—ç—Ä. –Ø —Ö–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å. –Ø —Ö–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ —Å—Ç—Ä–∏–ø–µ, –≥–¥–µ —è –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ–≥—É –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–∞ –∂–∏–∑–Ω—å\".\\n\\n\\n\\n–ù–µ –±—É–¥—É—á–∏ –æ—Ç –ø—Ä–∏—Ä–æ–¥—ã —Ç–∞–∫–æ–π —Å–º–µ–ª–æ–π, –æ–Ω–∞ –Ω–µ–º–Ω–æ–≥–æ –ø–æ–∫—Ä–∞—Å–Ω–µ–ª–∞, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏–ª–∞: \"–Ø —Ç—Ä—É–¥–æ–ª—é–±–∏–≤–∞—è, –±—ã—Å—Ç—Ä–æ —É—á—É—Å—å –∏ –≥–æ—Ç–æ–≤–∞ –¥–µ–ª–∞—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ, –µ—Å–ª–∏ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–±–∏—Ç—å—Å—è –Ω–∞ —Å—Ç—Ä–∏–ø. –ì–¥–µ-—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ—Å—Ç–æ –¥–ª—è –º–µ–Ω—è\".<|eot_id|><|start_header_id|>bot<|end_header_id|>\\n\\n–û–Ω –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–µ–ª –≤ –µ–µ –≥–ª–∞–∑–∞, –∫–æ–≥–¥–∞ –æ–Ω–∞ –≥–æ–≤–æ—Ä–∏–ª–∞, –∏, –≤–æ–∑–º–æ–∂–Ω–æ, —É–≤–∏–¥–µ–ª —Ç–∞–º —á—Ç–æ-—Ç–æ –æ—Ç —Å–µ–±—è.  –¢–æ, —á–µ–º –æ–Ω –±—ã–ª –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –ø–æ–¥–Ω—è–ª—Å—è –∏–∑ —Å–≤–æ–µ–π –Ω–µ–≥–ª—É–±'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "526a6229-03fd-4826-b7ea-d82cee652ae4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "0bc2daf4-23ab-4f4f-8d12-e2beb262b037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "14.535 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "1b960a9c-cf34-4a8d-8104-93bafc1f2fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 11,686 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 24,313,856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Most labels in your dataset are -100. Training losses will be all 0.\n",
            "For example, are you sure you used `train_on_responses_only` correctly?\n",
            "Or did you mask our tokens incorrectly? Maybe this is intended?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 28.12 MiB is free. Process 45902 has 14.71 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 50.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-3d62c575fcfd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/tokenizer_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         )\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3706\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3707\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3708\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3709\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3710\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m ):\n\u001b[0;32m-> 1130\u001b[0;31m     return self.base_model(\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mcausal_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_no_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             outputs = self.model(\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    854\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaDecoderLayer_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_rms_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/fast_lora.py\u001b[0m in \u001b[0;36mapply_lora_mlp_swiglu\u001b[0;34m(self, X, inplace)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mupW\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mupW_quant\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupA\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupB\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lora_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mup_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mdownW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lora_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     out = LoRA_MLP.apply(X,\n\u001b[0m\u001b[1;32m    163\u001b[0m                          \u001b[0mgateW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                          \u001b[0mupW\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mupW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupA\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupB\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcast_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fwd_used_autocast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mautocast_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/fast_lora.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, X, gateW, gateW_quant, gateA, gateB, gateS, upW, upW_quant, upA, upB, upS, downW, downW_quant, downA, downB, downS, _forward_function, _backward_function, inplace)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupW\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupW_quant\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupA\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupB\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         ctx.custom_saved_tensors = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py\u001b[0m in \u001b[0;36mmatmul_lora\u001b[0;34m(X, W, W_quant, A, B, s, out)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmatmul_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_dequantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_quant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py\u001b[0m in \u001b[0;36mfast_dequantize\u001b[0;34m(W, quant_state, out)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Create weight matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 28.12 MiB is free. Process 45902 has 14.71 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 50.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "6ed1d33e-ee2a-41f6-8231-692ace190477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "480.6658 seconds used for training.\n",
            "8.01 minutes used for training.\n",
            "Peak reserved memory = 14.553 GB.\n",
            "Peak reserved memory for training = 0.018 GB.\n",
            "Peak reserved memory % of max memory = 98.725 %.\n",
            "Peak reserved memory for training % of max memory = 0.122 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "6bcf8432-8785-4094-9feb-cb491b3117d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 45902 has 14.71 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 51.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-55f7c0b4d3b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m ).to(\"cuda\")\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n\u001b[0m\u001b[1;32m     20\u001b[0m                          temperature = 1.5, min_p = 0.1)\n\u001b[1;32m     21\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0;31m# Autocasted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3251\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3252\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_no_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             outputs = self.model(\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    854\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaDecoderLayer_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_rms_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/fast_lora.py\u001b[0m in \u001b[0;36mapply_lora_mlp_swiglu\u001b[0;34m(self, X, inplace)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mupW\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mupW_quant\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupA\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupB\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lora_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mup_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mdownW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lora_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     out = LoRA_MLP.apply(X,\n\u001b[0m\u001b[1;32m    163\u001b[0m                          \u001b[0mgateW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                          \u001b[0mupW\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mupW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupA\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupB\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcast_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fwd_used_autocast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mautocast_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/fast_lora.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, X, gateW, gateW_quant, gateA, gateB, gateS, upW, upW_quant, upA, upB, upS, downW, downW_quant, downA, downB, downS, _forward_function, _backward_function, inplace)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupW\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupW_quant\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupA\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupB\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mupS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py\u001b[0m in \u001b[0;36mmatmul_lora\u001b[0;34m(X, W, W_quant, A, B, s, out)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmatmul_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_quant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_dequantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_quant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/utils.py\u001b[0m in \u001b[0;36mfast_dequantize\u001b[0;34m(W, quant_state, out)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Create weight matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 45902 has 14.71 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 51.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"–ü—Ä–∏–≤–µ—Ç!\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "9218b594-368d-44ea-95dc-55572392d9ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1, 13, 21, 34, 55, 89.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "e2aea08b-611d-4ef7-ee55-b0d839bd98fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "36b0a9b8-2210-4efc-988e-14c7250ad7b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eiffel Tower - The Eiffel Tower is an iconic, tall tower situated in the heart of Paris, the capital of France. Standing 324 meters (1,063 feet) tall, it is a prominent and recognizable landmark. The Eiffel Tower was built for the 1889 World's Fair, held in Paris, and its construction required approximately 18 months. It was named after its designer, Gustave Eiffel. The Eiffel Tower has been used for various purposes since its construction, including as a communication and broadcasting tower. It has become a symbol of French culture and engineering.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Describe a tall tower in the capital of France.\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pHDaYcaTSIK"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57481ab209ec481cba85d9596869478d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6559dfe4336f4a8bb45ada14d0af4a7c",
              "IPY_MODEL_7c3d72d4bcf142f29b53c5d00818275c",
              "IPY_MODEL_3bacf0503cdc4d62a270b7d8c1e7bc48"
            ],
            "layout": "IPY_MODEL_ffef66b900be4ee1aacf9728abaa5eb2"
          }
        },
        "6559dfe4336f4a8bb45ada14d0af4a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81dd2cc8b9014609b2cd20ddeb9600bb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_85633e809da940679a182fba4bac08b8",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "7c3d72d4bcf142f29b53c5d00818275c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0a1160e3bd4597953bfadda9e25906",
            "max": 2354805470,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b84679ed4e74efeb264a4781fa443eb",
            "value": 2354805246
          }
        },
        "3bacf0503cdc4d62a270b7d8c1e7bc48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26c0805c1d9458bb0b8145de2e5c0ae",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3765bdf5a32049ddaccc70ac06352f7e",
            "value": "‚Äá2.35G/2.35G‚Äá[00:18&lt;00:00,‚Äá331MB/s]"
          }
        },
        "ffef66b900be4ee1aacf9728abaa5eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81dd2cc8b9014609b2cd20ddeb9600bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85633e809da940679a182fba4bac08b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf0a1160e3bd4597953bfadda9e25906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b84679ed4e74efeb264a4781fa443eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b26c0805c1d9458bb0b8145de2e5c0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3765bdf5a32049ddaccc70ac06352f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c410a11d395542c5aac3bb74d2168059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_950bcb2a564f4f02a5fc57eb8b7188cc",
              "IPY_MODEL_2d5f39b06e754c49b7d9dbcf678e50c9",
              "IPY_MODEL_72cb30322a744138a73ec84bb32db6ed"
            ],
            "layout": "IPY_MODEL_ccfd76324760453890bec67c8e0a64ee"
          }
        },
        "950bcb2a564f4f02a5fc57eb8b7188cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f779651494403daffb25c204776ded",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7e947372ad4547a2860fcb05a2a524ed",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "2d5f39b06e754c49b7d9dbcf678e50c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a76ffcd9a8524adba0f7e856ebcd2e14",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d72a70824ea246e69e29fff289bedadf",
            "value": 234
          }
        },
        "72cb30322a744138a73ec84bb32db6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be0676f942b546a79d986afcae5b217d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5ae629c85ac14f91be8d2c415c93e667",
            "value": "‚Äá234/234‚Äá[00:00&lt;00:00,‚Äá16.2kB/s]"
          }
        },
        "ccfd76324760453890bec67c8e0a64ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f779651494403daffb25c204776ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e947372ad4547a2860fcb05a2a524ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a76ffcd9a8524adba0f7e856ebcd2e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72a70824ea246e69e29fff289bedadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be0676f942b546a79d986afcae5b217d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ae629c85ac14f91be8d2c415c93e667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c3635e64b994d5da077270b2e154190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84a6478e693e43499ece9a6f3fa58c7c",
              "IPY_MODEL_2fe5f67dc5c24df9a2143ebe4bd44f9a",
              "IPY_MODEL_8716b0d7930b4a10a9be35fdb73ab7f3"
            ],
            "layout": "IPY_MODEL_a240c5967e3e49e0ad929304370dd214"
          }
        },
        "84a6478e693e43499ece9a6f3fa58c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8bdfcbe9e84822bf60ab478a8857ca",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_74c4c4ef08f3475c8f68558b4511b666",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "2fe5f67dc5c24df9a2143ebe4bd44f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688e5fe0bf944ce9a8cf7c5f01918fc7",
            "max": 54674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab7061cb2f4342b2aa5b69bd80d756dd",
            "value": 54674
          }
        },
        "8716b0d7930b4a10a9be35fdb73ab7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776e44dbfcb9432fbc020b3546df4bef",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_935167ea9e144e5e9acaba2d5321fb28",
            "value": "‚Äá54.7k/54.7k‚Äá[00:00&lt;00:00,‚Äá4.73MB/s]"
          }
        },
        "a240c5967e3e49e0ad929304370dd214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe8bdfcbe9e84822bf60ab478a8857ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74c4c4ef08f3475c8f68558b4511b666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "688e5fe0bf944ce9a8cf7c5f01918fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7061cb2f4342b2aa5b69bd80d756dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "776e44dbfcb9432fbc020b3546df4bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "935167ea9e144e5e9acaba2d5321fb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc31436406614d0da2da9af5ce040bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_841d599cfa794be1af02fcbaf851d8df",
              "IPY_MODEL_f23896430e7e4964a914745a70a6615d",
              "IPY_MODEL_3e837fa624c84b138ae5469855e13950"
            ],
            "layout": "IPY_MODEL_cf8104a986e54fcfa4abf431860766dc"
          }
        },
        "841d599cfa794be1af02fcbaf851d8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce1976f3a5d482693c794ff983b0c64",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5c3e6bd2f7314db3a2788a2f27c8ce86",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "f23896430e7e4964a914745a70a6615d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f55c1be429644c1be58df561c250a21",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b149939143fc421fb50e31fe61b8786a",
            "value": 17209920
          }
        },
        "3e837fa624c84b138ae5469855e13950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091a22c484294f61b9130229a3e48eac",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5b66903480f54a94a6df6277929c8c98",
            "value": "‚Äá17.2M/17.2M‚Äá[00:00&lt;00:00,‚Äá40.3MB/s]"
          }
        },
        "cf8104a986e54fcfa4abf431860766dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce1976f3a5d482693c794ff983b0c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3e6bd2f7314db3a2788a2f27c8ce86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f55c1be429644c1be58df561c250a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b149939143fc421fb50e31fe61b8786a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "091a22c484294f61b9130229a3e48eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b66903480f54a94a6df6277929c8c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5bb59e50d4446cfaa621feefdfebff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_051f004ad2af45b387e119e58dbaa556",
              "IPY_MODEL_a877ce22c57e43b98e51c5d62459e983",
              "IPY_MODEL_15efb40df15b41bd955e203dfbc36f6f"
            ],
            "layout": "IPY_MODEL_5181a0a13b7e44f09662bd54ab30a8a6"
          }
        },
        "051f004ad2af45b387e119e58dbaa556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9feaa7d7e504414eb2c2c57094631cd0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_74f15b5d1fd44c42872a6f17c37b51ff",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "a877ce22c57e43b98e51c5d62459e983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f7debb292b4a5cbe7e22f91c926eae",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1904f36568c84894936d11a5b516137a",
            "value": 454
          }
        },
        "15efb40df15b41bd955e203dfbc36f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4fed8b1ffe40f794a5c6782a35e913",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bb829a22304749ef847f75b0eda8d77e",
            "value": "‚Äá454/454‚Äá[00:00&lt;00:00,‚Äá37.8kB/s]"
          }
        },
        "5181a0a13b7e44f09662bd54ab30a8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9feaa7d7e504414eb2c2c57094631cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f15b5d1fd44c42872a6f17c37b51ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95f7debb292b4a5cbe7e22f91c926eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1904f36568c84894936d11a5b516137a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c4fed8b1ffe40f794a5c6782a35e913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb829a22304749ef847f75b0eda8d77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c19a89b8825649cd8c84f5dd086e5e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a490e51ce1a4355ad3f07869a41efc2",
              "IPY_MODEL_48e299974bb34a06a2cd2d67973e7972",
              "IPY_MODEL_0e880418a72946cb8090b95fb9ece14b"
            ],
            "layout": "IPY_MODEL_4142d77eb4a04c61b5139dfb217cb30a"
          }
        },
        "9a490e51ce1a4355ad3f07869a41efc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4cdf5b762de4f3fba7355c7391a6493",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4027f755aadd46b9b60a8fcedd8f0fa0",
            "value": "Map:‚Äá100%"
          }
        },
        "48e299974bb34a06a2cd2d67973e7972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4142bbd3e2d14555bbc5cb528649bc00",
            "max": 11686,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_463f8e1bafcf4a4ca9d45418d8ba5ea7",
            "value": 11686
          }
        },
        "0e880418a72946cb8090b95fb9ece14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49e0663d4a3f4a60a124b5be5c1aa76e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f1b628fb0eb3483cb856b64dd27f84de",
            "value": "‚Äá11686/11686‚Äá[00:25&lt;00:00,‚Äá643.90‚Äáexamples/s]"
          }
        },
        "4142d77eb4a04c61b5139dfb217cb30a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4cdf5b762de4f3fba7355c7391a6493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4027f755aadd46b9b60a8fcedd8f0fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4142bbd3e2d14555bbc5cb528649bc00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "463f8e1bafcf4a4ca9d45418d8ba5ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49e0663d4a3f4a60a124b5be5c1aa76e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b628fb0eb3483cb856b64dd27f84de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc512892c31c4c3589d74aa9a5b7a038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e1e1fdc2fc14e95b42a5fc5241d78fa",
              "IPY_MODEL_1485158611c54b718d894b4ae3786e0f",
              "IPY_MODEL_caf42e0cc1ec4a09989b2000332ae2cc"
            ],
            "layout": "IPY_MODEL_28853f5ef0d140f59bc8011dd844b8fd"
          }
        },
        "1e1e1fdc2fc14e95b42a5fc5241d78fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0474b3caa9e474480e15d5c0fc94cb8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5b1f5b135ed347b68104ca365363dbe2",
            "value": "Map‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "1485158611c54b718d894b4ae3786e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3284d646e8174b278a8a413acd7dd591",
            "max": 11686,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f081b07e7cbb40dd8643f1c98284dbe9",
            "value": 11686
          }
        },
        "caf42e0cc1ec4a09989b2000332ae2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cad95e52954d68b28ced2ee2c5ebaa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c028c13e59cd44d88a0bbd0d46b01ed2",
            "value": "‚Äá11686/11686‚Äá[07:26&lt;00:00,‚Äá34.01‚Äáexamples/s]"
          }
        },
        "28853f5ef0d140f59bc8011dd844b8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0474b3caa9e474480e15d5c0fc94cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1f5b135ed347b68104ca365363dbe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3284d646e8174b278a8a413acd7dd591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f081b07e7cbb40dd8643f1c98284dbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42cad95e52954d68b28ced2ee2c5ebaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c028c13e59cd44d88a0bbd0d46b01ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd74425b59b48a9beefe9c5162678ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_301ec1f21c5e4781884b0ebd7a9e2905",
              "IPY_MODEL_2a4d7b28b554467cba961703de59885c",
              "IPY_MODEL_8820d521701d433e952db0f129a7c43d"
            ],
            "layout": "IPY_MODEL_d47c5524c2874ee5a89d47bbce02de47"
          }
        },
        "301ec1f21c5e4781884b0ebd7a9e2905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf67f6c8cd54218acbab404bf3e7f46",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_73857c60f53142b48bcb3061bb38c725",
            "value": "Map:‚Äá100%"
          }
        },
        "2a4d7b28b554467cba961703de59885c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4218ac2f7e49cea3408fb52b5dec15",
            "max": 11686,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b56e94ba693d405ab4e7fe40bfccc1cc",
            "value": 11686
          }
        },
        "8820d521701d433e952db0f129a7c43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a962c6fbabc74b73b1bdfb0fc7f02bdb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_986c65a923334cff9a87fbbc1b70a2c2",
            "value": "‚Äá11686/11686‚Äá[00:17&lt;00:00,‚Äá680.62‚Äáexamples/s]"
          }
        },
        "d47c5524c2874ee5a89d47bbce02de47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf67f6c8cd54218acbab404bf3e7f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73857c60f53142b48bcb3061bb38c725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c4218ac2f7e49cea3408fb52b5dec15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56e94ba693d405ab4e7fe40bfccc1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a962c6fbabc74b73b1bdfb0fc7f02bdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986c65a923334cff9a87fbbc1b70a2c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}